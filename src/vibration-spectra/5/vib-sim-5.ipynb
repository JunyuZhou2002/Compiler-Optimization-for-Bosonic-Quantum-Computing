{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe18a8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "default_n_threads = 8\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = f\"{default_n_threads}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fb3a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import ast\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import strawberryfields as sf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import fsolve\n",
    "from strawberryfields import ops\n",
    "from itertools import combinations\n",
    "from strawberryfields.apps import data, qchem, plot\n",
    "from strawberryfields.utils import random_interferometer\n",
    "from collections import Counter\n",
    "csv.field_size_limit(500 * 1024 * 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba78470",
   "metadata": {},
   "source": [
    "Step1: Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e53b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that take a raw matrix and k (number of columns) and n (the nth number you want to compare) value in, return the best k columns\n",
    "def find_best_k_combination(matrix, k, n):\n",
    "    # get all possible combination\n",
    "    num_columns = matrix.shape[1]\n",
    "    column_combinations = combinations(range(num_columns), k)\n",
    "        \n",
    "#     column_combinations = get_column_combinations(matrix, k)\n",
    "    \n",
    "    strength = []\n",
    "    Combination = []\n",
    "\n",
    "    for combination in column_combinations:\n",
    "        Combination.append(combination)\n",
    "        selected_columns = matrix[:, combination]\n",
    "        # calculate the row abs square sum\n",
    "        row_sums = np.sum(np.abs(selected_columns) ** 2, axis=1)\n",
    "        # make it decrease\n",
    "        sorted_indices = np.argsort(row_sums)[::-1]\n",
    "        sorted_row_sums = row_sums[sorted_indices]\n",
    "        val = sorted_row_sums[n-1]\n",
    "        strength.append(val)\n",
    "\n",
    "    largest_value = np.max(strength)\n",
    "    largest_index = np.argmax(strength)\n",
    "\n",
    "    # find the best combination\n",
    "    best_combination = Combination[largest_index]\n",
    "    best_selected_columns = matrix[:, best_combination]\n",
    "\n",
    "    return best_selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630e421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_for_U2_row(U, len_list):\n",
    "    \n",
    "    M, N = U.shape\n",
    "    U_per = U\n",
    "    \n",
    "    # calculate the sum of first len for U_per\n",
    "    selected_columns = U_per[:, :len_list[0]] \n",
    "    # calculate the row abs square sum\n",
    "    row_sums = np.sum(np.abs(selected_columns) ** 2, axis=1)\n",
    "    \n",
    "    # decide the row rotation\n",
    "    sorted_indices = np.argsort(row_sums)\n",
    "    U_per_new = U_per[sorted_indices]\n",
    "    \n",
    "    # Find row permutation\n",
    "    row_permutation = []\n",
    "    for row in range(U_per_new.shape[0]):\n",
    "        for i in range(U_per.shape[0]):\n",
    "            if np.array_equal(U_per_new[row, :], U_per[i, :]):\n",
    "                row_permutation.append(i)\n",
    "                break\n",
    "                \n",
    "    # find the rows permutation matrix\n",
    "    row_per_matrix = np.zeros((M, M))\n",
    "    for i in range(M):\n",
    "        row_per_matrix[i, row_permutation[i]] = 1\n",
    "        \n",
    "    \n",
    "    U_final = U_per_new\n",
    "    \n",
    "    # U_final = U_per, out put U_final and the permutation\n",
    "    return U_final, row_per_matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacea0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final function, recieve the original matrix and a list of len, also n (the nth number you want to compare), return the permuted matrix\n",
    "# U = row_per_matrix*U'*col_per_matrix\n",
    "def mapping(U, len_list, n):\n",
    "    \n",
    "    M, N = U.shape\n",
    "    total_len = sum(len_list)\n",
    "    assert N == total_len\n",
    "    \n",
    "    # copy U\n",
    "    U_t = U\n",
    "\n",
    "    for i, length in enumerate(len_list):\n",
    "        U_new = find_best_k_combination(U_t, length, n)\n",
    "        \n",
    "        # Find column indices in the larger matrix corresponding to the smaller matrix\n",
    "        selected_columns = []\n",
    "        for col in range(U_new.shape[1]):\n",
    "            for j in range(U_t.shape[1]):\n",
    "                if np.array_equal(U_new[:, col], U_t[:, j]):\n",
    "                    selected_columns.append(j)\n",
    "                    break\n",
    "\n",
    "        # drop U_new from U_t\n",
    "        U_t = np.delete(U_t, selected_columns, axis=1)\n",
    "        \n",
    "        # add U_new to U_per\n",
    "        if i==0:\n",
    "            U_per = U_new\n",
    "        else:\n",
    "            U_per = np.hstack((U_per, U_new))\n",
    "      \n",
    "      \n",
    "    # find the permutation from U_per to U\n",
    "    col_permutation = []\n",
    "    for col in range(U_per.shape[1]):\n",
    "        for i in range(U.shape[1]):\n",
    "            if np.array_equal(U_per[:, col], U[:, i]):\n",
    "                col_permutation.append(i)\n",
    "                break\n",
    "                \n",
    "    # find the columns permutation matrix\n",
    "    col_per_matrix = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        col_per_matrix[col_permutation[i], i] = 1\n",
    "        \n",
    "\n",
    "\n",
    "    # calculate the sum of first len for U_per\n",
    "    selected_columns = U_per[:, :len_list[0]] \n",
    "    # calculate the row abs square sum\n",
    "    row_sums = np.sum(np.abs(selected_columns) ** 2, axis=1)\n",
    "    \n",
    "    # decide the row rotation\n",
    "    sorted_indices = np.argsort(row_sums)\n",
    "    U_per_new = U_per[sorted_indices]\n",
    "    \n",
    "    # Find row permutation\n",
    "    row_permutation = []\n",
    "    for row in range(U_per_new.shape[0]):\n",
    "        for i in range(U_per.shape[0]):\n",
    "            if np.array_equal(U_per_new[row, :], U_per[i, :]):\n",
    "                row_permutation.append(i)\n",
    "                break\n",
    "                \n",
    "    # find the rows permutation matrix\n",
    "    row_per_matrix = np.zeros((M, M))\n",
    "    for i in range(M):\n",
    "        row_per_matrix[i, row_permutation[i]] = 1\n",
    "        \n",
    "    \n",
    "    U_final = U_per_new\n",
    "    \n",
    "    # U_final = U_per, out put U_final and the permutation\n",
    "    return U_final, col_per_matrix.T, row_per_matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552d9a09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "548f1c1d",
   "metadata": {},
   "source": [
    "Step2: Matrix Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82af31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the left eliminate equations\n",
    "def left_equations(variables,parameters):\n",
    "    theta, phi = variables\n",
    "    a_r, a_i, b_r, b_i = parameters\n",
    "    eq1 = a_r * np.cos(phi) * np.cos(theta) + a_i * np.sin(phi) * np.cos(theta) - b_r * np.sin(theta)\n",
    "    eq2 = a_i * np.cos(phi) * np.cos(theta) - a_r * np.sin(phi) * np.cos(theta) - b_i * np.sin(theta)\n",
    "    return [eq1, eq2]\n",
    "\n",
    "# function of left elimination\n",
    "def left_elimination(a,b):\n",
    "    a_r = np.real(a)\n",
    "    a_i = np.imag(a)\n",
    "    b_r = np.real(b)\n",
    "    b_i = np.imag(b)\n",
    "    \n",
    "    # Solve the system of equations\n",
    "    initial_guess = [0, 0]  # Initial guess for the variables\n",
    "    parameters = [a_r, a_i, b_r, b_i]\n",
    "    raw_solution = fsolve(left_equations, initial_guess, args=(parameters,))\n",
    "    \n",
    "    \n",
    "    if np.abs(a_r) < 1e-8 and np.abs(b_i) < 1e-8:\n",
    "            raw_solution = [np.arctan(a_i/b_r), np.pi/2]\n",
    "        \n",
    "    if np.abs(a_i) < 1e-8 and np.abs(b_r) < 1e-8:\n",
    "            raw_solution = [np.arctan(-a_r/b_i), np.pi/2]\n",
    "            \n",
    "            \n",
    "    if np.abs(b_r) < 1e-8 and np.abs(b_i) < 1e-8:\n",
    "            raw_solution = [np.pi/2, 0]\n",
    "    \n",
    "    \n",
    "    normalized_solution = [angle % (2 * np.pi) for angle in raw_solution]\n",
    "    solution = []\n",
    "    for angle in normalized_solution:\n",
    "        if angle < np.pi:\n",
    "            solution.append(angle)\n",
    "        else:\n",
    "            solution.append(angle-2*np.pi)\n",
    "\n",
    "    # Print the solution\n",
    "#     print(\"Solution:\", solution)\n",
    "    return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5493f4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the right eliminate equations\n",
    "def right_equations(variables,parameters):\n",
    "    theta, phi = variables\n",
    "    a_r, a_i, b_r, b_i = parameters\n",
    "    eq1 = a_r * np.cos(phi) * np.sin(theta) + a_i * np.sin(phi) * np.sin(theta) + b_r * np.cos(theta)\n",
    "    eq2 = a_i * np.cos(phi) * np.sin(theta) - a_r * np.sin(phi) * np.sin(theta) + b_i * np.cos(theta)\n",
    "    return [eq1, eq2]\n",
    "\n",
    "# function of right elimination\n",
    "def right_elimination(a,b):\n",
    "    a_r = np.real(a)\n",
    "    a_i = np.imag(a)\n",
    "    b_r = np.real(b)\n",
    "    b_i = np.imag(b)\n",
    "    \n",
    "    # Solve the system of equations\n",
    "    initial_guess = [0, 0]  # Initial guess for the variables\n",
    "    parameters = [a_r, a_i, b_r, b_i]\n",
    "    raw_solution = fsolve(right_equations, initial_guess, args=(parameters,))\n",
    "    \n",
    "    if np.abs(a_r) < 1e-8 and np.abs(b_i) < 1e-8:\n",
    "        raw_solution = [np.arctan(-b_r/a_i), np.pi/2]\n",
    "        \n",
    "    if np.abs(a_i) < 1e-8 and np.abs(b_r) < 1e-8:\n",
    "        raw_solution = [np.arctan(b_i/a_r), np.pi/2]\n",
    "        \n",
    "    if np.abs(a_r) < 1e-8 and np.abs(a_i) < 1e-8:\n",
    "        raw_solution = [np.pi/2, 0]\n",
    "    \n",
    "    normalized_solution = [angle % (2 * np.pi) for angle in raw_solution]\n",
    "    solution = []\n",
    "    for angle in normalized_solution:\n",
    "        if angle < np.pi:\n",
    "            solution.append(angle)\n",
    "        else:\n",
    "            solution.append(angle-2*np.pi)\n",
    "\n",
    "    # Print the solution\n",
    "#     print(\"Solution:\", solution)\n",
    "    return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c8290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give rotation matrix with idx_1 < idx_2\n",
    "def rotation(theta, phi, n, idx_1, idx_2):\n",
    "    I = np.eye(n, dtype=complex)\n",
    "    I[idx_1,idx_1] = np.cos(theta)*(np.cos(phi)-np.sin(phi)*1j)\n",
    "    I[idx_1,idx_2] = np.sin(theta)*(np.cos(phi)-np.sin(phi)*1j)\n",
    "    I[idx_2,idx_1] = -np.sin(theta)\n",
    "    I[idx_2,idx_2] = np.cos(theta)\n",
    "    \n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d024604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix permutation\n",
    "def permutation(U):\n",
    "    \n",
    "    rows, columns = U.shape\n",
    "    assert(rows==columns)\n",
    "    \n",
    "    # create the permutation matrix\n",
    "    Permutation = np.zeros([rows,columns])\n",
    "    \n",
    "    diag_U = np.eye(rows, dtype=complex)\n",
    "    \n",
    "    indices = np.nonzero(U)\n",
    "    row_info = indices[0]\n",
    "    col_info = indices[1]\n",
    "    \n",
    "    for i in range(rows):\n",
    "        col = col_info[i]\n",
    "        row = row_info[i]\n",
    "        diag_U[col,:] = U[row,:]\n",
    "        Permutation[col,row] = 1\n",
    "        \n",
    "    return diag_U, Permutation.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0854916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase(x):\n",
    "    x_r = np.real(x)\n",
    "    x_i = np.imag(x)\n",
    "    \n",
    "    raw_phi = np.arccos(x_r)\n",
    "    if x_i > 0:\n",
    "        t_phi = raw_phi\n",
    "    else:\n",
    "        t_phi = -raw_phi\n",
    "        \n",
    "    normalized_solution = t_phi % (2 * np.pi)\n",
    "    if normalized_solution > np.pi:\n",
    "        normalized_solution = normalized_solution-2*np.pi\n",
    "\n",
    "    return normalized_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff424f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the all_list tell the decomposition order\n",
    "# [[1,2], [2,3], [3,4]] means first use 2 eliminate 1, then use 3 eliminate 2, then use 4 eliminate 3\n",
    "def U_decompose_plus(U, all_list):\n",
    "    \n",
    "    # pick up a machine precision\n",
    "    threshold = 1e-8\n",
    "    \n",
    "    # get the shape of unitary\n",
    "    rows, columns = U.shape\n",
    "    assert(rows==columns)\n",
    "    \n",
    "    # create the rotation record matrix, the first row for theta, the second row for phi \n",
    "    # third row for low index, forth row for high index\n",
    "    Theta = []\n",
    "    Phi = []\n",
    "    Low_idx = []\n",
    "    High_idx = []\n",
    "    \n",
    "    # create the diagonal record matrix\n",
    "    Diag = []\n",
    "    \n",
    "\n",
    "    for i in range(rows-1, 0, -1):\n",
    "        list_i = all_list[i-1]\n",
    "        row = U[i, :]\n",
    "        \n",
    "        for j in range(i):\n",
    "            pair = list_i[j]\n",
    "            \n",
    "            \n",
    "            # a is the number to be eliminated, b is the number to eliminate the previous one\n",
    "            a = row[pair[0]]\n",
    "            b = row[pair[1]]\n",
    "            \n",
    "            \n",
    "#             if i % 3 != 0:\n",
    "#                 if j == i-1:\n",
    "#                     a = row[pair[1]]\n",
    "#                     b = row[pair[0]]\n",
    "                \n",
    "                \n",
    "            # choose the elimination method by position\n",
    "            if pair[0] < pair[1]: \n",
    "                theta, phi = left_elimination(a,b)\n",
    "\n",
    "                # write down the parameter\n",
    "                Theta.append(theta)\n",
    "                Phi.append(phi)\n",
    "                Low_idx.append(pair[0])\n",
    "                High_idx.append(pair[1])\n",
    "\n",
    "                # create the rotation\n",
    "                r = rotation(theta, phi, rows, pair[0], pair[1])\n",
    "        \n",
    "\n",
    "                # update Unitary\n",
    "                U = np.dot(U, r)\n",
    "                U= np.where(np.abs(U) < threshold, 0, U)\n",
    "\n",
    "            else:\n",
    "                theta, phi = right_elimination(b,a)\n",
    "\n",
    "                # write down the parameter\n",
    "                Theta.append(theta)\n",
    "                Phi.append(phi)\n",
    "                Low_idx.append(pair[1])\n",
    "                High_idx.append(pair[0])\n",
    "\n",
    "                # create the rotation\n",
    "                r = rotation(theta, phi, rows, pair[1], pair[0])\n",
    "\n",
    "                # update Unitary\n",
    "                U = np.dot(U, r)\n",
    "                U= np.where(np.abs(U) < threshold, 0, U)\n",
    "\n",
    "            row = U[i, :]\n",
    "            \n",
    "#             if (np.count_nonzero(row) == 1):\n",
    "            if j == i-1:\n",
    "                entry = U[i, pair[1]]\n",
    "                U[:, pair[1]] = 0\n",
    "                U[i, :] = 0\n",
    "                U[i, pair[1]] = entry\n",
    "                flag = 0\n",
    "    \n",
    "    # do the permutation, and record\n",
    "    U, Permutation = permutation(U)\n",
    "    \n",
    "    # find the phase shift\n",
    "    for i in range(rows):\n",
    "        x = U[i,i]/np.abs(U[i,i])\n",
    "        phi_x = phase(x)\n",
    "        Diag.append(phi_x)\n",
    "        U[i,i] = U[i,i]*(np.cos(phi_x)-np.sin(phi_x)*1j)\n",
    "    \n",
    "    \n",
    "    return U, Theta, Phi, Low_idx, High_idx, Diag, Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1d7929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c797e2d",
   "metadata": {},
   "source": [
    "Step3: gate drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87465142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step1 probability\n",
    "def calculate_probability_sequence(angles, threshold, N):\n",
    "    abs_angles = np.abs(angles)\n",
    "    angles1 = abs_angles/(threshold)\n",
    "    angles2 = angles1**N\n",
    "    total_magnitude = np.sum(angles2)\n",
    "    probabilities = angles2 / total_magnitude\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867c0332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence is the origianl angel sequence, probability is calculate using calculate_probability_sequence(angles), percentage is the proportion you want to preserve\n",
    "def pick_entries_with_indices(sequence, probabilities, proportion):\n",
    "    \n",
    "    N = len(sequence)\n",
    "    num_entries = np.floor(N*proportion).astype(int)\n",
    "    \n",
    "    idx_sequence = np.arange(N).astype(int)\n",
    "    \n",
    "    picked_indices = np.random.choice(idx_sequence, size=num_entries, replace=False, p=probabilities)\n",
    "    picked_entries = [sequence[index] for index in picked_indices]\n",
    "\n",
    "    # Sort the picked entries and indices based on the indices\n",
    "    picked_entries, picked_indices = zip(*sorted(zip(picked_entries, picked_indices), key=lambda x: x[1]))\n",
    "    \n",
    "    modified_sequence = [entry if index in picked_indices else 0 for index, entry in enumerate(sequence)]\n",
    "\n",
    "    return modified_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e8217c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22b271e9",
   "metadata": {},
   "source": [
    "Step4: Matric Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30f9083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_entries_zero(array, threshold):\n",
    "    for i in range(len(array)):\n",
    "        if np.abs(array[i]) < threshold:\n",
    "            array[i] = 0\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6029d275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give rotation matrix with idx_1 < idx_2\n",
    "def reconstruct_rotation(theta, phi, n, idx_1, idx_2):\n",
    "    I = np.eye(n, dtype=complex)\n",
    "    I[idx_1,idx_1] = np.cos(theta)*(np.cos(phi)+np.sin(phi)*1j)\n",
    "    I[idx_1,idx_2] = -np.sin(theta)\n",
    "    I[idx_2,idx_1] = np.sin(theta)*(np.cos(phi)+np.sin(phi)*1j)\n",
    "    I[idx_2,idx_2] = np.cos(theta)\n",
    "    \n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95103d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_reconstruct(Theta, Phi, Low_idx, High_idx, Diag, Permutation, N):\n",
    "    \n",
    "    M = len(Theta)\n",
    "    \n",
    "    per_theta = (len([x for x in Theta if np.abs(x) == 0]) / len(Theta)) * 100\n",
    "#     print(\"theta reduce\")\n",
    "#     print(per_theta)\n",
    "    \n",
    "    per_phi = (len([x for x in Phi if np.abs(x) == 0]) / len(Phi)) * 100\n",
    "#     print(\"phi reduce\")\n",
    "#     print(per_phi)\n",
    "\n",
    "#     new_theta = Theta\n",
    "#     new_phi = Phi\n",
    "    \n",
    "    V = np.eye(N, dtype=complex)\n",
    "    \n",
    "    # rotation\n",
    "    for i in range(M):\n",
    "        r = reconstruct_rotation(Theta[i], Phi[i], N, Low_idx[i], High_idx[i])\n",
    "        V = np.dot(r, V)\n",
    "        \n",
    "    # phase shift\n",
    "    for i in range(N):\n",
    "        V[i,:] = V[i,:]*(np.cos(Diag[i])+np.sin(Diag[i])*1j)\n",
    "        \n",
    "    # permutation\n",
    "    V = np.dot(Permutation, V)\n",
    "    \n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e40086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9062bfeb",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23772846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the approximation accuracy\n",
    "def accuracy(U,U_app):\n",
    "    I = np.dot(U,np.conjugate(U_app).transpose())\n",
    "    N, N = I.shape\n",
    "    acc = np.trace(I)/N\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d5de89",
   "metadata": {},
   "source": [
    "Reduce counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9b6b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_numbers_less_than(numbers, threshold1, threshold2):\n",
    "    count = 0\n",
    "    for number in numbers:\n",
    "        if number < threshold1 and number > threshold2:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bdbd1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c13abb6",
   "metadata": {},
   "source": [
    "Step5: Sampling Vibrational Molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5783991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the sampleing function\n",
    "# M is the total sampling numbers\n",
    "# r, U2, alpha is the transition matrix, since Temperature is zero array\n",
    "# dec_list: a list give the decomposition order  \n",
    "# mapping: \"on\" or \"off\", coreesponding to 1 or 0\n",
    "# len_list: a list for mapping\n",
    "# n: a compare number for mapping\n",
    "# all_modes: (q[0], ..., q[N-1])\n",
    "# proportion: 0~1 for U2\n",
    "# loss is the photon number loss\n",
    "# qdrift_kind: 0: defualt, 1:cut\n",
    "def vibration_sampling_plus(M, t, U1, r, U2, alpha, dec_list, maps, len_list, n, proportion1, th1, N1, proportion2, th2, N2, loss):\n",
    "    \n",
    "    N, N = U2.shape\n",
    "    \n",
    "    # mapping\n",
    "    if maps:\n",
    "        U2_map, row_per_matrix = mapping_for_U2_row(U2, len_list)\n",
    "    else:\n",
    "        U2_map = U2\n",
    "        row_per_matrix = np.eye(N)\n",
    "        \n",
    "    # get the decomposition information of U1\n",
    "    _, Theta1, Phi1, Low_idx1, High_idx1, Diag1, Permutation1 = U_decompose_plus(U1, dec_list)\n",
    "    \n",
    "    # modify Theta\n",
    "    Theta_prob1 = calculate_probability_sequence(Theta1, th1, N1)\n",
    "    \n",
    "    # get the decomposition information of U2\n",
    "    _, Theta2, Phi2, Low_idx2, High_idx2, Diag2, Permutation2 = U_decompose_plus(U2_map, dec_list)\n",
    "    \n",
    "    # modify Theta\n",
    "    Theta_prob2 = calculate_probability_sequence(Theta2, th2, N2)\n",
    "    \n",
    "    \n",
    "    k = 0\n",
    "    sample = []\n",
    "    acc1 = []\n",
    "    acc2 = []\n",
    "    while k < M:\n",
    "            \n",
    "        # get the new Theta from the probability distribution\n",
    "        new_Theta1 = pick_entries_with_indices(Theta1, Theta_prob1, proportion1)\n",
    "        new_Phi1 = Phi1\n",
    "        \n",
    "        # reconstruction of U2 using new angel\n",
    "        U1_app = matrix_reconstruct(new_Theta1, new_Phi1, Low_idx1, High_idx1, Diag1, Permutation1, N)\n",
    "        # approximation accuracy\n",
    "        acc1_t = accuracy(U1,U1_app)\n",
    "        acc1.append(acc1_t)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # get the new Theta from the probability distribution\n",
    "        new_Theta2 = pick_entries_with_indices(Theta2, Theta_prob2, proportion2)\n",
    "        new_Phi2 = Phi2\n",
    "        \n",
    "        # reconstruction of U2 using new angel\n",
    "        U2_map_app = matrix_reconstruct(new_Theta2, new_Phi2, Low_idx2, High_idx2, Diag2, Permutation2, N)\n",
    "        # approximation accuracy\n",
    "        acc2_t = accuracy(U2_map,U2_map_app)\n",
    "        acc2.append(acc2_t)\n",
    "        \n",
    "\n",
    "        \n",
    "        # construct the circuit\n",
    "        prog = sf.Program(2*N)\n",
    "        eng = sf.Engine('gaussian')\n",
    "        with prog.context as q:\n",
    "            \n",
    "            # t squeezing\n",
    "            for i, s in enumerate(t):\n",
    "                ops.S2gate(s) | (q[i], q[i+N])\n",
    "#                 ops.Sgate(s) | q[i]\n",
    "                \n",
    "                \n",
    "            # interferometer U1\n",
    "            for i in range(len(new_Theta1)):\n",
    "                ops.Rgate(new_Phi1[i])       | q[Low_idx1[i]]\n",
    "                ops.BSgate(new_Theta1[i], 0) | (q[Low_idx1[i]], q[High_idx1[i]])\n",
    "                if np.abs(new_Theta1[i]) > 0:\n",
    "                    ops.LossChannel(loss) | q[Low_idx1[i]]\n",
    "                    ops.LossChannel(loss) | q[High_idx1[i]]\n",
    "                \n",
    "            for i in range(N):\n",
    "                ops.Rgate(Diag1[i])       | q[i]     \n",
    "            \n",
    "            \n",
    "            # r squeezing\n",
    "            for i, s in enumerate(r):\n",
    "                ops.Sgate(s) | q[i]\n",
    "            \n",
    "            \n",
    "            # interferometer U2\n",
    "            for i in range(len(new_Theta2)):\n",
    "                ops.Rgate(new_Phi2[i])       | q[Low_idx2[i]]\n",
    "                ops.BSgate(new_Theta2[i], 0) | (q[Low_idx2[i]], q[High_idx2[i]])\n",
    "                if np.abs(new_Theta2[i]) > 0:\n",
    "                    ops.LossChannel(loss) | q[Low_idx2[i]]\n",
    "                    ops.LossChannel(loss) | q[High_idx2[i]]\n",
    "                \n",
    "            for i in range(N):\n",
    "                ops.Rgate(Diag2[i])       | q[i]\n",
    "                \n",
    "                \n",
    "            # mapping's row transformation\n",
    "            ops.Interferometer(row_per_matrix) | (q[0], q[1], q[2], q[3], q[4], q[5], q[6], q[7], q[8], q[9], q[10], q[11], q[12], q[13], q[14], q[15], q[16], q[17], q[18], q[19], q[20], q[21], q[22], q[23])\n",
    "            \n",
    "            \n",
    "            # displacement alpha\n",
    "            for i, a in enumerate(alpha):\n",
    "                ops.Dgate(a) | q[i]\n",
    "    \n",
    "    \n",
    "            # measurement\n",
    "            ops.MeasureFock() | q\n",
    "            \n",
    "\n",
    "        \n",
    "        results = eng.run(prog, shots=1)\n",
    "        sample_t = results.samples\n",
    "        sample.append(sample_t[0])\n",
    "        \n",
    "        k = k+1\n",
    "    \n",
    "#     # manipulate the samples\n",
    "#     zero = np.zeros(N)\n",
    "#     for i in range(len(sample)):\n",
    "#         sample[i] = np.concatenate((sample[i], zero))\n",
    "    sample_list = []\n",
    "    for a in sample:\n",
    "        b = list(a)\n",
    "        c = [int(num) for num in b]\n",
    "        sample_list.append(c)\n",
    "\n",
    "        \n",
    "    acc1_mean = np.mean(acc1)\n",
    "#     print(\"mean accuracy for U1:\", acc1_mean)    \n",
    "    acc2_mean = np.mean(acc2)\n",
    "#     print(\"mean accuracy for U2:\", acc2_mean)\n",
    "        \n",
    "    return sample_list, acc1_mean, acc2_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c661deba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unitary_accuracy(M, U1, U2, dec_list, maps, len_list, n, proportion1, proportion2):\n",
    "    \n",
    "    N, N = U2.shape\n",
    "    \n",
    "    # mapping\n",
    "    if maps:\n",
    "        U2_map, row_per_matrix = mapping_for_U2_row(U2, len_list)\n",
    "    else:\n",
    "        U2_map = U2\n",
    "        row_per_matrix = np.eye(N)\n",
    "        \n",
    "    # get the decomposition information of U1\n",
    "    _, Theta1, Phi1, Low_idx1, High_idx1, Diag1, Permutation1 = U_decompose_plus(U1, dec_list)\n",
    "    \n",
    "    # modify Theta\n",
    "    Theta_prob1 = calculate_probability_sequence(Theta1)\n",
    "    \n",
    "    # get the decomposition information of U2\n",
    "    _, Theta2, Phi2, Low_idx2, High_idx2, Diag2, Permutation2 = U_decompose_plus(U2_map, dec_list)\n",
    "    \n",
    "    # modify Theta\n",
    "    Theta_prob2 = calculate_probability_sequence(Theta2)\n",
    "    \n",
    "    \n",
    "    k = 0\n",
    "    sample = []\n",
    "    acc1 = []\n",
    "    acc2 = []\n",
    "    while k < M:\n",
    "\n",
    "        # get the new Theta from the probability distribution\n",
    "        new_Theta1 = pick_entries_with_indices(Theta1, Theta_prob1, proportion1)\n",
    "        new_Phi1 = Phi1\n",
    "        \n",
    "        # reconstruction of U2 using new angel\n",
    "        U1_app = matrix_reconstruct(new_Theta1, new_Phi1, Low_idx1, High_idx1, Diag1, Permutation1, N)\n",
    "        # approximation accuracy\n",
    "        acc1_t = accuracy(U1,U1_app)\n",
    "        acc1.append(acc1_t)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # get the new Theta from the probability distribution\n",
    "        new_Theta2 = pick_entries_with_indices(Theta2, Theta_prob2, proportion2)\n",
    "        new_Phi2 = Phi2\n",
    "        \n",
    "        # reconstruction of U2 using new angel\n",
    "        U2_map_app = matrix_reconstruct(new_Theta2, new_Phi2, Low_idx2, High_idx2, Diag2, Permutation2, N)\n",
    "        # approximation accuracy\n",
    "        acc2_t = accuracy(U2_map,U2_map_app)\n",
    "        acc2.append(acc2_t)\n",
    "        \n",
    "\n",
    "        \n",
    "        k = k+1\n",
    "        \n",
    "    acc1_mean = np.mean(acc1)\n",
    "    print(\"mean accuracy for U1:\", acc1_mean)    \n",
    "    acc2_mean = np.mean(acc2)\n",
    "    print(\"mean accuracy for U2:\", acc2_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a96a0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unitary_dec_info(U1, U2, dec_list, maps, len_list):\n",
    "    \n",
    "    N, N = U2.shape\n",
    "    \n",
    "    # mapping\n",
    "    if maps:\n",
    "        U2_map, row_per_matrix = mapping_for_U2_row(U2, len_list)\n",
    "    else:\n",
    "        U2_map = U2\n",
    "        row_per_matrix = np.eye(N)\n",
    "        \n",
    "    # get the decomposition information of U1\n",
    "    _, Theta1, Phi1, Low_idx1, High_idx1, Diag1, Permutation1 = U_decompose_plus(U1, dec_list)\n",
    "    \n",
    "    \n",
    "    # get the decomposition information of U2\n",
    "    _, Theta2, Phi2, Low_idx2, High_idx2, Diag2, Permutation2 = U_decompose_plus(U2_map, dec_list)\n",
    "    \n",
    "    return Theta1, Theta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc78c4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea16c56c",
   "metadata": {},
   "source": [
    "The Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc681159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probabilities(list1, list2):\n",
    "    # Get unique spectras from both lists\n",
    "    all_spectras = np.unique(list1 + list2)\n",
    "\n",
    "    # Calculate frequency of spectras in list1\n",
    "    freq_list1 = np.array([(np.array(list1) == temp).sum() for temp in all_spectras])\n",
    "\n",
    "    # Calculate frequency of spectras in list2\n",
    "    freq_list2 = np.array([(np.array(list2) == temp).sum() for temp in all_spectras])\n",
    "\n",
    "    # Calculate probability of spectras in list1\n",
    "    prob_list1 = freq_list1 / len(list1)\n",
    "\n",
    "    # Calculate probability of spectras in list2\n",
    "    prob_list2 = freq_list2 / len(list2)\n",
    "\n",
    "    # Sort spectras and probabilities based on spectra values\n",
    "    sort_indices = np.argsort(all_spectras)\n",
    "    all_spectras = all_spectras[sort_indices]\n",
    "    prob_list1 = prob_list1[sort_indices]\n",
    "    prob_list2 = prob_list2[sort_indices]\n",
    "\n",
    "    return all_spectras, prob_list1, prob_list2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274fad46",
   "metadata": {},
   "source": [
    "calculate spectra list from sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eac470b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_spectra(samples, wi, wf):\n",
    "    spectras = []\n",
    "    for sample in samples:\n",
    "        spectra = np.dot(wf, sample[:len(sample)//2])-np.dot(wi, sample[len(sample)//2:])\n",
    "        spectras.append(spectra)\n",
    "        \n",
    "    return spectras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b566670d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectra_category(Spectras):\n",
    "    spectras = Spectras.copy()\n",
    "    for i, spectra in enumerate(spectras):\n",
    "        \n",
    "        if  spectra < -5500:\n",
    "            spectras[i] = -5750\n",
    "        \n",
    "        if -5500 <= spectra < -5000:\n",
    "            spectras[i] = -5250\n",
    "        \n",
    "        if -5000 <= spectra < -4500:\n",
    "            spectras[i] = -4750\n",
    "        \n",
    "        if -4500 <= spectra < -4000:\n",
    "            spectras[i] = -4250\n",
    "        \n",
    "        if -4000 <= spectra < -3500:\n",
    "            spectras[i] = -3750\n",
    "        \n",
    "        if -3500 <= spectra < -3000:\n",
    "            spectras[i] = -3250\n",
    "        \n",
    "        if -3000 <= spectra < -2500:\n",
    "            spectras[i] = -2750\n",
    "        \n",
    "        if -2500 <= spectra < -2000:\n",
    "            spectras[i] = -2250\n",
    "        \n",
    "        if -2000 <= spectra < -1500:\n",
    "            spectras[i] = -1750\n",
    "        \n",
    "        if -1500 <= spectra < -1000:\n",
    "            spectras[i] = -1250\n",
    "        \n",
    "        if -1000 <= spectra < -500:\n",
    "            spectras[i] = -750\n",
    "        \n",
    "        if -500 <= spectra < 0:\n",
    "            spectras[i] = -250\n",
    "        \n",
    "        if 0 <= spectra < 500:\n",
    "            spectras[i] = 250\n",
    "        \n",
    "        if 500 <= spectra < 1000:\n",
    "            spectras[i] = 750\n",
    "        \n",
    "        if 1000 <= spectra < 1500:\n",
    "            spectras[i] = 1250\n",
    "            \n",
    "        if 1500 <= spectra < 2000:\n",
    "            spectras[i] = 1750\n",
    "            \n",
    "        if 2000 <= spectra < 2500:\n",
    "            spectras[i] = 2250\n",
    "            \n",
    "        if 2500 <= spectra < 3000:\n",
    "            spectras[i] = 2750\n",
    "            \n",
    "        if 3000 <= spectra < 3500:\n",
    "            spectras[i] = 3250\n",
    "            \n",
    "        if 3500 <= spectra < 4000:\n",
    "            spectras[i] = 3750\n",
    "            \n",
    "        if 4000 <= spectra < 4500:\n",
    "            spectras[i] = 4250\n",
    "            \n",
    "        if 4500 <= spectra < 5000:\n",
    "            spectras[i] = 4750\n",
    "            \n",
    "        if 5000 <= spectra < 5500:\n",
    "            spectras[i] = 5250\n",
    "            \n",
    "        if 5500 <= spectra < 6000:\n",
    "            spectras[i] = 5750\n",
    "            \n",
    "        if 6000 <= spectra < 6500:\n",
    "            spectras[i] = 6250\n",
    "            \n",
    "        if 6500 <= spectra < 7000:\n",
    "            spectras[i] = 6750\n",
    "            \n",
    "        if 7000 <= spectra < 7500:\n",
    "            spectras[i] = 7250\n",
    "            \n",
    "        if 7500 <= spectra < 8000:\n",
    "            spectras[i] = 7750\n",
    "            \n",
    "        if 8000 <= spectra:\n",
    "            spectras[i] = 8250\n",
    "            \n",
    "    return spectras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df60a70e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da89711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcfdf158",
   "metadata": {},
   "source": [
    "Benchmark for vibration molecule: Pyrrole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c498a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "Li = sf.apps.data.Pyrrole(0).Li  # normal modes of the ground electronic state\n",
    "Lf = sf.apps.data.Pyrrole(0).Lf  # normal modes of the excited electronic state\n",
    "ri = sf.apps.data.Pyrrole(0).ri  # atomic coordinates of the ground electronic state\n",
    "rf = sf.apps.data.Pyrrole(0).rf  # atomic coordinates of the excited electronic state\n",
    "wi = sf.apps.data.Pyrrole(0).wi  # vibrational frequencies of the ground electronic state\n",
    "wf = sf.apps.data.Pyrrole(0).wf  # vibrational frequencies of the excited electronic state\n",
    "m = sf.apps.data.Pyrrole(0).m  # atomic masses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365a78ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ud, delta = qchem.duschinsky(Li, Lf, ri, rf, wf, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eb6c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 750\n",
    "t, U1, r, U2, alpha = qchem.vibronic.gbs_params(wi, wf, Ud, delta, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c75550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_T = 'T.csv'\n",
    "# with open(path_T, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow([T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9195e3f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bed94841",
   "metadata": {},
   "source": [
    "dec_list1: 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d639998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_order = [[0,1], [1,2], [2,3], [3,4], [4,5], [5,6], [6,7], [7,8], [8,9], [9,10], [10,11], [11,12], [12,13], [13,14], [14,15], [15,16], [16,17], [17,18], [18,19], [19,20], [20,21], [21,22], [22,23]]\n",
    "dec_list1 = [list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603a06b1",
   "metadata": {},
   "source": [
    "len_list1: 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6882725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_list1 = [24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fcec1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_dec_list1 = 'dec_list1.csv'\n",
    "# with open(path_dec_list1, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(dec_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2bdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_len_list1 = 'len_list1.csv'\n",
    "# with open(path_len_list1, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(len_list1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcee5562",
   "metadata": {},
   "source": [
    "dec_list2: 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23b1416",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_order23 = [[0,1], [9,1], [1,2], [10,2], [2,3], [13,12], [12,3], [11,3], [3,4], [14,4], [15,4], [4,5], [16,5], [17,5], [5,6], [18,6], [19,6], [6,7], [20,7], [21,7], [7,8], [22,8], [8,23]]\n",
    "list_order22 = [[0,1], [9,1], [1,2], [10,2], [2,3], [13,12], [12,3], [11,3], [3,4], [14,4], [15,4], [4,5], [16,5], [17,5], [5,6], [18,6], [19,6], [6,7], [20,7], [21,7], [7,8], [8,22]]\n",
    "list_order21 = [[0,1], [9,1], [1,2], [10,2], [2,3], [13,12], [12,3], [11,3], [3,4], [14,4], [15,4], [4,5], [16,5], [17,5], [5,6], [18,6], [19,6], [6,7], [20,7], [21,7], [7,8]]\n",
    "list_order20 = [[0,1], [9,1], [1,2], [10,2], [2,3], [13,12], [12,3], [11,3], [3,4], [14,4], [15,4], [4,5], [16,5], [17,5], [5,6], [18,6], [19,6], [6,7], [20,7], [7,21]]\n",
    "list_order19 = [[0,1], [9,1], [1,2], [10,2], [2,3], [13,12], [12,3], [11,3], [3,4], [14,4], [15,4], [4,5], [16,5], [17,5], [5,6], [18,6], [19,6], [6,7], [7,20]]\n",
    "list_order18 = [[0,1], [9,1], [1,2], [10,2], [2,3], [13,12], [12,3], [11,3], [3,4], [14,4], [15,4], [4,5], [16,5], [17,5], [5,6], [18,6], [19,6], [6,7]]\n",
    "list_order17 = [[0,1], [9,1], [1,2], [10,2], [2,3], [13,12], [12,3], [11,3], [3,4], [14,4], [15,4], [4,5], [16,5], [17,5], [5,6], [18,6], [6,19]]\n",
    "list_order16 = [[0,1], [9,1], [1,2], [10,2], [2,3], [13,12], [12,3], [11,3], [3,4], [14,4], [15,4], [4,5], [16,5], [17,5], [5,6], [6,18]]\n",
    "list_order15 = [[0,1], [9,1], [1,2], [10,2], [2,3], [13,12], [12,3], [11,3], [3,4], [14,4], [15,4], [4,5], [16,5], [17,5], [5,6]]\n",
    "list_order14 = [[0,1], [9,1], [1,2], [10,2], [2,3], [13,12], [12,3], [11,3], [3,4], [14,4], [15,4], [4,5], [16,5], [5,17]]\n",
    "list_order13 = [[0,1], [9,1], [1,2], [10,2], [2,3], [13,12], [12,3], [11,3], [3,4], [14,4], [15,4], [4,5], [5,16]]\n",
    "list_order12 = [[0,1], [9,1], [1,2], [10,2], [2,3], [13,12], [12,3], [11,3], [3,4], [14,4], [15,4], [4,5]]\n",
    "list_order11 = [[0,1], [9,1], [1,2], [10,2], [2,3], [13,12], [12,3], [11,3], [3,4], [14,4], [4,15]]\n",
    "list_order10 = [[0,1], [9,1], [1,2], [10,2], [2,3], [13,12], [12,3], [11,3], [3,4], [4,14]]\n",
    "list_order9 = [[0,1], [9,1], [1,2], [10,2], [2,3], [13,12], [12,3], [11,3], [3,4]]\n",
    "list_order8 = [[0,1], [9,1], [1,2], [10,2], [2,3], [13,12], [12,3], [3,11]]\n",
    "list_order7 = [[0,1], [9,1], [1,2], [10,2], [2,3], [3,12], [12,13]]\n",
    "list_order6 = [[0,1], [9,1], [1,2], [10,2], [2,3], [3,12]]\n",
    "list_order5 = [[0,1], [9,1], [1,2], [10,2], [2,3]]\n",
    "list_order4 = [[0,1], [9,1], [1,2], [2,10]]\n",
    "list_order3 = [[0,1], [9,1], [1,2]]\n",
    "list_order2 = [[0,1], [1,9]]\n",
    "list_order1 = [[0,1]]\n",
    "\n",
    "\n",
    "dec_list2 = [list_order1, list_order2, list_order3, list_order4, list_order5, list_order6, list_order7, list_order8, list_order9, list_order10, list_order11, list_order12, list_order13, list_order14, list_order15, list_order16, list_order17, list_order18, list_order19, list_order20, list_order21, list_order22, list_order23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c6e695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_dec_list2 = 'dec_list2.csv'\n",
    "# with open(path_dec_list2, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(dec_list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e6dbe1",
   "metadata": {},
   "source": [
    "len_list2: 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6886e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_list2 = [9,1,1,2,1,1,1,1,1,1,1,1,1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dd5297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_len_list2 = 'len_list2.csv'\n",
    "# with open(path_len_list2, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(len_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e0604e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "427c56ac",
   "metadata": {},
   "source": [
    "Base Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f69922",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_base = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3720128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create path for M_base\n",
    "# path_M_base = 'M_base.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_M_base, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow([M_base])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156fa9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "sample_base, accU1_base, accU2_base = vibration_sampling_plus(M_base, t, U1, r, U2, alpha, dec_list1, 0, len_list1, 12, 1, 1, 1, 1, 1, 1, 1)\n",
    "end_time = time.time()\n",
    "execution_time_base = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5111bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create path for accU1_base\n",
    "# path_accU1_base = 'accU1_base.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_accU1_base, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow([accU1_base])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3222dec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create path for accU2_base\n",
    "# path_accU2_base = 'accU2_base.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_accU2_base, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow([accU2_base])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46abb02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create path for time_base\n",
    "# path_time_base = 'time_base.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_time_base, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow([execution_time_base])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8274cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import base data\n",
    "path_base_sample = 'base_sample.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0922fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file in write mode and create a CSV writer\n",
    "with open(path_base_sample, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the list as a single row in the CSV file\n",
    "    writer.writerow(sample_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7580d8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file in read mode and create a CSV reader\n",
    "with open(path_base_sample, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    # Read the first row from the CSV file\n",
    "    row = next(reader)\n",
    "\n",
    "    # Convert the row elements to integers (if needed)\n",
    "    sample_base_read = [element for element in row] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c2eb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample = []\n",
    "for sample in sample_base_read:\n",
    "    # Remove the square brackets from the string\n",
    "    sample = sample.strip('')\n",
    "    # Convert the string to a list\n",
    "    sample = eval(sample)\n",
    "    new_sample.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7146b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cc6513",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_base = calculate_spectra(sample_base, wi, wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcbb203",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_base_spectra = 'base_spectra.csv'\n",
    "# Open the file in write mode and create a CSV writer\n",
    "with open(path_base_spectra, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the list as a single row in the CSV file\n",
    "    writer.writerow(spectra_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a499a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file in read mode and create a CSV reader\n",
    "with open(path_base_spectra, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    # Read the first row from the CSV file\n",
    "    row = next(reader)\n",
    "\n",
    "    # Convert the row elements to integers (if needed)\n",
    "    spectra_base = [float(element) for element in row] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da3d710",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_base_c = spectra_category(spectra_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ab0836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create path for category spectra\n",
    "# path_base_spectra_c = 'base_spectra_c.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_base_spectra_c, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(spectra_base_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d710fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate how many spectra exceed maximum\n",
    "count = count_numbers_less_than(spectra_base_c, 8000, -5500)\n",
    "proportion = 1-count/len(spectra_base_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deae7bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create path for larger spectra proportion\n",
    "# path_large_spectra = 'large_spectra.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_large_spectra, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow([proportion])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b888fb",
   "metadata": {},
   "source": [
    "Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ad8297",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_range = [0.99, 0.98, 0.97, 0.96, 0.95, 0.94, 0.93, 0.92, 0.91, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6ab3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create path for loss list\n",
    "# path_loss = 'loss.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_loss, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(loss_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506a6265",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_000 = []\n",
    "acc_001 = []\n",
    "acc_101 = []\n",
    "acc_111 = []\n",
    "M = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fe39a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create path for M\n",
    "# path_M = 'M.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_M, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow([M])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7247f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = []\n",
    "spectra = []\n",
    "spectra_c = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da080fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "AccU1 = []\n",
    "AccU2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1738797d",
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = []\n",
    "time2 = []\n",
    "time3 = []\n",
    "time4 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedc4814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we set matrix approximation accuracy as 0.98\n",
    "for loss in loss_range:\n",
    "    \n",
    "    # experiments 1: both turn down\n",
    "    start_time = time.time()\n",
    "    sample1, accU1, accU2 = vibration_sampling_plus(M, t, U1, r, U2, alpha, dec_list1, 0, len_list1, 12, 1, 1, 1, 1, 1, 1, loss)\n",
    "    end_time = time.time()\n",
    "    execution_time1 = end_time - start_time\n",
    "    time1.append(execution_time1)\n",
    "    AccU1.append(accU1)\n",
    "    AccU2.append(accU2)\n",
    "    sample.append(sample1)\n",
    "    spectra1 = calculate_spectra(sample1, wi, wf)\n",
    "    spectra.append(spectra1)\n",
    "    spectra1_c = spectra_category(spectra1)\n",
    "    spectra_c.append(spectra1_c)\n",
    "    _, prob_list1, prob_list_base = calculate_probabilities(spectra1_c, spectra_base_c)\n",
    "    acc1 = np.dot(np.sqrt(prob_list1),np.sqrt(prob_list_base))\n",
    "    acc_000.append(acc1)\n",
    "    \n",
    "    # experiments 2: open drop angles\n",
    "    start_time = time.time()\n",
    "    sample2, accU1, accU2 = vibration_sampling_plus(M, t, U1, r, U2, alpha, dec_list1, 0, len_list1, 12, 0.877, 0.227, 100, 0.888, 0.24, 100, loss)\n",
    "    end_time = time.time()\n",
    "    execution_time2 = end_time - start_time\n",
    "    time2.append(execution_time2)\n",
    "    AccU1.append(accU1)\n",
    "    AccU2.append(accU2)\n",
    "    sample.append(sample2)\n",
    "    spectra2 = calculate_spectra(sample2, wi, wf)\n",
    "    spectra.append(spectra2)\n",
    "    spectra2_c = spectra_category(spectra2)\n",
    "    spectra_c.append(spectra2_c)\n",
    "    _, prob_list2, prob_list_base = calculate_probabilities(spectra2_c, spectra_base_c)\n",
    "    acc2 = np.dot(np.sqrt(prob_list2),np.sqrt(prob_list_base))\n",
    "    acc_001.append(acc2)\n",
    "    \n",
    "\n",
    "    # experiments 3: dec + select\n",
    "    start_time = time.time()\n",
    "    sample3, accU1, accU2 = vibration_sampling_plus(M, t, U1, r, U2, alpha, dec_list2, 0, len_list2, 12, 0.562, 0.245, 30, 0.671, 0.158, 100, loss)\n",
    "    end_time = time.time()\n",
    "    execution_time3 = end_time - start_time\n",
    "    time3.append(execution_time3)\n",
    "    AccU1.append(accU1)\n",
    "    AccU2.append(accU2)\n",
    "    sample.append(sample3)\n",
    "    spectra3 = calculate_spectra(sample3, wi, wf)\n",
    "    spectra.append(spectra3)\n",
    "    spectra3_c = spectra_category(spectra3)\n",
    "    spectra_c.append(spectra3_c)\n",
    "    _, prob_list3, prob_list_base = calculate_probabilities(spectra3_c, spectra_base_c)\n",
    "    acc3 = np.dot(np.sqrt(prob_list3),np.sqrt(prob_list_base))\n",
    "    acc_101.append(acc3)\n",
    "    \n",
    "    # experiments 4: dec + mapping + select\n",
    "    start_time = time.time()\n",
    "    sample4, accU1, accU2 = vibration_sampling_plus(M, t, U1, r, U2, alpha, dec_list2, 1, len_list2, 12, 0.562, 0.245, 30, 0.602, 0.18, 20, loss)\n",
    "    end_time = time.time()\n",
    "    execution_time4 = end_time - start_time\n",
    "    time4.append(execution_time4)\n",
    "    AccU1.append(accU1)\n",
    "    AccU2.append(accU2)\n",
    "    sample.append(sample4)\n",
    "    spectra4 = calculate_spectra(sample4, wi, wf)\n",
    "    spectra.append(spectra4)\n",
    "    spectra4_c = spectra_category(spectra4)\n",
    "    spectra_c.append(spectra4_c)\n",
    "    _, prob_list4, prob_list_base = calculate_probabilities(spectra4_c, spectra_base_c)\n",
    "    acc4 = np.dot(np.sqrt(prob_list4),np.sqrt(prob_list_base))\n",
    "    acc_111.append(acc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2042be05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create path for AccU1\n",
    "# path_AccU1 = 'AccU1.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_AccU1, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(AccU1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cea187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create path for AccU2\n",
    "# path_AccU2 = 'AccU2.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_AccU2, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(AccU2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81869de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create path for time1\n",
    "# path_time1 = 'time1.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_time1, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf9db12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create path for time2\n",
    "# path_time2 = 'time2.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_time2, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(time2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a96a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create path for time3\n",
    "# path_time3 = 'time3.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_time3, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(time3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72a32f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create path for time4\n",
    "# path_time4 = 'time4.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_time4, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(time4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ac6485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create path for sample\n",
    "path_sample = 'sample.csv'\n",
    "# Open the file in write mode and create a CSV writer\n",
    "with open(path_sample, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the list as a single row in the CSV file\n",
    "    writer.writerow(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de00d741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create path for spectra\n",
    "# path_spectra = 'spectra.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_spectra, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4daa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create path for spectra_c\n",
    "# path_spectra_c = 'spectra_c.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_spectra_c, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(spectra_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5cd6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create path for acc_000\n",
    "# path_acc_000 = 'acc_000.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_acc_000, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(acc_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c54ae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create path for acc_001\n",
    "# path_acc_001 = 'acc_001.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_acc_001, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(acc_001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0900b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create path for acc_101\n",
    "# path_acc_101 = 'acc_101.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_acc_101, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(acc_101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2469ccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create path for acc_111\n",
    "# path_acc_111 = 'acc_111.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_acc_111, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(acc_111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caf8e93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8107edd",
   "metadata": {},
   "source": [
    "JSD caculation, picture 5 in vibration simulation, Fig. 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a586a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jensen_shannon_divergence(p, q):\n",
    "    \"\"\"\n",
    "    Calculate the Jensen-Shannon Divergence (JSD) between two probability distributions.\n",
    "\n",
    "    Parameters:\n",
    "        p (numpy array): Probability distribution P as a 1D numpy array.\n",
    "        q (numpy array): Probability distribution Q as a 1D numpy array.\n",
    "\n",
    "    Returns:\n",
    "        float: The Jensen-Shannon Divergence (JSD) between P and Q in nats.\n",
    "    \"\"\"\n",
    "    # Ensure that the input arrays have the same length\n",
    "    if len(p) != len(q):\n",
    "        raise ValueError(\"Input arrays must have the same length.\")\n",
    "\n",
    "    # Normalize the input arrays to ensure they are valid probability distributions\n",
    "    p = p / np.sum(p)\n",
    "    q = q / np.sum(q)\n",
    "\n",
    "    # Calculate the average distribution (M) as the element-wise average of P and Q\n",
    "    m = 0.5 * (p + q)\n",
    "    \n",
    "    # Count the number of zero entries\n",
    "    zero_count = np.count_nonzero(m == 0)\n",
    "\n",
    "    # Print the result\n",
    "    if zero_count>0:\n",
    "        print('error: m has zero entry')\n",
    "\n",
    "\n",
    "    kl_pm = 0\n",
    "    for i, p_i in enumerate(p):\n",
    "        if p[i] != 0:\n",
    "            kl_pm = kl_pm + p[i]*np.log(p[i] / m[i])\n",
    "            \n",
    "    kl_qm = 0\n",
    "    for i, q_i in enumerate(q):\n",
    "        if q[i] != 0:\n",
    "            kl_qm = kl_qm + q[i]*np.log(q[i] / m[i])\n",
    "    \n",
    "\n",
    "    # Calculate the Jensen-Shannon Divergence (JSD) in nats\n",
    "    jsd = 0.5 * (kl_pm + kl_qm)\n",
    "\n",
    "    return jsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24683d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sample(sample):\n",
    "    # Remove 0 from the sample\n",
    "    sample_without_zeros = [element for element in sample if element != 0]\n",
    "    # Sort the sample in descending order\n",
    "    sorted_sample = sorted(sample_without_zeros, reverse=True)\n",
    "    return sorted_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076a5c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the element in base_sample and sample should be str\n",
    "def calculate_jsd(base_sample, sample):\n",
    "    \n",
    "    for i, s in enumerate(base_sample):\n",
    "        # Example string representing a list\n",
    "        string_representation = s\n",
    "\n",
    "        # Convert the string to a list using ast.literal_eval()\n",
    "        try:\n",
    "            result_list = ast.literal_eval(string_representation)\n",
    "        except ValueError as e:\n",
    "            # If the string is not a valid Python literal, handle the exception\n",
    "            print(f\"Error: {e}\")\n",
    "            result_list = None\n",
    "            \n",
    "        s = process_sample(result_list)\n",
    "        \n",
    "        string_list = str(s)\n",
    "        \n",
    "        base_sample[i] = string_list\n",
    "        \n",
    "    for i, s in enumerate(sample):\n",
    "        # Example string representing a list\n",
    "        string_representation = s\n",
    "\n",
    "        # Convert the string to a list using ast.literal_eval()\n",
    "        try:\n",
    "            result_list = ast.literal_eval(string_representation)\n",
    "        except ValueError as e:\n",
    "            # If the string is not a valid Python literal, handle the exception\n",
    "            print(f\"Error: {e}\")\n",
    "            result_list = None\n",
    "            \n",
    "        s = process_sample(result_list)\n",
    "        \n",
    "        string_list = str(s)\n",
    "        \n",
    "        sample[i] = string_list\n",
    "        \n",
    "        \n",
    "    \n",
    "    # Combine the two lists and convert to a set to remove duplicates\n",
    "    combined_set = set(base_sample + sample)\n",
    "\n",
    "    # Convert the set back to a list to get a distinct list\n",
    "    distinct_sample = list(combined_set)\n",
    "    \n",
    "    # Calculate the probability for base_sample\n",
    "    probability_list1 = []\n",
    "    total_elements1 = len(base_sample)\n",
    "    element_count1 = Counter(base_sample)\n",
    "    for element in distinct_sample:\n",
    "        occurrences = element_count1[element] if element in element_count1 else 0\n",
    "        probability = occurrences / total_elements1\n",
    "        probability_list1.append(probability)\n",
    "        \n",
    "    # Calculate the probability for sample\n",
    "    probability_list2 = []\n",
    "    total_elements2 = len(sample)\n",
    "    element_count2 = Counter(sample)\n",
    "    for element in distinct_sample:\n",
    "        occurrences = element_count2[element] if element in element_count2 else 0\n",
    "        probability = occurrences / total_elements2\n",
    "        probability_list2.append(probability) \n",
    "        \n",
    "    # Calculate the Jensen-Shannon Divergence (JSD) between P and Q\n",
    "    jsd_result = jensen_shannon_divergence(probability_list1, probability_list2)\n",
    "#     print(\"Jensen-Shannon Divergence:\", jsd_result)   \n",
    "    \n",
    "    return jsd_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8efc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the mean value for a group of 3 numbers\n",
    "def calculate_mean(group):\n",
    "    return sum(group) / len(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc94796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create path for base_sample\n",
    "path_sample_base = 'base_sample.csv'\n",
    "# Open the file in read mode and create a CSV reader\n",
    "with open(path_sample_base, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    # Read the first row from the CSV file\n",
    "    row = next(reader)\n",
    "\n",
    "    # Convert the row elements to integers (if needed)\n",
    "    sample_base_read = [element for element in row]   \n",
    "    \n",
    "x_axis = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41158608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vib 750K\n",
    "# create path for sample\n",
    "path_sample = 'sample.csv'\n",
    "# Open the file in read mode and create a CSV reader\n",
    "with open(path_sample, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    # Read the first row from the CSV file\n",
    "    row = next(reader)\n",
    "\n",
    "    # Convert the row elements to integers (if needed)\n",
    "    sample_read = [element for element in row]\n",
    "    \n",
    "\n",
    "jsd1 = []\n",
    "jsd2 = []\n",
    "jsd3 = []\n",
    "jsd4 = []\n",
    "\n",
    "for i in range(40):\n",
    "    \n",
    "    # Your string representation of the list of lists\n",
    "    string_representation = sample_read[i]\n",
    "\n",
    "    # Convert the string to an actual list of lists\n",
    "    try:\n",
    "        list_of_lists = ast.literal_eval(string_representation)\n",
    "    except ValueError as e:\n",
    "        # If the string_representation is not a valid Python literal, ValueError will be raised.\n",
    "        print(\"Error:\", e)\n",
    "        list_of_lists = None\n",
    "    \n",
    "    string_list = [str(sub_list) for sub_list in list_of_lists]\n",
    "    \n",
    "    jsd = calculate_jsd(sample_base_read, string_list)\n",
    "    \n",
    "    if i%4 == 0:\n",
    "        jsd1.append(jsd)\n",
    "    elif i%4 == 1:\n",
    "        jsd2.append(jsd)\n",
    "    elif i%4 == 2:\n",
    "        jsd3.append(jsd)\n",
    "    elif i%4 == 3:\n",
    "        jsd4.append(jsd)\n",
    "    \n",
    "#     print(jsd)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 4))    \n",
    "    \n",
    "# Plot data on each subplot\n",
    "plt.plot(x_axis, jsd1, color='blue', label='baseline', marker='x', markersize=16, linewidth=1)\n",
    "plt.plot(x_axis, jsd2, color='green', label='rotation-cut', marker='^', markersize=16, linewidth=1)\n",
    "plt.plot(x_axis, jsd3, color='orange', label='decomposition-opt', marker='o', markersize=16, linewidth=1)\n",
    "plt.plot(x_axis, jsd4, color='red', label='full-opt', marker='s', markersize=16, linewidth=1)\n",
    "# plt.set_title('6by6 structure', fontsize=15)\n",
    "# plt.xlabel('loss', fontsize=15)\n",
    "# plt.ylabel('JSD-dense', fontsize=15)\n",
    "plt.tick_params(axis='x', labelsize=28)\n",
    "plt.tick_params(axis='y', labelsize=28)\n",
    "# Hide the tick labels on both x and y axes\n",
    "# plt.xticks([])\n",
    "# plt.yticks([])\n",
    "# axs[0, 0].legend(fontsize=12, loc='lower left')  # Set the fontsize for the legend labels to 12\n",
    "# plt.gca().invert_yaxis()  # Invert the y-axis\n",
    "# plt.legend(loc='lower left', fontsize=16)\n",
    "\n",
    "# Save the plot as a PDF\n",
    "output_filename = 'vib-sim-5.svg'\n",
    "plt.savefig(output_filename, format='svg', bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf29a74c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0dac78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
