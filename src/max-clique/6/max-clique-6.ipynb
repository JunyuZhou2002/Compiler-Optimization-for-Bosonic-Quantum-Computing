{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fb3a3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:58.501085Z",
     "iopub.status.busy": "2023-07-19T21:25:58.500758Z",
     "iopub.status.idle": "2023-07-19T21:25:59.442573Z",
     "shell.execute_reply": "2023-07-19T21:25:59.442021Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import ast\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import strawberryfields as sf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import fsolve\n",
    "from strawberryfields import ops\n",
    "from itertools import combinations\n",
    "from strawberryfields.apps import data, sample, subgraph, plot, qchem\n",
    "from strawberryfields.apps.similarity import feature_vector_orbits_sampling\n",
    "from strawberryfields.utils import random_interferometer\n",
    "from collections import Counter\n",
    "csv.field_size_limit(500 * 1024 * 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba78470",
   "metadata": {},
   "source": [
    "Step1: Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e53b11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.445263Z",
     "iopub.status.busy": "2023-07-19T21:25:59.444831Z",
     "iopub.status.idle": "2023-07-19T21:25:59.449017Z",
     "shell.execute_reply": "2023-07-19T21:25:59.448554Z"
    }
   },
   "outputs": [],
   "source": [
    "# function that take a raw matrix and k (number of columns) and n (the nth number you want to compare) value in, return the best k columns\n",
    "def find_best_k_combination(matrix, k, n):\n",
    "    # get all possible combination\n",
    "    num_columns = matrix.shape[1]\n",
    "    column_combinations = combinations(range(num_columns), k)\n",
    "        \n",
    "#     column_combinations = get_column_combinations(matrix, k)\n",
    "    \n",
    "    strength = []\n",
    "    Combination = []\n",
    "\n",
    "    for combination in column_combinations:\n",
    "        Combination.append(combination)\n",
    "        selected_columns = matrix[:, combination]\n",
    "        # calculate the row abs square sum\n",
    "        row_sums = np.sum(np.abs(selected_columns) ** 2, axis=1)\n",
    "        # make it decrease\n",
    "        sorted_indices = np.argsort(row_sums)[::-1]\n",
    "        sorted_row_sums = row_sums[sorted_indices]\n",
    "        val = sorted_row_sums[n-1]\n",
    "        strength.append(val)\n",
    "\n",
    "    largest_value = np.max(strength)\n",
    "    largest_index = np.argmax(strength)\n",
    "\n",
    "    # find the best combination\n",
    "    best_combination = Combination[largest_index]\n",
    "    best_selected_columns = matrix[:, best_combination]\n",
    "\n",
    "    return best_selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacea0bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.451120Z",
     "iopub.status.busy": "2023-07-19T21:25:59.450775Z",
     "iopub.status.idle": "2023-07-19T21:25:59.458830Z",
     "shell.execute_reply": "2023-07-19T21:25:59.458343Z"
    }
   },
   "outputs": [],
   "source": [
    "# final function, recieve the original matrix and a list of len, also n (the nth number you want to compare), return the permuted matrix\n",
    "# U = row_per_matrix*U'*col_per_matrix\n",
    "def mapping(U, len_list, n):\n",
    "    \n",
    "    M, N = U.shape\n",
    "    total_len = sum(len_list)\n",
    "    assert N == total_len\n",
    "    \n",
    "    # copy U\n",
    "    U_t = U.copy()\n",
    "#     print(U)\n",
    "    \n",
    "    # new column permutation\n",
    "    for i, length in enumerate(len_list):\n",
    "        if i<len(len_list)-1:\n",
    "            U_new = U_t[:,:length].copy()\n",
    "#             print(\"i:\", i)\n",
    "            # calculate the row abs square sum\n",
    "            row_sums = np.sum(np.abs(U_new) ** 2, axis=1)\n",
    "            U_new_update = U_new.copy()\n",
    "            # iterate remain column\n",
    "            for j in range(np.sum(len_list[i+1:])):\n",
    "#                 print(\"j:\", j)\n",
    "                for k in range(length):\n",
    "#                     print(\"k:\", k)\n",
    "                    U_new_update_k = U_new_update[:,k].copy()\n",
    "                    U_new_update[:,k] = U_t[:,length+j].copy()\n",
    "                    # calculate the row abs square sum\n",
    "                    row_sums_update = np.sum(np.abs(U_new_update) ** 2, axis=1)\n",
    "                \n",
    "                    if np.sort(row_sums_update)[::-1][n-1] > np.sort(row_sums)[::-1][n-1]:\n",
    "#                     row_sums_update[n-1] > row_sums[n-1]:\n",
    "                        U_new = U_new_update.copy()\n",
    "                        U_t[:,length+j] = U_new_update_k.copy()\n",
    "                        U_t[:,:length] = U_new.copy()\n",
    "                        row_sums = row_sums_update\n",
    "                    else:\n",
    "                        U_new_update = U_new.copy()\n",
    "\n",
    "            \n",
    "            # add U_new to U_per\n",
    "            if i==0:\n",
    "                U_per = U_new.copy()\n",
    "            elif i==len(len_list)-2:\n",
    "                U_per = np.hstack((U_per, U_t)).copy()\n",
    "            else:\n",
    "                U_per = np.hstack((U_per, U_new)).copy()\n",
    "\n",
    "            \n",
    "            # drop U_new from U_t\n",
    "            U_t = U_t[:,length:].copy()\n",
    "        \n",
    "                    \n",
    "\n",
    "#     for i, length in enumerate(len_list):\n",
    "#         U_new = find_best_k_combination(U_t, length, n)\n",
    "        \n",
    "#         # Find column indices in the larger matrix corresponding to the smaller matrix\n",
    "#         selected_columns = []\n",
    "#         for col in range(U_new.shape[1]):\n",
    "#             for j in range(U_t.shape[1]):\n",
    "#                 if np.array_equal(U_new[:, col], U_t[:, j]):\n",
    "#                     selected_columns.append(j)\n",
    "#                     break\n",
    "\n",
    "#         # drop U_new from U_t\n",
    "#         U_t = np.delete(U_t, selected_columns, axis=1)\n",
    "        \n",
    "#         # add U_new to U_per\n",
    "#         if i==0:\n",
    "#             U_per = U_new\n",
    "#         else:\n",
    "#             U_per = np.hstack((U_per, U_new))\n",
    "      \n",
    "      \n",
    "    # find the permutation from U_per to U\n",
    "    col_permutation = []\n",
    "    for col in range(U_per.shape[1]):\n",
    "        for i in range(U.shape[1]):\n",
    "            if np.array_equal(U_per[:, col], U[:, i]):\n",
    "                col_permutation.append(i)\n",
    "                break\n",
    "                \n",
    "    # find the columns permutation matrix\n",
    "    col_per_matrix = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        col_per_matrix[col_permutation[i], i] = 1\n",
    "        \n",
    "\n",
    "\n",
    "    # calculate the sum of first len for U_per\n",
    "    selected_columns = U_per[:, :len_list[0]] \n",
    "    # calculate the row abs square sum\n",
    "    row_sums = np.sum(np.abs(selected_columns) ** 2, axis=1)\n",
    "    \n",
    "    # decide the row rotation\n",
    "    sorted_indices = np.argsort(row_sums)\n",
    "    U_per_new = U_per[sorted_indices]\n",
    "    \n",
    "    # Find row permutation\n",
    "    row_permutation = []\n",
    "    for row in range(U_per_new.shape[0]):\n",
    "        for i in range(U_per.shape[0]):\n",
    "            if np.array_equal(U_per_new[row, :], U_per[i, :]):\n",
    "                row_permutation.append(i)\n",
    "                break\n",
    "                \n",
    "    # find the rows permutation matrix\n",
    "    row_per_matrix = np.zeros((M, M))\n",
    "    for i in range(M):\n",
    "        row_per_matrix[i, row_permutation[i]] = 1\n",
    "        \n",
    "    \n",
    "    U_final = U_per_new\n",
    "    \n",
    "    # U_final = U_per, out put U_final and the permutation\n",
    "    return U_final, col_per_matrix.T, row_per_matrix.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548f1c1d",
   "metadata": {},
   "source": [
    "Step2: Matrix Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82af31b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.460809Z",
     "iopub.status.busy": "2023-07-19T21:25:59.460493Z",
     "iopub.status.idle": "2023-07-19T21:25:59.465732Z",
     "shell.execute_reply": "2023-07-19T21:25:59.465252Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the left eliminate equations\n",
    "def left_equations(variables,parameters):\n",
    "    theta, phi = variables\n",
    "    a_r, a_i, b_r, b_i = parameters\n",
    "    eq1 = a_r * np.cos(phi) * np.cos(theta) + a_i * np.sin(phi) * np.cos(theta) - b_r * np.sin(theta)\n",
    "    eq2 = a_i * np.cos(phi) * np.cos(theta) - a_r * np.sin(phi) * np.cos(theta) - b_i * np.sin(theta)\n",
    "    return [eq1, eq2]\n",
    "\n",
    "# function of left elimination\n",
    "def left_elimination(a,b):\n",
    "    a_r = np.real(a)\n",
    "    a_i = np.imag(a)\n",
    "    b_r = np.real(b)\n",
    "    b_i = np.imag(b)\n",
    "    \n",
    "    # Solve the system of equations\n",
    "    initial_guess = [0, 0]  # Initial guess for the variables\n",
    "    parameters = [a_r, a_i, b_r, b_i]\n",
    "    raw_solution = fsolve(left_equations, initial_guess, args=(parameters,))\n",
    "    \n",
    "    \n",
    "    if np.abs(a_r) < 1e-8 and np.abs(b_i) < 1e-8:\n",
    "            raw_solution = [np.arctan(a_i/b_r), np.pi/2]\n",
    "        \n",
    "    if np.abs(a_i) < 1e-8 and np.abs(b_r) < 1e-8:\n",
    "            raw_solution = [np.arctan(-a_r/b_i), np.pi/2]\n",
    "            \n",
    "            \n",
    "    if np.abs(b_r) < 1e-8 and np.abs(b_i) < 1e-8:\n",
    "            raw_solution = [np.pi/2, 0]\n",
    "    \n",
    "    \n",
    "    normalized_solution = [angle % (2 * np.pi) for angle in raw_solution]\n",
    "    solution = []\n",
    "    for angle in normalized_solution:\n",
    "        if angle < np.pi:\n",
    "            solution.append(angle)\n",
    "        else:\n",
    "            solution.append(angle-2*np.pi)\n",
    "\n",
    "    # Print the solution\n",
    "#     print(\"Solution:\", solution)\n",
    "    return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5493f4e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.467615Z",
     "iopub.status.busy": "2023-07-19T21:25:59.467280Z",
     "iopub.status.idle": "2023-07-19T21:25:59.472299Z",
     "shell.execute_reply": "2023-07-19T21:25:59.471907Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the right eliminate equations\n",
    "def right_equations(variables,parameters):\n",
    "    theta, phi = variables\n",
    "    a_r, a_i, b_r, b_i = parameters\n",
    "    eq1 = a_r * np.cos(phi) * np.sin(theta) + a_i * np.sin(phi) * np.sin(theta) + b_r * np.cos(theta)\n",
    "    eq2 = a_i * np.cos(phi) * np.sin(theta) - a_r * np.sin(phi) * np.sin(theta) + b_i * np.cos(theta)\n",
    "    return [eq1, eq2]\n",
    "\n",
    "# function of right elimination\n",
    "def right_elimination(a,b):\n",
    "    a_r = np.real(a)\n",
    "    a_i = np.imag(a)\n",
    "    b_r = np.real(b)\n",
    "    b_i = np.imag(b)\n",
    "    \n",
    "    # Solve the system of equations\n",
    "    initial_guess = [0, 0]  # Initial guess for the variables\n",
    "    parameters = [a_r, a_i, b_r, b_i]\n",
    "    raw_solution = fsolve(right_equations, initial_guess, args=(parameters,))\n",
    "    \n",
    "    if np.abs(a_r) < 1e-8 and np.abs(b_i) < 1e-8:\n",
    "        raw_solution = [np.arctan(-b_r/a_i), np.pi/2]\n",
    "        \n",
    "    if np.abs(a_i) < 1e-8 and np.abs(b_r) < 1e-8:\n",
    "        raw_solution = [np.arctan(b_i/a_r), np.pi/2]\n",
    "        \n",
    "    if np.abs(a_r) < 1e-8 and np.abs(a_i) < 1e-8:\n",
    "        raw_solution = [np.pi/2, 0]\n",
    "    \n",
    "    normalized_solution = [angle % (2 * np.pi) for angle in raw_solution]\n",
    "    solution = []\n",
    "    for angle in normalized_solution:\n",
    "        if angle < np.pi:\n",
    "            solution.append(angle)\n",
    "        else:\n",
    "            solution.append(angle-2*np.pi)\n",
    "\n",
    "    # Print the solution\n",
    "#     print(\"Solution:\", solution)\n",
    "    return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c8290b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.474247Z",
     "iopub.status.busy": "2023-07-19T21:25:59.473938Z",
     "iopub.status.idle": "2023-07-19T21:25:59.477049Z",
     "shell.execute_reply": "2023-07-19T21:25:59.476636Z"
    }
   },
   "outputs": [],
   "source": [
    "# give rotation matrix with idx_1 < idx_2\n",
    "def rotation(theta, phi, n, idx_1, idx_2):\n",
    "    I = np.eye(n, dtype=complex)\n",
    "    I[idx_1,idx_1] = np.cos(theta)*(np.cos(phi)-np.sin(phi)*1j)\n",
    "    I[idx_1,idx_2] = np.sin(theta)*(np.cos(phi)-np.sin(phi)*1j)\n",
    "    I[idx_2,idx_1] = -np.sin(theta)\n",
    "    I[idx_2,idx_2] = np.cos(theta)\n",
    "    \n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d024604b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.478980Z",
     "iopub.status.busy": "2023-07-19T21:25:59.478652Z",
     "iopub.status.idle": "2023-07-19T21:25:59.481929Z",
     "shell.execute_reply": "2023-07-19T21:25:59.481468Z"
    }
   },
   "outputs": [],
   "source": [
    "# matrix permutation\n",
    "def permutation(U):\n",
    "    \n",
    "    rows, columns = U.shape\n",
    "    assert(rows==columns)\n",
    "    \n",
    "    # create the permutation matrix\n",
    "    Permutation = np.zeros([rows,columns])\n",
    "    \n",
    "    diag_U = np.eye(rows, dtype=complex)\n",
    "    \n",
    "    indices = np.nonzero(U)\n",
    "    row_info = indices[0]\n",
    "    col_info = indices[1]\n",
    "    \n",
    "    for i in range(rows):\n",
    "        col = col_info[i]\n",
    "        row = row_info[i]\n",
    "        diag_U[col,:] = U[row,:]\n",
    "        Permutation[col,row] = 1\n",
    "        \n",
    "    return diag_U, Permutation.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0854916",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.483891Z",
     "iopub.status.busy": "2023-07-19T21:25:59.483564Z",
     "iopub.status.idle": "2023-07-19T21:25:59.486514Z",
     "shell.execute_reply": "2023-07-19T21:25:59.486071Z"
    }
   },
   "outputs": [],
   "source": [
    "def phase(x):\n",
    "    x_r = np.real(x)\n",
    "    x_i = np.imag(x)\n",
    "    \n",
    "    raw_phi = np.arccos(x_r)\n",
    "    if x_i > 0:\n",
    "        t_phi = raw_phi\n",
    "    else:\n",
    "        t_phi = -raw_phi\n",
    "        \n",
    "    normalized_solution = t_phi % (2 * np.pi)\n",
    "    if normalized_solution > np.pi:\n",
    "        normalized_solution = normalized_solution-2*np.pi\n",
    "\n",
    "    return normalized_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff424f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.488449Z",
     "iopub.status.busy": "2023-07-19T21:25:59.488123Z",
     "iopub.status.idle": "2023-07-19T21:25:59.494651Z",
     "shell.execute_reply": "2023-07-19T21:25:59.494169Z"
    }
   },
   "outputs": [],
   "source": [
    "# the all_list tell the decomposition order\n",
    "# [[1,2], [2,3], [3,4]] means first use 2 eliminate 1, then use 3 eliminate 2, then use 4 eliminate 3\n",
    "def U_decompose_plus(U, all_list):\n",
    "    \n",
    "    # pick up a machine precision\n",
    "    threshold = 1e-8\n",
    "    \n",
    "    # get the shape of unitary\n",
    "    rows, columns = U.shape\n",
    "    assert(rows==columns)\n",
    "    \n",
    "    # create the rotation record matrix, the first row for theta, the second row for phi \n",
    "    # third row for low index, forth row for high index\n",
    "    Theta = []\n",
    "    Phi = []\n",
    "    Low_idx = []\n",
    "    High_idx = []\n",
    "    \n",
    "    # create the diagonal record matrix\n",
    "    Diag = []\n",
    "    \n",
    "\n",
    "    for i in range(rows-1, 0, -1):\n",
    "        list_i = all_list[i-1]\n",
    "        row = U[i, :]\n",
    "        \n",
    "        for j in range(i):\n",
    "            pair = list_i[j]\n",
    "            \n",
    "            \n",
    "            # a is the number to be eliminated, b is the number to eliminate the previous one\n",
    "            a = row[pair[0]]\n",
    "            b = row[pair[1]]\n",
    "            \n",
    "            \n",
    "#             if i % 3 != 0:\n",
    "#                 if j == i-1:\n",
    "#                     a = row[pair[1]]\n",
    "#                     b = row[pair[0]]\n",
    "                \n",
    "                \n",
    "            # choose the elimination method by position\n",
    "            if pair[0] < pair[1]: \n",
    "                theta, phi = left_elimination(a,b)\n",
    "\n",
    "                # write down the parameter\n",
    "                Theta.append(theta)\n",
    "                Phi.append(phi)\n",
    "                Low_idx.append(pair[0])\n",
    "                High_idx.append(pair[1])\n",
    "\n",
    "                # create the rotation\n",
    "                r = rotation(theta, phi, rows, pair[0], pair[1])\n",
    "        \n",
    "\n",
    "                # update Unitary\n",
    "                U = np.dot(U, r)\n",
    "                U= np.where(np.abs(U) < threshold, 0, U)\n",
    "\n",
    "            else:\n",
    "                theta, phi = right_elimination(b,a)\n",
    "\n",
    "                # write down the parameter\n",
    "                Theta.append(theta)\n",
    "                Phi.append(phi)\n",
    "                Low_idx.append(pair[1])\n",
    "                High_idx.append(pair[0])\n",
    "\n",
    "                # create the rotation\n",
    "                r = rotation(theta, phi, rows, pair[1], pair[0])\n",
    "\n",
    "                # update Unitary\n",
    "                U = np.dot(U, r)\n",
    "                U= np.where(np.abs(U) < threshold, 0, U)\n",
    "\n",
    "            row = U[i, :]\n",
    "            \n",
    "#             if (np.count_nonzero(row) == 1):\n",
    "            if j == i-1:\n",
    "                entry = U[i, pair[1]]\n",
    "                U[:, pair[1]] = 0\n",
    "                U[i, :] = 0\n",
    "                U[i, pair[1]] = entry\n",
    "                flag = 0\n",
    "    \n",
    "    # do the permutation, and record\n",
    "    U, Permutation = permutation(U)\n",
    "    \n",
    "    # find the phase shift\n",
    "    for i in range(rows):\n",
    "        x = U[i,i]/np.abs(U[i,i])\n",
    "        phi_x = phase(x)\n",
    "        Diag.append(phi_x)\n",
    "        U[i,i] = U[i,i]*(np.cos(phi_x)-np.sin(phi_x)*1j)\n",
    "    \n",
    "    \n",
    "    return U, Theta, Phi, Low_idx, High_idx, Diag, Permutation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c797e2d",
   "metadata": {},
   "source": [
    "Step3: Gate drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87465142",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.496488Z",
     "iopub.status.busy": "2023-07-19T21:25:59.496155Z",
     "iopub.status.idle": "2023-07-19T21:25:59.498739Z",
     "shell.execute_reply": "2023-07-19T21:25:59.498327Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step1 probability\n",
    "def calculate_probability_sequence(angles, threshold, N):\n",
    "    abs_angles = np.abs(angles)\n",
    "    angles1 = abs_angles/(threshold)\n",
    "    angles2 = angles1**N\n",
    "    total_magnitude = np.sum(angles2)\n",
    "    probabilities = angles2 / total_magnitude\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867c0332",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.500546Z",
     "iopub.status.busy": "2023-07-19T21:25:59.500223Z",
     "iopub.status.idle": "2023-07-19T21:25:59.503871Z",
     "shell.execute_reply": "2023-07-19T21:25:59.503411Z"
    }
   },
   "outputs": [],
   "source": [
    "# sequence is the origianl angel sequence, probability is calculate using calculate_probability_sequence(angles), percentage is the proportion you want to preserve\n",
    "def pick_entries_with_indices(sequence, probabilities, proportion):\n",
    "    \n",
    "    N = len(sequence)\n",
    "    num_entries = np.floor(N*proportion).astype(int)\n",
    "    \n",
    "    idx_sequence = np.arange(N).astype(int)\n",
    "    \n",
    "    if np.count_nonzero(probabilities) < num_entries:\n",
    "        num_entries = np.count_nonzero(probabilities)\n",
    "    \n",
    "    picked_indices = np.random.choice(idx_sequence, size=num_entries, replace=False, p=probabilities)\n",
    "    picked_entries = [sequence[index] for index in picked_indices]\n",
    "\n",
    "    # Sort the picked entries and indices based on the indices\n",
    "    picked_entries, picked_indices = zip(*sorted(zip(picked_entries, picked_indices), key=lambda x: x[1]))\n",
    "    \n",
    "    modified_sequence = [entry if index in picked_indices else 0 for index, entry in enumerate(sequence)]\n",
    "\n",
    "    return modified_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b271e9",
   "metadata": {},
   "source": [
    "Step4: Matric Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30f9083",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.505983Z",
     "iopub.status.busy": "2023-07-19T21:25:59.505635Z",
     "iopub.status.idle": "2023-07-19T21:25:59.508324Z",
     "shell.execute_reply": "2023-07-19T21:25:59.507906Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_entries_zero(Array, threshold):\n",
    "    array = Array.copy()\n",
    "    for i in range(len(array)):\n",
    "        if np.abs(array[i]) < threshold:\n",
    "            array[i] = 0\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6029d275",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.510236Z",
     "iopub.status.busy": "2023-07-19T21:25:59.509931Z",
     "iopub.status.idle": "2023-07-19T21:25:59.513024Z",
     "shell.execute_reply": "2023-07-19T21:25:59.512571Z"
    }
   },
   "outputs": [],
   "source": [
    "# give rotation matrix with idx_1 < idx_2\n",
    "def reconstruct_rotation(theta, phi, n, idx_1, idx_2):\n",
    "    I = np.eye(n, dtype=complex)\n",
    "    I[idx_1,idx_1] = np.cos(theta)*(np.cos(phi)+np.sin(phi)*1j)\n",
    "    I[idx_1,idx_2] = -np.sin(theta)\n",
    "    I[idx_2,idx_1] = np.sin(theta)*(np.cos(phi)+np.sin(phi)*1j)\n",
    "    I[idx_2,idx_2] = np.cos(theta)\n",
    "    \n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95103d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.514949Z",
     "iopub.status.busy": "2023-07-19T21:25:59.514620Z",
     "iopub.status.idle": "2023-07-19T21:25:59.518553Z",
     "shell.execute_reply": "2023-07-19T21:25:59.518101Z"
    }
   },
   "outputs": [],
   "source": [
    "def matrix_reconstruct(Theta, Phi, Low_idx, High_idx, Diag, Permutation, N):\n",
    "    \n",
    "    M = len(Theta)\n",
    "    \n",
    "    per_theta = (len([x for x in Theta if np.abs(x) == 0]) / len(Theta)) * 100\n",
    "#     print(\"theta reduce\")\n",
    "#     print(per_theta)\n",
    "    \n",
    "    per_phi = (len([x for x in Phi if np.abs(x) == 0]) / len(Phi)) * 100\n",
    "#     print(\"phi reduce\")\n",
    "#     print(per_phi)\n",
    "\n",
    "#     new_theta = Theta\n",
    "#     new_phi = Phi\n",
    "    \n",
    "    V = np.eye(N, dtype=complex)\n",
    "    \n",
    "    # rotation\n",
    "    for i in range(M):\n",
    "        r = reconstruct_rotation(Theta[i], Phi[i], N, Low_idx[i], High_idx[i])\n",
    "        V = np.dot(r, V)\n",
    "        \n",
    "    # phase shift\n",
    "    for i in range(N):\n",
    "        V[i,:] = V[i,:]*(np.cos(Diag[i])+np.sin(Diag[i])*1j)\n",
    "        \n",
    "    # permutation\n",
    "    V = np.dot(Permutation, V)\n",
    "    \n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e40086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9062bfeb",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23772846",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.520511Z",
     "iopub.status.busy": "2023-07-19T21:25:59.520181Z",
     "iopub.status.idle": "2023-07-19T21:25:59.522738Z",
     "shell.execute_reply": "2023-07-19T21:25:59.522309Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to calculate the approximation accuracy\n",
    "def accuracy(U,U_app):\n",
    "    I = np.dot(U,np.conjugate(U_app).transpose())\n",
    "    N, N = I.shape\n",
    "    acc = np.trace(I)/N\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140a48af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.524558Z",
     "iopub.status.busy": "2023-07-19T21:25:59.524232Z",
     "iopub.status.idle": "2023-07-19T21:25:59.528046Z",
     "shell.execute_reply": "2023-07-19T21:25:59.527592Z"
    }
   },
   "outputs": [],
   "source": [
    "def unitary_accuracy(M, U1, dec_list, maps, len_list, n, proportion1, th, N):\n",
    "    \n",
    "    N, N = U1.shape\n",
    "    \n",
    "    # mapping\n",
    "    if maps:\n",
    "        U1_map, col_per_matrix, row_per_matrix = mapping(U1, len_list, n)\n",
    "    else:\n",
    "        U1_map = U1\n",
    "        \n",
    "    # get the decomposition information of U1\n",
    "    _, Theta1, Phi1, Low_idx1, High_idx1, Diag1, Permutation1 = U_decompose_plus(U1_map, dec_list)\n",
    "    \n",
    "    # modify Theta\n",
    "    Theta_prob1 = calculate_probability_sequence(Theta1, th, N)\n",
    "    \n",
    "    k = 0\n",
    "    acc1 = []\n",
    "    while k < M:\n",
    "\n",
    "        # get the new Theta from the probability distribution\n",
    "        new_Theta1 = pick_entries_with_indices(Theta1, Theta_prob1, proportion1)\n",
    "        new_Phi1 = Phi1\n",
    "        \n",
    "        # reconstruction of U2 using new angel\n",
    "        U1_map_app = matrix_reconstruct(new_Theta1, new_Phi1, Low_idx1, High_idx1, Diag1, Permutation1, N)\n",
    "        # approximation accuracy\n",
    "        acc1_t = accuracy(U1_map,U1_map_app)\n",
    "        acc1.append(acc1_t)\n",
    "        \n",
    "        k = k+1\n",
    "        \n",
    "    acc1_mean = np.mean(acc1)\n",
    "    print(\"mean accuracy for U1:\", acc1_mean)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d5de89",
   "metadata": {},
   "source": [
    "Reduce counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9b6b62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.530060Z",
     "iopub.status.busy": "2023-07-19T21:25:59.529734Z",
     "iopub.status.idle": "2023-07-19T21:25:59.532271Z",
     "shell.execute_reply": "2023-07-19T21:25:59.531863Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_numbers_less_than(numbers, threshold):\n",
    "    count = 0\n",
    "    for number in numbers:\n",
    "        if np.abs(number) < threshold:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93726d0c",
   "metadata": {},
   "source": [
    "Convert sample to nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eb16db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.534235Z",
     "iopub.status.busy": "2023-07-19T21:25:59.533918Z",
     "iopub.status.idle": "2023-07-19T21:25:59.536467Z",
     "shell.execute_reply": "2023-07-19T21:25:59.536056Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert sample to nodes\n",
    "def convert_binary_to_nodes(binary_array):\n",
    "    nodes_array = []\n",
    "\n",
    "    for i in range(len(binary_array)):\n",
    "        if binary_array[i] == 1:\n",
    "            nodes_array.append(i)\n",
    "\n",
    "    return nodes_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbecd295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e1000e6",
   "metadata": {},
   "source": [
    "Step5: Sampling dense subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b954071",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.538430Z",
     "iopub.status.busy": "2023-07-19T21:25:59.538119Z",
     "iopub.status.idle": "2023-07-19T21:25:59.548213Z",
     "shell.execute_reply": "2023-07-19T21:25:59.547769Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the sampleing function\n",
    "# G is the graph\n",
    "# G_dense_dic contains the information that tells the densest value of k nodes, k from 1 to N\n",
    "# M is the total sampling numbers\n",
    "# A is the adjacency matrix\n",
    "# dec_list: a list give the decomposition order  \n",
    "# mapping: \"on\" or \"off\", coreesponding to 1 or 0\n",
    "# len_list: a list for mapping\n",
    "# n: a compare number for mapping\n",
    "# all_modes: (q[0], ..., q[N-1])\n",
    "# proportion: 0~1 for U2\n",
    "# loss is the photon number loss\n",
    "# qdrift_kind: 0: defualt, 1:cut\n",
    "def graph_sampling_plus(G, G_dense_dic, M, S, U, dec_list, maps, len_list, n, proportion, th, N, loss, kind):\n",
    "    \n",
    "#     # takagi decomposition to get Squeezing and Unitary\n",
    "#     S, U = sf.decompositions.takagi(A)\n",
    "    \n",
    "    N, N = U.shape\n",
    "    \n",
    "    S_max = np.max(S)\n",
    "    S = S/(S_max+1.8)\n",
    "    S = np.arctanh(S)\n",
    "    \n",
    "    # mapping\n",
    "    if maps:\n",
    "        U_map, col_per_matrix, row_per_matrix = mapping(U, len_list, n)\n",
    "    else:\n",
    "        U_map = U\n",
    "        col_per_matrix = np.eye(N)\n",
    "        row_per_matrix = np.eye(N)\n",
    "    \n",
    "    # get the decomposition information of U\n",
    "    _, Theta, Phi, Low_idx, High_idx, Diag, Permutation = U_decompose_plus(U_map, dec_list)\n",
    "    \n",
    "    # modify Theta\n",
    "    Theta_prob = calculate_probability_sequence(Theta, th, N)\n",
    "    \n",
    "    \n",
    "    \n",
    "    k = 0\n",
    "    sample = []\n",
    "    acc = []\n",
    "    confusion_list = []\n",
    "    clique = 0\n",
    "    while k < M:\n",
    "#         print(k)\n",
    "#         if k % 1000 == 0:\n",
    "#             print(k)\n",
    "        \n",
    "        # get the new Theta from the probability distribution\n",
    "        new_Theta = pick_entries_with_indices(Theta, Theta_prob, proportion)\n",
    "#         new_Theta = Theta\n",
    "        new_Phi = Phi\n",
    "        \n",
    "        # reconstruction of U using new angel\n",
    "        U_map_app = matrix_reconstruct(new_Theta, new_Phi, Low_idx, High_idx, Diag, Permutation, N)\n",
    "        # approximation accuracy\n",
    "        acc_t = accuracy(U_map,U_map_app)\n",
    "        acc.append(acc_t)\n",
    "        \n",
    "        \n",
    "        # construct the circuit\n",
    "        prog = sf.Program(N)\n",
    "        eng = sf.Engine('gaussian')\n",
    "        with prog.context as q:\n",
    "            \n",
    "            # r squeezing\n",
    "            for i, s in enumerate(S):\n",
    "                ops.Sgate(s) | q[i]\n",
    "            \n",
    "            # mapping's column transformation\n",
    "            ops.Interferometer(col_per_matrix) | (q[0], q[1], q[2], q[3], q[4], q[5], q[6], q[7], q[8], q[9], q[10], q[11], q[12], q[13], q[14], q[15], q[16], q[17], q[18], q[19], q[20], q[21], q[22], q[23])\n",
    "            \n",
    "            \n",
    "            # interferometer U\n",
    "            for i in range(len(new_Theta)):\n",
    "                ops.Rgate(new_Phi[i])       | q[Low_idx[i]]\n",
    "                ops.BSgate(new_Theta[i], 0) | (q[Low_idx[i]], q[High_idx[i]])\n",
    "                if np.abs(new_Theta[i]) > 0:\n",
    "                    ops.LossChannel(loss) | q[Low_idx[i]]\n",
    "                    ops.LossChannel(loss) | q[High_idx[i]]\n",
    "                \n",
    "            for i in range(N):\n",
    "                ops.Rgate(Diag[i])       | q[i]\n",
    "                \n",
    "                \n",
    "            # mapping's row transformation\n",
    "            ops.Interferometer(row_per_matrix) | (q[0], q[1], q[2], q[3], q[4], q[5], q[6], q[7], q[8], q[9], q[10], q[11], q[12], q[13], q[14], q[15], q[16], q[17], q[18], q[19], q[20], q[21], q[22], q[23])\n",
    "            \n",
    "            \n",
    "            # measurement\n",
    "            ops.MeasureThreshold() | q\n",
    "            \n",
    "\n",
    "        \n",
    "        results = eng.run(prog, shots=1)\n",
    "        sample_t = results.samples\n",
    "        sample.append(sample_t[0])\n",
    "#         print(sample_t)\n",
    "        \n",
    "        # change the sample to the right form\n",
    "        sample_sub_t = convert_binary_to_nodes(sample_t[0])\n",
    "        sample_sub_t = [str(num) for num in sample_sub_t]\n",
    "#         print(sample_sub_t)\n",
    "        \n",
    "        # calculate is this sample_sub's desity  \n",
    "        if (len(sample_sub_t)>=10):\n",
    "            subgraph = G.subgraph(sample_sub_t)\n",
    "            density = calculate_density(subgraph)\n",
    "#             density = subgraph.search([sample_sub_t], G, len(sample_sub_t), len(sample_sub_t), max_count=1)[len(sample_sub_t)][0][0]\n",
    "#             print(density)\n",
    "        else: \n",
    "            density = 0\n",
    "        \n",
    "        # find the subgraph size\n",
    "        size_t = len(sample_sub_t)\n",
    "#         print(size_t)\n",
    "\n",
    "        # find out if it is the densest subgraph in this size\n",
    "        if density >= G_dense_dic[size_t]-1e-5:\n",
    "            confusion_list.append(1)\n",
    "            if density == 1:\n",
    "#                 print(kind, size_t)\n",
    "                clique = clique + 1\n",
    "#             print(density)\n",
    "#             print(size_t)\n",
    "        else: \n",
    "            confusion_list.append(0)\n",
    "        \n",
    "        k = k+1\n",
    "        \n",
    "    # calculate the frequency that successfully find the dense sub graph\n",
    "    \n",
    "    acc_mean = np.mean(acc)\n",
    "#     print(\"mean accuracy for U:\", acc_mean)\n",
    "    \n",
    "    metric = clique/M\n",
    "#     print(\"successfully find dense subgraph:\", metric)\n",
    "#     print(clique)\n",
    "\n",
    "    # manipulate the samples\n",
    "    zero = np.zeros(N)\n",
    "    for i in range(len(sample)):\n",
    "        sample[i] = np.concatenate((sample[i], zero))\n",
    "    sample_list = []\n",
    "    for a in sample:\n",
    "        b = list(a)\n",
    "        c = [int(num) for num in b]\n",
    "        sample_list.append(c)\n",
    "    \n",
    "        \n",
    "    return sample_list, metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc78c4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77912b50",
   "metadata": {},
   "source": [
    "Create benchmark for max clique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ce08b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.550242Z",
     "iopub.status.busy": "2023-07-19T21:25:59.549918Z",
     "iopub.status.idle": "2023-07-19T21:25:59.552673Z",
     "shell.execute_reply": "2023-07-19T21:25:59.552237Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_random_graph(nodes, probability):\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(nodes)\n",
    "\n",
    "    for i in nodes:\n",
    "        for j in nodes:\n",
    "            if i != j and random.random() < probability:\n",
    "                G.add_edge(i, j)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f671d1e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.554497Z",
     "iopub.status.busy": "2023-07-19T21:25:59.554186Z",
     "iopub.status.idle": "2023-07-19T21:25:59.556712Z",
     "shell.execute_reply": "2023-07-19T21:25:59.556268Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_density(subgraph):\n",
    "    num_nodes = len(subgraph.nodes())\n",
    "    num_edges = len(subgraph.edges())\n",
    "    return 2 * num_edges / (num_nodes * (num_nodes - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a800e485",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.558457Z",
     "iopub.status.busy": "2023-07-19T21:25:59.558141Z",
     "iopub.status.idle": "2023-07-19T21:25:59.561390Z",
     "shell.execute_reply": "2023-07-19T21:25:59.560966Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_highest_density_subgraph(G):\n",
    "    \n",
    "    highest_density = 0.0\n",
    "    highest_density_subgraph = None\n",
    "    N = len(G)\n",
    "    \n",
    "    density_iter = [1.0, 1.0]\n",
    "    for k_nodes in range(2, N+1):  # Iterate over all possible subgraph sizes\n",
    "#         print(k_nodes)\n",
    "        subgraphs = combinations(G.nodes(), k_nodes)  # Generate all combinations of nodes\n",
    "        highest_density = 0\n",
    "        \n",
    "#         highest_density = 0.5\n",
    "        \n",
    "        for nodes in subgraphs:\n",
    "            subgraph = G.subgraph(nodes)  # Create a subgraph from the selected nodes\n",
    "            density = calculate_density(subgraph)\n",
    "            if density > highest_density:\n",
    "                highest_density = density\n",
    "                \n",
    "        print(highest_density)\n",
    "        density_iter.append(highest_density)\n",
    "        \n",
    "#     density_iter.append(1.0)\n",
    "\n",
    "    return density_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f0c2c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.563296Z",
     "iopub.status.busy": "2023-07-19T21:25:59.562974Z",
     "iopub.status.idle": "2023-07-19T21:25:59.565442Z",
     "shell.execute_reply": "2023-07-19T21:25:59.565029Z"
    }
   },
   "outputs": [],
   "source": [
    "# give a dictionary that contains the information that the densest density for k nodes\n",
    "def create_density_dictionary(density_iter):\n",
    "    density_dict = {}\n",
    "    for position, density in enumerate(density_iter):\n",
    "        density_dict[position] = density\n",
    "    return density_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe6c09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.567295Z",
     "iopub.status.busy": "2023-07-19T21:25:59.566977Z",
     "iopub.status.idle": "2023-07-19T21:25:59.568974Z",
     "shell.execute_reply": "2023-07-19T21:25:59.568584Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate G\n",
    "# G = generate_random_graph(range(24), 0.875)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455969ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.570889Z",
     "iopub.status.busy": "2023-07-19T21:25:59.570573Z",
     "iopub.status.idle": "2023-07-19T21:25:59.573391Z",
     "shell.execute_reply": "2023-07-19T21:25:59.572965Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write the graph as an adjacency list\n",
    "# nx.write_adjlist(G, \"new_graph.adjlist\")\n",
    "\n",
    "# Read the graph from the adjacency list\n",
    "G = nx.read_adjlist(\"graph.adjlist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6031537a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.575277Z",
     "iopub.status.busy": "2023-07-19T21:25:59.574972Z",
     "iopub.status.idle": "2023-07-19T21:25:59.726531Z",
     "shell.execute_reply": "2023-07-19T21:25:59.726082Z"
    }
   },
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(G)  # Layout algorithm for node positioning\n",
    "nx.draw(G, pos, with_labels=True, node_color='lightblue', edge_color='gray', font_weight='bold')\n",
    "\n",
    "plt.title(\"Graph\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f15fd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.729126Z",
     "iopub.status.busy": "2023-07-19T21:25:59.728715Z",
     "iopub.status.idle": "2023-07-19T21:25:59.731384Z",
     "shell.execute_reply": "2023-07-19T21:25:59.730969Z"
    }
   },
   "outputs": [],
   "source": [
    "# Obtain the adjacency matrix of the graph G\n",
    "A = nx.to_numpy_array(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73260596",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.733356Z",
     "iopub.status.busy": "2023-07-19T21:25:59.733011Z",
     "iopub.status.idle": "2023-07-19T21:25:59.735664Z",
     "shell.execute_reply": "2023-07-19T21:25:59.735260Z"
    }
   },
   "outputs": [],
   "source": [
    "S, U = sf.decompositions.takagi(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85053e23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.737512Z",
     "iopub.status.busy": "2023-07-19T21:25:59.737163Z",
     "iopub.status.idle": "2023-07-19T21:25:59.739921Z",
     "shell.execute_reply": "2023-07-19T21:25:59.739513Z"
    }
   },
   "outputs": [],
   "source": [
    "S, U = sf.decompositions.takagi(A)\n",
    "S_max = np.max(S)\n",
    "S = S/(S_max+0.55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d816c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.741779Z",
     "iopub.status.busy": "2023-07-19T21:25:59.741469Z",
     "iopub.status.idle": "2023-07-19T21:25:59.744395Z",
     "shell.execute_reply": "2023-07-19T21:25:59.743983Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 0\n",
    "for s in S:\n",
    "    n = n+s**2/(1-s**2)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d15099e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.746334Z",
     "iopub.status.busy": "2023-07-19T21:25:59.746015Z",
     "iopub.status.idle": "2023-07-19T21:25:59.748514Z",
     "shell.execute_reply": "2023-07-19T21:25:59.748114Z"
    }
   },
   "outputs": [],
   "source": [
    "S, U = sf.decompositions.takagi(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5b575b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.750390Z",
     "iopub.status.busy": "2023-07-19T21:25:59.750063Z",
     "iopub.status.idle": "2023-07-19T21:25:59.752996Z",
     "shell.execute_reply": "2023-07-19T21:25:59.752595Z"
    }
   },
   "outputs": [],
   "source": [
    "calculate_density(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b0e2e2",
   "metadata": {},
   "source": [
    "Calculate the information of this graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabeeead",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.754819Z",
     "iopub.status.busy": "2023-07-19T21:25:59.754480Z",
     "iopub.status.idle": "2023-07-19T21:25:59.756586Z",
     "shell.execute_reply": "2023-07-19T21:25:59.756177Z"
    }
   },
   "outputs": [],
   "source": [
    "# function that find the densest subgraph in graph G of all size k\n",
    "# density_iter = find_highest_density_subgraph(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47284020",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.758435Z",
     "iopub.status.busy": "2023-07-19T21:25:59.758123Z",
     "iopub.status.idle": "2023-07-19T21:25:59.760764Z",
     "shell.execute_reply": "2023-07-19T21:25:59.760319Z"
    }
   },
   "outputs": [],
   "source": [
    "density_iter = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99523, 0.99134, 0.98814, 0.98188]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4573d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.762663Z",
     "iopub.status.busy": "2023-07-19T21:25:59.762327Z",
     "iopub.status.idle": "2023-07-19T21:25:59.764517Z",
     "shell.execute_reply": "2023-07-19T21:25:59.764114Z"
    }
   },
   "outputs": [],
   "source": [
    "density_dict = create_density_dictionary(density_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a64d792",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.766384Z",
     "iopub.status.busy": "2023-07-19T21:25:59.766065Z",
     "iopub.status.idle": "2023-07-19T21:25:59.768478Z",
     "shell.execute_reply": "2023-07-19T21:25:59.768068Z"
    }
   },
   "outputs": [],
   "source": [
    "print(density_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed94841",
   "metadata": {},
   "source": [
    "dec_list1: 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d639998d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.770306Z",
     "iopub.status.busy": "2023-07-19T21:25:59.769991Z",
     "iopub.status.idle": "2023-07-19T21:25:59.773309Z",
     "shell.execute_reply": "2023-07-19T21:25:59.772911Z"
    }
   },
   "outputs": [],
   "source": [
    "list_order = [[0,1], [1,2], [2,3], [3,4], [4,5], [5,6], [6,7], [7,8], [8,9], [9,10], [10,11], [11,12], [12,13], [13,14], [14,15], [15,16], [16,17], [17,18], [18,19], [19,20], [20,21], [21,22], [22,23]]\n",
    "dec_list1 = [list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603a06b1",
   "metadata": {},
   "source": [
    "len_list1: 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6882725d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.775277Z",
     "iopub.status.busy": "2023-07-19T21:25:59.774954Z",
     "iopub.status.idle": "2023-07-19T21:25:59.777134Z",
     "shell.execute_reply": "2023-07-19T21:25:59.776694Z"
    }
   },
   "outputs": [],
   "source": [
    "len_list1 = [24]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcee5562",
   "metadata": {},
   "source": [
    "dec_list2: 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23b1416",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.779204Z",
     "iopub.status.busy": "2023-07-19T21:25:59.778876Z",
     "iopub.status.idle": "2023-07-19T21:25:59.791660Z",
     "shell.execute_reply": "2023-07-19T21:25:59.791227Z"
    }
   },
   "outputs": [],
   "source": [
    "list_order23 = [[8,0], [9,0], [0,1], [10,1], [11,1], [1,2], [12,2], [13,2], [2,3], [14,3], [15,3], [3,4], [16,4], [17,4], [4,5], [18,5], [19,5], [5,6], [20,6], [21,6], [6,7], [22,7], [7,23]]\n",
    "list_order22 = [[8,0], [9,0], [0,1], [10,1], [11,1], [1,2], [12,2], [13,2], [2,3], [14,3], [15,3], [3,4], [16,4], [17,4], [4,5], [18,5], [19,5], [5,6], [20,6], [21,6], [6,7], [7,22]]\n",
    "list_order21 = [[8,0], [9,0], [0,1], [10,1], [11,1], [1,2], [12,2], [13,2], [2,3], [14,3], [15,3], [3,4], [16,4], [17,4], [4,5], [18,5], [19,5], [5,6], [20,6], [21,6], [6,7]]\n",
    "list_order20 = [[8,0], [9,0], [0,1], [10,1], [11,1], [1,2], [12,2], [13,2], [2,3], [14,3], [15,3], [3,4], [16,4], [17,4], [4,5], [18,5], [19,5], [5,6], [20,6], [6,21]]\n",
    "list_order19 = [[8,0], [9,0], [0,1], [10,1], [11,1], [1,2], [12,2], [13,2], [2,3], [14,3], [15,3], [3,4], [16,4], [17,4], [4,5], [18,5], [19,5], [5,6], [6,20]]\n",
    "list_order18 = [[8,0], [9,0], [0,1], [10,1], [11,1], [1,2], [12,2], [13,2], [2,3], [14,3], [15,3], [3,4], [16,4], [17,4], [4,5], [18,5], [19,5], [5,6]]\n",
    "list_order17 = [[8,0], [9,0], [0,1], [10,1], [11,1], [1,2], [12,2], [13,2], [2,3], [14,3], [15,3], [3,4], [16,4], [17,4], [4,5], [18,5], [5,19]]\n",
    "list_order16 = [[8,0], [9,0], [0,1], [10,1], [11,1], [1,2], [12,2], [13,2], [2,3], [14,3], [15,3], [3,4], [16,4], [17,4], [4,5], [5,18]]\n",
    "list_order15 = [[8,0], [9,0], [0,1], [10,1], [11,1], [1,2], [12,2], [13,2], [2,3], [14,3], [15,3], [3,4], [16,4], [17,4], [4,5]]\n",
    "list_order14 = [[8,0], [9,0], [0,1], [10,1], [11,1], [1,2], [12,2], [13,2], [2,3], [14,3], [15,3], [3,4], [16,4], [4,17]]\n",
    "list_order13 = [[8,0], [9,0], [0,1], [10,1], [11,1], [1,2], [12,2], [13,2], [2,3], [14,3], [15,3], [3,4], [4,16]]\n",
    "list_order12 = [[8,0], [9,0], [0,1], [10,1], [11,1], [1,2], [12,2], [13,2], [2,3], [14,3], [15,3], [3,4]]\n",
    "list_order11 = [[8,0], [9,0], [0,1], [10,1], [11,1], [1,2], [12,2], [13,2], [2,3], [14,3], [3,15]]\n",
    "list_order10 = [[8,0], [9,0], [0,1], [10,1], [11,1], [1,2], [12,2], [13,2], [2,3], [3,14]]\n",
    "list_order9 = [[8,0], [9,0], [0,1], [10,1], [11,1], [1,2], [12,2], [13,2], [2,3]]\n",
    "list_order8 = [[8,0], [9,0], [0,1], [10,1], [11,1], [1,2], [12,2], [2,13]]\n",
    "list_order7 = [[8,0], [9,0], [0,1], [10,1], [11,1], [1,2], [2,12]]\n",
    "list_order6 = [[8,0], [9,0], [0,1], [10,1], [11,1], [1,2]]\n",
    "list_order5 = [[8,0], [9,0], [0,1], [10,1], [1,11]]\n",
    "list_order4 = [[8,0], [9,0], [0,1], [1,10]]\n",
    "list_order3 = [[8,0], [9,0], [0,1]]\n",
    "list_order2 = [[8,0], [0,9]]\n",
    "list_order1 = [[0,8]]\n",
    "\n",
    "\n",
    "dec_list2 = [list_order1, list_order2, list_order3, list_order4, list_order5, list_order6, list_order7, list_order8, list_order9, list_order10, list_order11, list_order12, list_order13, list_order14, list_order15, list_order16, list_order17, list_order18, list_order19, list_order20, list_order21, list_order22, list_order23]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e6dbe1",
   "metadata": {},
   "source": [
    "len_list2: 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6886e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.793483Z",
     "iopub.status.busy": "2023-07-19T21:25:59.793198Z",
     "iopub.status.idle": "2023-07-19T21:25:59.795657Z",
     "shell.execute_reply": "2023-07-19T21:25:59.795221Z"
    }
   },
   "outputs": [],
   "source": [
    "len_list2 = [8,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac187270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e5ee21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135ea063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cd75683",
   "metadata": {},
   "source": [
    "Base Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f955834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "sample_list_base, acc_base = graph_sampling_plus(G, density_dict, 20000, S, U, dec_list1, 0, len_list1, 12, 1, 1, 1, 1, 'base:')\n",
    "end_time = time.time()\n",
    "execution_time_base = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6a6a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create path for sample_base\n",
    "path_sample_base = 'sample_base.csv'\n",
    "# Open the file in write mode and create a CSV writer\n",
    "with open(path_sample_base, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the list as a single row in the CSV file\n",
    "    writer.writerow(sample_list_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95db8a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0006b1d6",
   "metadata": {},
   "source": [
    "Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b919c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.797451Z",
     "iopub.status.busy": "2023-07-19T21:25:59.797157Z",
     "iopub.status.idle": "2023-07-19T21:25:59.799538Z",
     "shell.execute_reply": "2023-07-19T21:25:59.799136Z"
    }
   },
   "outputs": [],
   "source": [
    "acc_000 = []\n",
    "acc_001 = []\n",
    "acc_101 = []\n",
    "acc_111 = []\n",
    "M = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e84894",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.801412Z",
     "iopub.status.busy": "2023-07-19T21:25:59.801046Z",
     "iopub.status.idle": "2023-07-19T21:25:59.803408Z",
     "shell.execute_reply": "2023-07-19T21:25:59.803003Z"
    }
   },
   "outputs": [],
   "source": [
    "time1 = []\n",
    "time2 = []\n",
    "time3 = []\n",
    "time4 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db00272",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.805242Z",
     "iopub.status.busy": "2023-07-19T21:25:59.804911Z",
     "iopub.status.idle": "2023-07-19T21:25:59.807192Z",
     "shell.execute_reply": "2023-07-19T21:25:59.806785Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_000 = []\n",
    "sample_001 = []\n",
    "sample_101 = []\n",
    "sample_111 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5207593",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.809062Z",
     "iopub.status.busy": "2023-07-19T21:25:59.808731Z",
     "iopub.status.idle": "2023-07-19T21:25:59.811095Z",
     "shell.execute_reply": "2023-07-19T21:25:59.810658Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_range = [0.99, 0.98, 0.97, 0.96, 0.95, 0.94, 0.93, 0.92, 0.91, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902529ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T21:25:59.816602Z",
     "iopub.status.busy": "2023-07-19T21:25:59.816280Z",
     "iopub.status.idle": "2023-07-19T22:42:37.202409Z",
     "shell.execute_reply": "2023-07-19T22:42:37.201865Z"
    }
   },
   "outputs": [],
   "source": [
    "# setting: e1--000, e2--001, e3--101, e4--111\n",
    "# the proportion of gate we use are 1 for e1, 0.943 for e2, 0.801 for e3, and 0.736 for e4\n",
    "# then matrix approximation accuracy is 0.9998 for e2, 0.9999 for e3 and e4 (verify at the end of notebook)\n",
    "\n",
    "for loss in loss_range:\n",
    "    \n",
    "    # 000\n",
    "    start_time = time.time()\n",
    "    sample_list1, acc1 = graph_sampling_plus(G, density_dict, M, S, U, dec_list1, 0, len_list1, 12, 1, 1, 1, loss, '000:')\n",
    "    end_time = time.time()\n",
    "    execution_time1 = end_time - start_time\n",
    "    time1.append(execution_time1)\n",
    "    sample_000.append(sample_list1)\n",
    "    acc_000.append(acc1)\n",
    "    \n",
    "    # 001\n",
    "    start_time = time.time()\n",
    "    sample_list2, acc2 = graph_sampling_plus(G, density_dict, M, S, U, dec_list1, 0, len_list1, 12, 0.9711, 0.03, 100, loss, '001:')\n",
    "#     sample_list2, acc2 = graph_sampling_plus(G, density_dict, M, S, U, dec_list1, 0, len_list1, 12, 0.946, 0.2, 100, loss, '001:')\n",
    "    end_time = time.time()\n",
    "    execution_time2 = end_time - start_time\n",
    "    time2.append(execution_time2)\n",
    "    sample_001.append(sample_list2)\n",
    "    acc_001.append(acc2)\n",
    "    \n",
    "    # 101\n",
    "    start_time = time.time()\n",
    "    sample_list3, acc3 = graph_sampling_plus(G, density_dict, M, S, U, dec_list2, 0, len_list2, 12, 0.801, 0.025, 100, loss, '101:')\n",
    "    end_time = time.time()\n",
    "    execution_time3 = end_time - start_time\n",
    "    time3.append(execution_time3)\n",
    "    sample_101.append(sample_list3)\n",
    "    acc_101.append(acc3)\n",
    "    \n",
    "    # 111\n",
    "    start_time = time.time()\n",
    "    sample_list4, acc4 = graph_sampling_plus(G, density_dict, M, S, U, dec_list2, 1, len_list2, 7, 0.712, 0.03, 100, loss, '111:')\n",
    "    end_time = time.time()\n",
    "    execution_time4 = end_time - start_time\n",
    "    time4.append(execution_time4)\n",
    "    sample_111.append(sample_list4)\n",
    "    acc_111.append(acc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e4468e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa948e04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T22:42:37.340707Z",
     "iopub.status.busy": "2023-07-19T22:42:37.340425Z",
     "iopub.status.idle": "2023-07-19T22:42:37.343017Z",
     "shell.execute_reply": "2023-07-19T22:42:37.342601Z"
    }
   },
   "outputs": [],
   "source": [
    "# create path for sample_000\n",
    "path_sample_000 = 'sample_000.csv'\n",
    "# Open the file in write mode and create a CSV writer\n",
    "with open(path_sample_000, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the list as a single row in the CSV file\n",
    "    writer.writerow(sample_000)\n",
    "    \n",
    "# create path for sample_001\n",
    "path_sample_001 = 'sample_001.csv'\n",
    "# Open the file in write mode and create a CSV writer\n",
    "with open(path_sample_001, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the list as a single row in the CSV file\n",
    "    writer.writerow(sample_001)\n",
    "    \n",
    "# create path for sample_101\n",
    "path_sample_101 = 'sample_101.csv'\n",
    "# Open the file in write mode and create a CSV writer\n",
    "with open(path_sample_101, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the list as a single row in the CSV file\n",
    "    writer.writerow(sample_101)\n",
    "    \n",
    "# create path for sample_111\n",
    "path_sample_111 = 'sample_111.csv'\n",
    "# Open the file in write mode and create a CSV writer\n",
    "with open(path_sample_111, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the list as a single row in the CSV file\n",
    "    writer.writerow(sample_111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752cf8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8f58545",
   "metadata": {},
   "source": [
    "Calculate the JSD, picture 6 in max clique, Fig. 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f731f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jensen_shannon_divergence(p, q):\n",
    "    \"\"\"\n",
    "    Calculate the Jensen-Shannon Divergence (JSD) between two probability distributions.\n",
    "\n",
    "    Parameters:\n",
    "        p (numpy array): Probability distribution P as a 1D numpy array.\n",
    "        q (numpy array): Probability distribution Q as a 1D numpy array.\n",
    "\n",
    "    Returns:\n",
    "        float: The Jensen-Shannon Divergence (JSD) between P and Q in nats.\n",
    "    \"\"\"\n",
    "    # Ensure that the input arrays have the same length\n",
    "    if len(p) != len(q):\n",
    "        raise ValueError(\"Input arrays must have the same length.\")\n",
    "\n",
    "    # Normalize the input arrays to ensure they are valid probability distributions\n",
    "    p = p / np.sum(p)\n",
    "    q = q / np.sum(q)\n",
    "\n",
    "    # Calculate the average distribution (M) as the element-wise average of P and Q\n",
    "    m = 0.5 * (p + q)\n",
    "    \n",
    "    # Count the number of zero entries\n",
    "    zero_count = np.count_nonzero(m == 0)\n",
    "\n",
    "    # Print the result\n",
    "    if zero_count>0:\n",
    "        print('error: m has zero entry')\n",
    "\n",
    "\n",
    "    kl_pm = 0\n",
    "    for i, p_i in enumerate(p):\n",
    "        if p[i] != 0:\n",
    "            kl_pm = kl_pm + p[i]*np.log(p[i] / m[i])\n",
    "            \n",
    "    kl_qm = 0\n",
    "    for i, q_i in enumerate(q):\n",
    "        if q[i] != 0:\n",
    "            kl_qm = kl_qm + q[i]*np.log(q[i] / m[i])\n",
    "    \n",
    "\n",
    "    # Calculate the Jensen-Shannon Divergence (JSD) in nats\n",
    "    jsd = 0.5 * (kl_pm + kl_qm)\n",
    "\n",
    "    return jsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a34a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sample(sample):\n",
    "    # Remove 0 from the sample\n",
    "    sample_without_zeros = [element for element in sample if element != 0]\n",
    "    # Sort the sample in descending order\n",
    "    sorted_sample = sorted(sample_without_zeros, reverse=True)\n",
    "    return sorted_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e56c3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the element in base_sample and sample should be str\n",
    "def calculate_jsd(base_sample, sample):\n",
    "    \n",
    "    for i, s in enumerate(base_sample):\n",
    "        # Example string representing a list\n",
    "        string_representation = s\n",
    "\n",
    "        # Convert the string to a list using ast.literal_eval()\n",
    "        try:\n",
    "            result_list = ast.literal_eval(string_representation)\n",
    "        except ValueError as e:\n",
    "            # If the string is not a valid Python literal, handle the exception\n",
    "            print(f\"Error: {e}\")\n",
    "            result_list = None\n",
    "            \n",
    "        s = process_sample(result_list)\n",
    "        \n",
    "        string_list = str(s)\n",
    "        \n",
    "        base_sample[i] = string_list\n",
    "        \n",
    "    for i, s in enumerate(sample):\n",
    "        # Example string representing a list\n",
    "        string_representation = s\n",
    "\n",
    "        # Convert the string to a list using ast.literal_eval()\n",
    "        try:\n",
    "            result_list = ast.literal_eval(string_representation)\n",
    "        except ValueError as e:\n",
    "            # If the string is not a valid Python literal, handle the exception\n",
    "            print(f\"Error: {e}\")\n",
    "            result_list = None\n",
    "            \n",
    "        s = process_sample(result_list)\n",
    "        \n",
    "        string_list = str(s)\n",
    "        \n",
    "        sample[i] = string_list\n",
    "        \n",
    "        \n",
    "    \n",
    "    # Combine the two lists and convert to a set to remove duplicates\n",
    "    combined_set = set(base_sample + sample)\n",
    "\n",
    "    # Convert the set back to a list to get a distinct list\n",
    "    distinct_sample = list(combined_set)\n",
    "    \n",
    "    # Calculate the probability for base_sample\n",
    "    probability_list1 = []\n",
    "    total_elements1 = len(base_sample)\n",
    "    element_count1 = Counter(base_sample)\n",
    "    for element in distinct_sample:\n",
    "        occurrences = element_count1[element] if element in element_count1 else 0\n",
    "        probability = occurrences / total_elements1\n",
    "        probability_list1.append(probability)\n",
    "        \n",
    "    # Calculate the probability for sample\n",
    "    probability_list2 = []\n",
    "    total_elements2 = len(sample)\n",
    "    element_count2 = Counter(sample)\n",
    "    for element in distinct_sample:\n",
    "        occurrences = element_count2[element] if element in element_count2 else 0\n",
    "        probability = occurrences / total_elements2\n",
    "        probability_list2.append(probability) \n",
    "        \n",
    "    # Calculate the Jensen-Shannon Divergence (JSD) between P and Q\n",
    "    jsd_result = jensen_shannon_divergence(probability_list1, probability_list2)\n",
    "#     print(\"Jensen-Shannon Divergence:\", jsd_result)   \n",
    "    \n",
    "    return jsd_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02073b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the mean value for a group of 3 numbers\n",
    "def calculate_mean(group):\n",
    "    return sum(group) / len(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4c043f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9c3d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create path for base_sample\n",
    "path_sample_base = 'sample_base.csv'\n",
    "# Open the file in read mode and create a CSV reader\n",
    "with open(path_sample_base, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    # Read the first row from the CSV file\n",
    "    row = next(reader)\n",
    "\n",
    "    # Convert the row elements to integers (if needed)\n",
    "    sample_base_read = [element for element in row] \n",
    "    \n",
    "x_axis = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab63831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create path for sample\n",
    "path_sample = 'sample_000.csv'\n",
    "# Open the file in read mode and create a CSV reader\n",
    "with open(path_sample, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    # Read the first row from the CSV file\n",
    "    row = next(reader)\n",
    "\n",
    "    # Convert the row elements to integers (if needed)\n",
    "    sample_read1 = [element for element in row]\n",
    "    \n",
    "\n",
    "# create path for sample\n",
    "path_sample = 'sample_001.csv'\n",
    "# Open the file in read mode and create a CSV reader\n",
    "with open(path_sample, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    # Read the first row from the CSV file\n",
    "    row = next(reader)\n",
    "\n",
    "    # Convert the row elements to integers (if needed)\n",
    "    sample_read2 = [element for element in row]\n",
    "    \n",
    "# create path for sample\n",
    "path_sample = 'sample_101.csv'\n",
    "# Open the file in read mode and create a CSV reader\n",
    "with open(path_sample, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    # Read the first row from the CSV file\n",
    "    row = next(reader)\n",
    "\n",
    "    # Convert the row elements to integers (if needed)\n",
    "    sample_read3 = [element for element in row]\n",
    "    \n",
    "# create path for sample\n",
    "path_sample = 'sample_111.csv'\n",
    "# Open the file in read mode and create a CSV reader\n",
    "with open(path_sample, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    # Read the first row from the CSV file\n",
    "    row = next(reader)\n",
    "\n",
    "    # Convert the row elements to integers (if needed)\n",
    "    sample_read4 = [element for element in row]\n",
    "    \n",
    "    \n",
    "\n",
    "jsd1 = []\n",
    "\n",
    "for i, sample in enumerate(sample_read1):\n",
    "    \n",
    "    # Your string representation of the list of lists\n",
    "    string_representation = sample_read1[i]\n",
    "\n",
    "    # Convert the string to an actual list of lists\n",
    "    try:\n",
    "        list_of_lists = ast.literal_eval(string_representation)\n",
    "    except ValueError as e:\n",
    "        # If the string_representation is not a valid Python literal, ValueError will be raised.\n",
    "        print(\"Error:\", e)\n",
    "        list_of_lists = None\n",
    "    \n",
    "    string_list = [str(sub_list) for sub_list in list_of_lists]\n",
    "    \n",
    "    jsd = calculate_jsd(sample_base_read, string_list)\n",
    "    \n",
    "    jsd1.append(jsd)\n",
    "    \n",
    "#     print(jsd)\n",
    "    \n",
    "jsd2 = []\n",
    "\n",
    "for i, sample in enumerate(sample_read2):\n",
    "    \n",
    "    # Your string representation of the list of lists\n",
    "    string_representation = sample_read2[i]\n",
    "\n",
    "    # Convert the string to an actual list of lists\n",
    "    try:\n",
    "        list_of_lists = ast.literal_eval(string_representation)\n",
    "    except ValueError as e:\n",
    "        # If the string_representation is not a valid Python literal, ValueError will be raised.\n",
    "        print(\"Error:\", e)\n",
    "        list_of_lists = None\n",
    "    \n",
    "    string_list = [str(sub_list) for sub_list in list_of_lists]\n",
    "    \n",
    "    jsd = calculate_jsd(sample_base_read, string_list)\n",
    "    \n",
    "    jsd2.append(jsd)\n",
    "    \n",
    "#     print(jsd)\n",
    "    \n",
    "    \n",
    "jsd3 = []\n",
    "\n",
    "for i, sample in enumerate(sample_read3):\n",
    "    \n",
    "    # Your string representation of the list of lists\n",
    "    string_representation = sample_read3[i]\n",
    "\n",
    "    # Convert the string to an actual list of lists\n",
    "    try:\n",
    "        list_of_lists = ast.literal_eval(string_representation)\n",
    "    except ValueError as e:\n",
    "        # If the string_representation is not a valid Python literal, ValueError will be raised.\n",
    "        print(\"Error:\", e)\n",
    "        list_of_lists = None\n",
    "    \n",
    "    string_list = [str(sub_list) for sub_list in list_of_lists]\n",
    "    \n",
    "    jsd = calculate_jsd(sample_base_read, string_list)\n",
    "    \n",
    "    jsd3.append(jsd)\n",
    "    \n",
    "#     print(jsd)\n",
    "    \n",
    "    \n",
    "    \n",
    "jsd4 = []\n",
    "\n",
    "for i, sample in enumerate(sample_read4):\n",
    "    \n",
    "    # Your string representation of the list of lists\n",
    "    string_representation = sample_read4[i]\n",
    "\n",
    "    # Convert the string to an actual list of lists\n",
    "    try:\n",
    "        list_of_lists = ast.literal_eval(string_representation)\n",
    "    except ValueError as e:\n",
    "        # If the string_representation is not a valid Python literal, ValueError will be raised.\n",
    "        print(\"Error:\", e)\n",
    "        list_of_lists = None\n",
    "    \n",
    "    string_list = [str(sub_list) for sub_list in list_of_lists]\n",
    "    \n",
    "    jsd = calculate_jsd(sample_base_read, string_list)\n",
    "    \n",
    "    jsd4.append(jsd)\n",
    "    \n",
    "    \n",
    "plt.figure(figsize=(8, 4))    \n",
    "    \n",
    "# Plot data on each subplot\n",
    "plt.plot(x_axis, jsd1, color='blue', label='baseline', marker='x', markersize=16, linewidth=1)\n",
    "plt.plot(x_axis, jsd2, color='green', label='rotation-cut', marker='^', markersize=16, linewidth=1)\n",
    "plt.plot(x_axis, jsd3, color='orange', label='decomposition-opt', marker='o', markersize=16, linewidth=1)\n",
    "plt.plot(x_axis, jsd4, color='red', label='full-opt', marker='s', markersize=16, linewidth=1)\n",
    "# plt.set_title('6by6 structure', fontsize=15)\n",
    "# plt.xlabel('loss', fontsize=15)\n",
    "# plt.ylabel('JSD-dense', fontsize=15)\n",
    "plt.tick_params(axis='x', labelsize=28)\n",
    "plt.tick_params(axis='y', labelsize=28)\n",
    "# Hide the tick labels on both x and y axes\n",
    "# plt.xticks([])\n",
    "# plt.yticks([])\n",
    "# axs[0, 0].legend(fontsize=12, loc='lower left')  # Set the fontsize for the legend labels to 12\n",
    "# plt.gca().invert_yaxis()  # Invert the y-axis\n",
    "# plt.legend(loc='lower left', fontsize=16)\n",
    "\n",
    "# Save the plot as a PDF\n",
    "output_filename = 'Fig 11.svg.svg'\n",
    "plt.savefig(output_filename, format='svg', bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4587cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426a06ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b66cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbd7c251",
   "metadata": {},
   "source": [
    "Calculate the approximation accuracy for the four experiment settings, this is just a verification to show our gate drop ratio is reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af64231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unitary_accuracy(1000, U, dec_list1, 0, len_list1, 12, 1, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4bd0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "unitary_accuracy(1000, U, dec_list1, 0, len_list1, 12, 0.9711, 0.03, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec58d62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unitary_accuracy(1000, U, dec_list2, 0, len_list2, 12, 0.801, 0.025, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed46c6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "unitary_accuracy(1000, U, dec_list2, 1, len_list2, 7, 0.712, 0.03, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a92797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
