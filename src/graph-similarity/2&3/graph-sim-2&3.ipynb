{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69faafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "default_n_threads = 8\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = f\"{default_n_threads}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fb3a3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:00.922197Z",
     "iopub.status.busy": "2023-08-01T20:55:00.921831Z",
     "iopub.status.idle": "2023-08-01T20:55:01.869357Z",
     "shell.execute_reply": "2023-08-01T20:55:01.868730Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import ast\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import strawberryfields as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.io as pio\n",
    "from collections import Counter\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from scipy.optimize import fsolve\n",
    "from strawberryfields import ops\n",
    "from itertools import combinations\n",
    "from strawberryfields.apps import data, qchem, plot\n",
    "from strawberryfields.utils import random_interferometer\n",
    "from strawberryfields.apps.similarity import feature_vector_orbits_sampling\n",
    "from collections import Counter\n",
    "csv.field_size_limit(500 * 1024 * 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba78470",
   "metadata": {},
   "source": [
    "Step1: Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e53b11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:01.872117Z",
     "iopub.status.busy": "2023-08-01T20:55:01.871814Z",
     "iopub.status.idle": "2023-08-01T20:55:01.876127Z",
     "shell.execute_reply": "2023-08-01T20:55:01.875595Z"
    }
   },
   "outputs": [],
   "source": [
    "# function that take a raw matrix and k (number of columns) and n (the nth number you want to compare) value in, return the best k columns\n",
    "def find_best_k_combination(matrix, k, n):\n",
    "    # get all possible combination\n",
    "    num_columns = matrix.shape[1]\n",
    "    column_combinations = combinations(range(num_columns), k)\n",
    "        \n",
    "#     column_combinations = get_column_combinations(matrix, k)\n",
    "    \n",
    "    strength = []\n",
    "    Combination = []\n",
    "\n",
    "    for combination in column_combinations:\n",
    "        Combination.append(combination)\n",
    "        selected_columns = matrix[:, combination]\n",
    "        # calculate the row abs square sum\n",
    "        row_sums = np.sum(np.abs(selected_columns) ** 2, axis=1)\n",
    "        # make it decrease\n",
    "        sorted_indices = np.argsort(row_sums)[::-1]\n",
    "        sorted_row_sums = row_sums[sorted_indices]\n",
    "        val = sorted_row_sums[n-1]\n",
    "        strength.append(val)\n",
    "\n",
    "    largest_value = np.max(strength)\n",
    "    largest_index = np.argmax(strength)\n",
    "\n",
    "    # find the best combination\n",
    "    best_combination = Combination[largest_index]\n",
    "    best_selected_columns = matrix[:, best_combination]\n",
    "\n",
    "    return best_selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacea0bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:01.878051Z",
     "iopub.status.busy": "2023-08-01T20:55:01.877862Z",
     "iopub.status.idle": "2023-08-01T20:55:01.886081Z",
     "shell.execute_reply": "2023-08-01T20:55:01.885571Z"
    }
   },
   "outputs": [],
   "source": [
    "# final function, recieve the original matrix and a list of len, also n (the nth number you want to compare), return the permuted matrix\n",
    "# U = row_per_matrix*U'*col_per_matrix\n",
    "def mapping(U, len_list, n):\n",
    "    \n",
    "    M, N = U.shape\n",
    "    total_len = sum(len_list)\n",
    "    assert N == total_len\n",
    "    \n",
    "    # copy U\n",
    "    U_t = U.copy()\n",
    "#     print(U)\n",
    "    \n",
    "    # new column permutation\n",
    "    for i, length in enumerate(len_list):\n",
    "        if i<len(len_list)-1:\n",
    "            U_new = U_t[:,:length].copy()\n",
    "#             print(\"i:\", i)\n",
    "            # calculate the row abs square sum\n",
    "            row_sums = np.sum(np.abs(U_new) ** 2, axis=1)\n",
    "            U_new_update = U_new.copy()\n",
    "            # iterate remain column\n",
    "            for j in range(np.sum(len_list[i+1:])):\n",
    "#                 print(\"j:\", j)\n",
    "                for k in range(length):\n",
    "#                     print(\"k:\", k)\n",
    "                    U_new_update_k = U_new_update[:,k].copy()\n",
    "                    U_new_update[:,k] = U_t[:,length+j].copy()\n",
    "                    # calculate the row abs square sum\n",
    "                    row_sums_update = np.sum(np.abs(U_new_update) ** 2, axis=1)\n",
    "                \n",
    "                    if np.sort(row_sums_update)[::-1][n-1] > np.sort(row_sums)[::-1][n-1]:\n",
    "#                     row_sums_update[n-1] > row_sums[n-1]:\n",
    "                        U_new = U_new_update.copy()\n",
    "                        U_t[:,length+j] = U_new_update_k.copy()\n",
    "                        U_t[:,:length] = U_new.copy()\n",
    "                        row_sums = row_sums_update\n",
    "                    else:\n",
    "                        U_new_update = U_new.copy()\n",
    "\n",
    "            \n",
    "            # add U_new to U_per\n",
    "            if i==0:\n",
    "                U_per = U_new.copy()\n",
    "            elif i==len(len_list)-2:\n",
    "                U_per = np.hstack((U_per, U_t)).copy()\n",
    "            else:\n",
    "                U_per = np.hstack((U_per, U_new)).copy()\n",
    "\n",
    "            \n",
    "            # drop U_new from U_t\n",
    "            U_t = U_t[:,length:].copy()\n",
    "        \n",
    "                    \n",
    "\n",
    "#     for i, length in enumerate(len_list):\n",
    "#         U_new = find_best_k_combination(U_t, length, n)\n",
    "        \n",
    "#         # Find column indices in the larger matrix corresponding to the smaller matrix\n",
    "#         selected_columns = []\n",
    "#         for col in range(U_new.shape[1]):\n",
    "#             for j in range(U_t.shape[1]):\n",
    "#                 if np.array_equal(U_new[:, col], U_t[:, j]):\n",
    "#                     selected_columns.append(j)\n",
    "#                     break\n",
    "\n",
    "#         # drop U_new from U_t\n",
    "#         U_t = np.delete(U_t, selected_columns, axis=1)\n",
    "        \n",
    "#         # add U_new to U_per\n",
    "#         if i==0:\n",
    "#             U_per = U_new\n",
    "#         else:\n",
    "#             U_per = np.hstack((U_per, U_new))\n",
    "      \n",
    "      \n",
    "    # find the permutation from U_per to U\n",
    "    col_permutation = []\n",
    "    for col in range(U_per.shape[1]):\n",
    "        for i in range(U.shape[1]):\n",
    "            if np.array_equal(U_per[:, col], U[:, i]):\n",
    "                col_permutation.append(i)\n",
    "                break\n",
    "                \n",
    "    # find the columns permutation matrix\n",
    "    col_per_matrix = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        col_per_matrix[col_permutation[i], i] = 1\n",
    "        \n",
    "\n",
    "\n",
    "    # calculate the sum of first len for U_per\n",
    "    selected_columns = U_per[:, :len_list[0]] \n",
    "    # calculate the row abs square sum\n",
    "    row_sums = np.sum(np.abs(selected_columns) ** 2, axis=1)\n",
    "    \n",
    "    # decide the row rotation\n",
    "    sorted_indices = np.argsort(row_sums)\n",
    "    U_per_new = U_per[sorted_indices]\n",
    "    \n",
    "    # Find row permutation\n",
    "    row_permutation = []\n",
    "    for row in range(U_per_new.shape[0]):\n",
    "        for i in range(U_per.shape[0]):\n",
    "            if np.array_equal(U_per_new[row, :], U_per[i, :]):\n",
    "                row_permutation.append(i)\n",
    "                break\n",
    "                \n",
    "    # find the rows permutation matrix\n",
    "    row_per_matrix = np.zeros((M, M))\n",
    "    for i in range(M):\n",
    "        row_per_matrix[i, row_permutation[i]] = 1\n",
    "        \n",
    "    \n",
    "    U_final = U_per_new\n",
    "    \n",
    "    # U_final = U_per, out put U_final and the permutation\n",
    "    return U_final, col_per_matrix.T, row_per_matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552d9a09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "548f1c1d",
   "metadata": {},
   "source": [
    "Step2: Matrix Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82af31b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:01.888237Z",
     "iopub.status.busy": "2023-08-01T20:55:01.887868Z",
     "iopub.status.idle": "2023-08-01T20:55:01.893129Z",
     "shell.execute_reply": "2023-08-01T20:55:01.892630Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the left eliminate equations\n",
    "def left_equations(variables,parameters):\n",
    "    theta, phi = variables\n",
    "    a_r, a_i, b_r, b_i = parameters\n",
    "    eq1 = a_r * np.cos(phi) * np.cos(theta) + a_i * np.sin(phi) * np.cos(theta) - b_r * np.sin(theta)\n",
    "    eq2 = a_i * np.cos(phi) * np.cos(theta) - a_r * np.sin(phi) * np.cos(theta) - b_i * np.sin(theta)\n",
    "    return [eq1, eq2]\n",
    "\n",
    "# function of left elimination\n",
    "def left_elimination(a,b):\n",
    "    a_r = np.real(a)\n",
    "    a_i = np.imag(a)\n",
    "    b_r = np.real(b)\n",
    "    b_i = np.imag(b)\n",
    "    \n",
    "    # Solve the system of equations\n",
    "    initial_guess = [0, 0]  # Initial guess for the variables\n",
    "    parameters = [a_r, a_i, b_r, b_i]\n",
    "    raw_solution = fsolve(left_equations, initial_guess, args=(parameters,))\n",
    "    \n",
    "    \n",
    "    if np.abs(a_r) < 1e-8 and np.abs(b_i) < 1e-8:\n",
    "            raw_solution = [np.arctan(a_i/b_r), np.pi/2]\n",
    "        \n",
    "    if np.abs(a_i) < 1e-8 and np.abs(b_r) < 1e-8:\n",
    "            raw_solution = [np.arctan(-a_r/b_i), np.pi/2]\n",
    "            \n",
    "            \n",
    "    if np.abs(b_r) < 1e-8 and np.abs(b_i) < 1e-8:\n",
    "            raw_solution = [np.pi/2, 0]\n",
    "    \n",
    "    \n",
    "    normalized_solution = [angle % (2 * np.pi) for angle in raw_solution]\n",
    "    solution = []\n",
    "    for angle in normalized_solution:\n",
    "        if angle < np.pi:\n",
    "            solution.append(angle)\n",
    "        else:\n",
    "            solution.append(angle-2*np.pi)\n",
    "\n",
    "    # Print the solution\n",
    "#     print(\"Solution:\", solution)\n",
    "    return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5493f4e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:01.895025Z",
     "iopub.status.busy": "2023-08-01T20:55:01.894774Z",
     "iopub.status.idle": "2023-08-01T20:55:01.899958Z",
     "shell.execute_reply": "2023-08-01T20:55:01.899464Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the right eliminate equations\n",
    "def right_equations(variables,parameters):\n",
    "    theta, phi = variables\n",
    "    a_r, a_i, b_r, b_i = parameters\n",
    "    eq1 = a_r * np.cos(phi) * np.sin(theta) + a_i * np.sin(phi) * np.sin(theta) + b_r * np.cos(theta)\n",
    "    eq2 = a_i * np.cos(phi) * np.sin(theta) - a_r * np.sin(phi) * np.sin(theta) + b_i * np.cos(theta)\n",
    "    return [eq1, eq2]\n",
    "\n",
    "# function of right elimination\n",
    "def right_elimination(a,b):\n",
    "    a_r = np.real(a)\n",
    "    a_i = np.imag(a)\n",
    "    b_r = np.real(b)\n",
    "    b_i = np.imag(b)\n",
    "    \n",
    "    # Solve the system of equations\n",
    "    initial_guess = [0, 0]  # Initial guess for the variables\n",
    "    parameters = [a_r, a_i, b_r, b_i]\n",
    "    raw_solution = fsolve(right_equations, initial_guess, args=(parameters,))\n",
    "    \n",
    "    if np.abs(a_r) < 1e-8 and np.abs(b_i) < 1e-8:\n",
    "        raw_solution = [np.arctan(-b_r/a_i), np.pi/2]\n",
    "        \n",
    "    if np.abs(a_i) < 1e-8 and np.abs(b_r) < 1e-8:\n",
    "        raw_solution = [np.arctan(b_i/a_r), np.pi/2]\n",
    "        \n",
    "    if np.abs(a_r) < 1e-8 and np.abs(a_i) < 1e-8:\n",
    "        raw_solution = [np.pi/2, 0]\n",
    "    \n",
    "    normalized_solution = [angle % (2 * np.pi) for angle in raw_solution]\n",
    "    solution = []\n",
    "    for angle in normalized_solution:\n",
    "        if angle < np.pi:\n",
    "            solution.append(angle)\n",
    "        else:\n",
    "            solution.append(angle-2*np.pi)\n",
    "\n",
    "    # Print the solution\n",
    "#     print(\"Solution:\", solution)\n",
    "    return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c8290b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:01.901800Z",
     "iopub.status.busy": "2023-08-01T20:55:01.901617Z",
     "iopub.status.idle": "2023-08-01T20:55:01.904848Z",
     "shell.execute_reply": "2023-08-01T20:55:01.904343Z"
    }
   },
   "outputs": [],
   "source": [
    "# give rotation matrix with idx_1 < idx_2\n",
    "def rotation(theta, phi, n, idx_1, idx_2):\n",
    "    I = np.eye(n, dtype=complex)\n",
    "    I[idx_1,idx_1] = np.cos(theta)*(np.cos(phi)-np.sin(phi)*1j)\n",
    "    I[idx_1,idx_2] = np.sin(theta)*(np.cos(phi)-np.sin(phi)*1j)\n",
    "    I[idx_2,idx_1] = -np.sin(theta)\n",
    "    I[idx_2,idx_2] = np.cos(theta)\n",
    "    \n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d024604b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:01.906727Z",
     "iopub.status.busy": "2023-08-01T20:55:01.906551Z",
     "iopub.status.idle": "2023-08-01T20:55:01.909969Z",
     "shell.execute_reply": "2023-08-01T20:55:01.909453Z"
    }
   },
   "outputs": [],
   "source": [
    "# matrix permutation\n",
    "def permutation(U):\n",
    "    \n",
    "    rows, columns = U.shape\n",
    "    assert(rows==columns)\n",
    "    \n",
    "    # create the permutation matrix\n",
    "    Permutation = np.zeros([rows,columns])\n",
    "    \n",
    "    diag_U = np.eye(rows, dtype=complex)\n",
    "    \n",
    "    indices = np.nonzero(U)\n",
    "    row_info = indices[0]\n",
    "    col_info = indices[1]\n",
    "    \n",
    "    for i in range(rows):\n",
    "        col = col_info[i]\n",
    "        row = row_info[i]\n",
    "        diag_U[col,:] = U[row,:]\n",
    "        Permutation[col,row] = 1\n",
    "        \n",
    "    return diag_U, Permutation.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0854916",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:01.911786Z",
     "iopub.status.busy": "2023-08-01T20:55:01.911609Z",
     "iopub.status.idle": "2023-08-01T20:55:01.914666Z",
     "shell.execute_reply": "2023-08-01T20:55:01.914176Z"
    }
   },
   "outputs": [],
   "source": [
    "def phase(x):\n",
    "    x_r = np.real(x)\n",
    "    x_i = np.imag(x)\n",
    "    \n",
    "    raw_phi = np.arccos(x_r)\n",
    "    if x_i > 0:\n",
    "        t_phi = raw_phi\n",
    "    else:\n",
    "        t_phi = -raw_phi\n",
    "        \n",
    "    normalized_solution = t_phi % (2 * np.pi)\n",
    "    if normalized_solution > np.pi:\n",
    "        normalized_solution = normalized_solution-2*np.pi\n",
    "\n",
    "    return normalized_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff424f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:01.916526Z",
     "iopub.status.busy": "2023-08-01T20:55:01.916348Z",
     "iopub.status.idle": "2023-08-01T20:55:01.923040Z",
     "shell.execute_reply": "2023-08-01T20:55:01.922534Z"
    }
   },
   "outputs": [],
   "source": [
    "# the all_list tell the decomposition order\n",
    "# [[1,2], [2,3], [3,4]] means first use 2 eliminate 1, then use 3 eliminate 2, then use 4 eliminate 3\n",
    "def U_decompose_plus(U, all_list):\n",
    "    \n",
    "    # pick up a machine precision\n",
    "    threshold = 1e-8\n",
    "    \n",
    "    # get the shape of unitary\n",
    "    rows, columns = U.shape\n",
    "    assert(rows==columns)\n",
    "    \n",
    "    # create the rotation record matrix, the first row for theta, the second row for phi \n",
    "    # third row for low index, forth row for high index\n",
    "    Theta = []\n",
    "    Phi = []\n",
    "    Low_idx = []\n",
    "    High_idx = []\n",
    "    \n",
    "    # create the diagonal record matrix\n",
    "    Diag = []\n",
    "    \n",
    "\n",
    "    for i in range(rows-1, 0, -1):\n",
    "        list_i = all_list[i-1]\n",
    "        row = U[i, :]\n",
    "        \n",
    "        for j in range(i):\n",
    "            pair = list_i[j]\n",
    "            \n",
    "            \n",
    "            # a is the number to be eliminated, b is the number to eliminate the previous one\n",
    "            a = row[pair[0]]\n",
    "            b = row[pair[1]]\n",
    "            \n",
    "            \n",
    "#             if i % 3 != 0:\n",
    "#                 if j == i-1:\n",
    "#                     a = row[pair[1]]\n",
    "#                     b = row[pair[0]]\n",
    "                \n",
    "                \n",
    "            # choose the elimination method by position\n",
    "            if pair[0] < pair[1]: \n",
    "                theta, phi = left_elimination(a,b)\n",
    "\n",
    "                # write down the parameter\n",
    "                Theta.append(theta)\n",
    "                Phi.append(phi)\n",
    "                Low_idx.append(pair[0])\n",
    "                High_idx.append(pair[1])\n",
    "\n",
    "                # create the rotation\n",
    "                r = rotation(theta, phi, rows, pair[0], pair[1])\n",
    "        \n",
    "\n",
    "                # update Unitary\n",
    "                U = np.dot(U, r)\n",
    "                U= np.where(np.abs(U) < threshold, 0, U)\n",
    "\n",
    "            else:\n",
    "                theta, phi = right_elimination(b,a)\n",
    "\n",
    "                # write down the parameter\n",
    "                Theta.append(theta)\n",
    "                Phi.append(phi)\n",
    "                Low_idx.append(pair[1])\n",
    "                High_idx.append(pair[0])\n",
    "\n",
    "                # create the rotation\n",
    "                r = rotation(theta, phi, rows, pair[1], pair[0])\n",
    "\n",
    "                # update Unitary\n",
    "                U = np.dot(U, r)\n",
    "                U= np.where(np.abs(U) < threshold, 0, U)\n",
    "\n",
    "            row = U[i, :]\n",
    "            \n",
    "#             if (np.count_nonzero(row) == 1):\n",
    "            if j == i-1:\n",
    "                entry = U[i, pair[1]]\n",
    "                U[:, pair[1]] = 0\n",
    "                U[i, :] = 0\n",
    "                U[i, pair[1]] = entry\n",
    "                flag = 0\n",
    "    \n",
    "    # do the permutation, and record\n",
    "    U, Permutation = permutation(U)\n",
    "    \n",
    "    # find the phase shift\n",
    "    for i in range(rows):\n",
    "        x = U[i,i]/np.abs(U[i,i])\n",
    "        phi_x = phase(x)\n",
    "        Diag.append(phi_x)\n",
    "        U[i,i] = U[i,i]*(np.cos(phi_x)-np.sin(phi_x)*1j)\n",
    "    \n",
    "    \n",
    "    return U, Theta, Phi, Low_idx, High_idx, Diag, Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1d7929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c797e2d",
   "metadata": {},
   "source": [
    "Step3: gate drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87465142",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:01.925055Z",
     "iopub.status.busy": "2023-08-01T20:55:01.924802Z",
     "iopub.status.idle": "2023-08-01T20:55:01.927590Z",
     "shell.execute_reply": "2023-08-01T20:55:01.927070Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step1 probability\n",
    "def calculate_probability_sequence(angles, threshold, N):\n",
    "    abs_angles = np.abs(angles)\n",
    "    angles1 = abs_angles/(threshold)\n",
    "    angles2 = angles1**N\n",
    "    total_magnitude = np.sum(angles2)\n",
    "    probabilities = angles2 / total_magnitude\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867c0332",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:01.929336Z",
     "iopub.status.busy": "2023-08-01T20:55:01.929085Z",
     "iopub.status.idle": "2023-08-01T20:55:01.932862Z",
     "shell.execute_reply": "2023-08-01T20:55:01.932358Z"
    }
   },
   "outputs": [],
   "source": [
    "# sequence is the origianl angel sequence, probability is calculate using calculate_probability_sequence(angles), percentage is the proportion you want to preserve\n",
    "def pick_entries_with_indices(sequence, probabilities, proportion):\n",
    "    \n",
    "    N = len(sequence)\n",
    "    num_entries = np.floor(N*proportion).astype(int)\n",
    "    \n",
    "    idx_sequence = np.arange(N).astype(int)\n",
    "    \n",
    "    if np.count_nonzero(sequence) < num_entries:\n",
    "        num_entries = np.count_nonzero(sequence)\n",
    "    \n",
    "    picked_indices = np.random.choice(idx_sequence, size=num_entries, replace=False, p=probabilities)\n",
    "    picked_entries = [sequence[index] for index in picked_indices]\n",
    "\n",
    "    # Sort the picked entries and indices based on the indices\n",
    "    picked_entries, picked_indices = zip(*sorted(zip(picked_entries, picked_indices), key=lambda x: x[1]))\n",
    "    \n",
    "    modified_sequence = [entry if index in picked_indices else 0 for index, entry in enumerate(sequence)]\n",
    "\n",
    "    return modified_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e8217c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22b271e9",
   "metadata": {},
   "source": [
    "Step4: Matric Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30f9083",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:01.934977Z",
     "iopub.status.busy": "2023-08-01T20:55:01.934609Z",
     "iopub.status.idle": "2023-08-01T20:55:01.937457Z",
     "shell.execute_reply": "2023-08-01T20:55:01.936953Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_entries_zero(Array, threshold):\n",
    "    array = Array.copy()\n",
    "    for i in range(len(array)):\n",
    "        if np.abs(array[i]) < threshold:\n",
    "            array[i] = 0\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6029d275",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:01.939288Z",
     "iopub.status.busy": "2023-08-01T20:55:01.939018Z",
     "iopub.status.idle": "2023-08-01T20:55:01.942232Z",
     "shell.execute_reply": "2023-08-01T20:55:01.941734Z"
    }
   },
   "outputs": [],
   "source": [
    "# give rotation matrix with idx_1 < idx_2\n",
    "def reconstruct_rotation(theta, phi, n, idx_1, idx_2):\n",
    "    I = np.eye(n, dtype=complex)\n",
    "    I[idx_1,idx_1] = np.cos(theta)*(np.cos(phi)+np.sin(phi)*1j)\n",
    "    I[idx_1,idx_2] = -np.sin(theta)\n",
    "    I[idx_2,idx_1] = np.sin(theta)*(np.cos(phi)+np.sin(phi)*1j)\n",
    "    I[idx_2,idx_2] = np.cos(theta)\n",
    "    \n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95103d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:01.944221Z",
     "iopub.status.busy": "2023-08-01T20:55:01.943847Z",
     "iopub.status.idle": "2023-08-01T20:55:01.947920Z",
     "shell.execute_reply": "2023-08-01T20:55:01.947412Z"
    }
   },
   "outputs": [],
   "source": [
    "def matrix_reconstruct(Theta, Phi, Low_idx, High_idx, Diag, Permutation, N):\n",
    "    \n",
    "    M = len(Theta)\n",
    "    \n",
    "    per_theta = (len([x for x in Theta if np.abs(x) == 0]) / len(Theta)) * 100\n",
    "#     print(\"theta reduce\")\n",
    "#     print(per_theta)\n",
    "    \n",
    "    per_phi = (len([x for x in Phi if np.abs(x) == 0]) / len(Phi)) * 100\n",
    "#     print(\"phi reduce\")\n",
    "#     print(per_phi)\n",
    "\n",
    "#     new_theta = Theta\n",
    "#     new_phi = Phi\n",
    "    \n",
    "    V = np.eye(N, dtype=complex)\n",
    "    \n",
    "    # rotation\n",
    "    for i in range(M):\n",
    "        r = reconstruct_rotation(Theta[i], Phi[i], N, Low_idx[i], High_idx[i])\n",
    "        V = np.dot(r, V)\n",
    "        \n",
    "    # phase shift\n",
    "    for i in range(N):\n",
    "        V[i,:] = V[i,:]*(np.cos(Diag[i])+np.sin(Diag[i])*1j)\n",
    "        \n",
    "    # permutation\n",
    "    V = np.dot(Permutation, V)\n",
    "    \n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e40086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9062bfeb",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23772846",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:01.949951Z",
     "iopub.status.busy": "2023-08-01T20:55:01.949682Z",
     "iopub.status.idle": "2023-08-01T20:55:01.952419Z",
     "shell.execute_reply": "2023-08-01T20:55:01.951916Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to calculate the approximation accuracy\n",
    "def accuracy(U,U_app):\n",
    "    I = np.dot(U,np.conjugate(U_app).transpose())\n",
    "    N, N = I.shape\n",
    "    acc = np.trace(I)/N\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a49292",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:01.954154Z",
     "iopub.status.busy": "2023-08-01T20:55:01.953975Z",
     "iopub.status.idle": "2023-08-01T20:55:01.956512Z",
     "shell.execute_reply": "2023-08-01T20:55:01.956011Z"
    }
   },
   "outputs": [],
   "source": [
    "def distance_between_vectors(v1, v2):\n",
    "    distance = np.linalg.norm(v1 - v2)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d5de89",
   "metadata": {},
   "source": [
    "Reduce counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9b6b62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:01.958280Z",
     "iopub.status.busy": "2023-08-01T20:55:01.958013Z",
     "iopub.status.idle": "2023-08-01T20:55:01.960695Z",
     "shell.execute_reply": "2023-08-01T20:55:01.960199Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_numbers_less_than(numbers, threshold):\n",
    "    count = 0\n",
    "    for number in numbers:\n",
    "        if np.abs(number) < threshold:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bdbd1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c13abb6",
   "metadata": {},
   "source": [
    "Step5: Sampling Vibrational Molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5783991",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:01.962636Z",
     "iopub.status.busy": "2023-08-01T20:55:01.962271Z",
     "iopub.status.idle": "2023-08-01T20:55:01.971150Z",
     "shell.execute_reply": "2023-08-01T20:55:01.970642Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the sampleing function\n",
    "# M is the total sampling numbers\n",
    "# r, U2, alpha is the transition matrix, since Temperature is zero array\n",
    "# dec_list: a list give the decomposition order  \n",
    "# mapping: \"on\" or \"off\", coreesponding to 1 or 0\n",
    "# len_list: a list for mapping\n",
    "# n: a compare number for mapping\n",
    "# all_modes: (q[0], ..., q[N-1])\n",
    "# proportion: 0~1 for U2\n",
    "# loss is the photon number loss\n",
    "# qdrift_kind: 0: defualt, 1:cut\n",
    "def vibration_sampling_plus(M, S, S_model, U, dec_list, maps, len_list, n, proportion, threshold, N, loss):\n",
    "    \n",
    "    N, N = U.shape\n",
    "    \n",
    "    S_max = np.max(S)\n",
    "    S = S/(S_max+S_model)\n",
    "    S = np.arctanh(S)\n",
    "\n",
    "    \n",
    "    # mapping\n",
    "    if maps:\n",
    "        U_map, col_per_matrix, row_per_matrix = mapping(U, len_list, n)\n",
    "    else:\n",
    "        U_map = U\n",
    "        col_per_matrix = np.eye(N)\n",
    "        row_per_matrix = np.eye(N)\n",
    "    \n",
    "    # get the decomposition information of U\n",
    "    _, Theta, Phi, Low_idx, High_idx, Diag, Permutation = U_decompose_plus(U_map, dec_list)\n",
    "    \n",
    "    # modify Theta\n",
    "    Theta_prob = calculate_probability_sequence(Theta, threshold, N)\n",
    "    \n",
    "    \n",
    "    k = 0\n",
    "    sample = []\n",
    "    acc = []\n",
    "    while k < M:\n",
    "#         if k % 1 == 0:\n",
    "#             print(k)\n",
    "        \n",
    "        # get the new Theta from the probability distribution\n",
    "        new_Theta = pick_entries_with_indices(Theta, Theta_prob, proportion)\n",
    "        new_Phi = Phi\n",
    "        \n",
    "        # reconstruction of U using new angel\n",
    "        U_map_app = matrix_reconstruct(new_Theta, new_Phi, Low_idx, High_idx, Diag, Permutation, N)\n",
    "        # approximation accuracy\n",
    "        acc_t = accuracy(U_map,U_map_app)\n",
    "        acc.append(acc_t)\n",
    "        \n",
    "\n",
    "#         print(\"here\")\n",
    "        # construct the circuit\n",
    "        prog = sf.Program(N)\n",
    "        eng = sf.Engine('gaussian')\n",
    "        with prog.context as q:\n",
    "            \n",
    "            # r squeezing\n",
    "            for i, s in enumerate(S):\n",
    "                ops.Sgate(s) | q[i]\n",
    "            \n",
    "            # mapping's column transformation\n",
    "            ops.Interferometer(col_per_matrix) | (q[0], q[1], q[2], q[3], q[4], q[5], q[6], q[7], q[8], q[9], q[10], q[11], q[12], q[13], q[14], q[15], q[16], q[17], q[18], q[19], q[20], q[21], q[22], q[23])\n",
    "            \n",
    "            \n",
    "            # interferometer U\n",
    "            for i in range(len(new_Theta)):\n",
    "                ops.Rgate(new_Phi[i])       | q[Low_idx[i]]\n",
    "                ops.BSgate(new_Theta[i], 0) | (q[Low_idx[i]], q[High_idx[i]])\n",
    "                if np.abs(new_Theta[i]) > 0:\n",
    "                    ops.LossChannel(loss) | q[Low_idx[i]]\n",
    "                    ops.LossChannel(loss) | q[High_idx[i]]\n",
    "                \n",
    "            for i in range(N):\n",
    "                ops.Rgate(Diag[i])       | q[i]\n",
    "                \n",
    "                \n",
    "            # mapping's row transformation\n",
    "            ops.Interferometer(row_per_matrix) | (q[0], q[1], q[2], q[3], q[4], q[5], q[6], q[7], q[8], q[9], q[10], q[11], q[12], q[13], q[14], q[15], q[16], q[17], q[18], q[19], q[20], q[21], q[22], q[23])\n",
    "            \n",
    "            \n",
    "            # measurement\n",
    "            ops.MeasureFock() | q\n",
    "            \n",
    "\n",
    "        \n",
    "        results = eng.run(prog, shots=1)\n",
    "        sample_t = results.samples\n",
    "        sample.append(sample_t[0])\n",
    "#         print(\"here\")\n",
    "        \n",
    "        k = k+1\n",
    "    \n",
    "    # manipulate the samples\n",
    "    zero = np.zeros(N)\n",
    "    for i in range(len(sample)):\n",
    "        sample[i] = np.concatenate((sample[i], zero))\n",
    "    sample_list = []\n",
    "    for a in sample:\n",
    "        b = list(a)\n",
    "        c = [int(num) for num in b]\n",
    "        sample_list.append(c)\n",
    "\n",
    "    acc_mean = np.mean(acc)\n",
    "#     print(\"mean accuracy for U:\", acc_mean)\n",
    "        \n",
    "    return sample_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb05634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da89711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bed94841",
   "metadata": {},
   "source": [
    "dec_list1: 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d639998d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:01.973306Z",
     "iopub.status.busy": "2023-08-01T20:55:01.972931Z",
     "iopub.status.idle": "2023-08-01T20:55:01.976433Z",
     "shell.execute_reply": "2023-08-01T20:55:01.975930Z"
    }
   },
   "outputs": [],
   "source": [
    "list_order = [[0,1], [1,2], [2,3], [3,4], [4,5], [5,6], [6,7], [7,8], [8,9], [9,10], [10,11], [11,12], [12,13], [13,14], [14,15], [15,16], [16,17], [17,18], [18,19], [19,20], [20,21], [21,22], [22,23]]\n",
    "dec_list1 = [list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order, list_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603a06b1",
   "metadata": {},
   "source": [
    "len_list1: 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6882725d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:01.978270Z",
     "iopub.status.busy": "2023-08-01T20:55:01.978018Z",
     "iopub.status.idle": "2023-08-01T20:55:01.980383Z",
     "shell.execute_reply": "2023-08-01T20:55:01.979899Z"
    }
   },
   "outputs": [],
   "source": [
    "len_list1 = [24]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcee5562",
   "metadata": {},
   "source": [
    "dec_list2: 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23b1416",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:01.982350Z",
     "iopub.status.busy": "2023-08-01T20:55:01.981999Z",
     "iopub.status.idle": "2023-08-01T20:55:01.994703Z",
     "shell.execute_reply": "2023-08-01T20:55:01.994251Z"
    }
   },
   "outputs": [],
   "source": [
    "list_order23 = [[0,1], [9,1], [10,1], [1,2], [11,2], [2,3], [12,3], [3,4], [15,14], [14,4], [13,4], [4,5], [16,5], [17,5], [5,6], [18,6], [19,6], [6,7], [20,7], [21,7], [7,8], [22,8], [8,23]]\n",
    "list_order22 = [[0,1], [9,1], [10,1], [1,2], [11,2], [2,3], [12,3], [3,4], [15,14], [14,4], [13,4], [4,5], [16,5], [17,5], [5,6], [18,6], [19,6], [6,7], [20,7], [21,7], [7,8], [8,22]]\n",
    "list_order21 = [[0,1], [9,1], [10,1], [1,2], [11,2], [2,3], [12,3], [3,4], [15,14], [14,4], [13,4], [4,5], [16,5], [17,5], [5,6], [18,6], [19,6], [6,7], [20,7], [21,7], [7,8]]\n",
    "list_order20 = [[0,1], [9,1], [10,1], [1,2], [11,2], [2,3], [12,3], [3,4], [15,14], [14,4], [13,4], [4,5], [16,5], [17,5], [5,6], [18,6], [19,6], [6,7], [20,7], [7,21]]\n",
    "list_order19 = [[0,1], [9,1], [10,1], [1,2], [11,2], [2,3], [12,3], [3,4], [15,14], [14,4], [13,4], [4,5], [16,5], [17,5], [5,6], [18,6], [19,6], [6,7], [7,20]]\n",
    "list_order18 = [[0,1], [9,1], [10,1], [1,2], [11,2], [2,3], [12,3], [3,4], [15,14], [14,4], [13,4], [4,5], [16,5], [17,5], [5,6], [18,6], [19,6], [6,7]]\n",
    "list_order17 = [[0,1], [9,1], [10,1], [1,2], [11,2], [2,3], [12,3], [3,4], [15,14], [14,4], [13,4], [4,5], [16,5], [17,5], [5,6], [18,6], [6,19]]\n",
    "list_order16 = [[0,1], [9,1], [10,1], [1,2], [11,2], [2,3], [12,3], [3,4], [15,14], [14,4], [13,4], [4,5], [16,5], [17,5], [5,6], [6,18]]\n",
    "list_order15 = [[0,1], [9,1], [10,1], [1,2], [11,2], [2,3], [12,3], [3,4], [15,14], [14,4], [13,4], [4,5], [16,5], [17,5], [5,6]]\n",
    "list_order14 = [[0,1], [9,1], [10,1], [1,2], [11,2], [2,3], [12,3], [3,4], [15,14], [14,4], [13,4], [4,5], [16,5], [5,17]]\n",
    "list_order13 = [[0,1], [9,1], [10,1], [1,2], [11,2], [2,3], [12,3], [3,4], [15,14], [14,4], [13,4], [4,5], [5,16]]\n",
    "list_order12 = [[0,1], [9,1], [10,1], [1,2], [11,2], [2,3], [12,3], [3,4], [15,14], [14,4], [13,4], [4,5]]\n",
    "list_order11 = [[0,1], [9,1], [10,1], [1,2], [11,2], [2,3], [12,3], [3,4], [15,14], [14,4], [4,13]]\n",
    "list_order10 = [[0,1], [9,1], [10,1], [1,2], [11,2], [2,3], [12,3], [3,4], [4,14], [14,15]]\n",
    "list_order9 = [[0,1], [9,1], [10,1], [1,2], [11,2], [2,3], [12,3], [3,4], [4,14]]\n",
    "list_order8 = [[0,1], [9,1], [10,1], [1,2], [11,2], [2,3], [12,3], [3,4]]\n",
    "list_order7 = [[0,1], [9,1], [10,1], [1,2], [11,2], [2,3], [3,12]]\n",
    "list_order6 = [[0,1], [9,1], [10,1], [1,2], [11,2], [2,3]]\n",
    "list_order5 = [[0,1], [9,1], [10,1], [1,2], [2,11]]\n",
    "list_order4 = [[0,1], [9,1], [10,1], [1,2]]\n",
    "list_order3 = [[0,1], [9,1], [1,10]]\n",
    "list_order2 = [[0,1], [1,9]]\n",
    "list_order1 = [[0,1]]\n",
    "\n",
    "\n",
    "dec_list2 = [list_order1, list_order2, list_order3, list_order4, list_order5, list_order6, list_order7, list_order8, list_order9, list_order10, list_order11, list_order12, list_order13, list_order14, list_order15, list_order16, list_order17, list_order18, list_order19, list_order20, list_order21, list_order22, list_order23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e274a72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15e6dbe1",
   "metadata": {},
   "source": [
    "len_list2: 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6886e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:01.996680Z",
     "iopub.status.busy": "2023-08-01T20:55:01.996336Z",
     "iopub.status.idle": "2023-08-01T20:55:01.998741Z",
     "shell.execute_reply": "2023-08-01T20:55:01.998319Z"
    }
   },
   "outputs": [],
   "source": [
    "len_list2 = [9,1,1,1,1,2,1,1,1,1,1,1,1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98230b16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f879fba2",
   "metadata": {},
   "source": [
    "Create benchmark for graph similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cfa8c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:02.000655Z",
     "iopub.status.busy": "2023-08-01T20:55:02.000315Z",
     "iopub.status.idle": "2023-08-01T20:55:02.003030Z",
     "shell.execute_reply": "2023-08-01T20:55:02.002612Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_random_graph(nodes, probability):\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(nodes)\n",
    "\n",
    "    for i in nodes:\n",
    "        for j in nodes:\n",
    "            if i != j and random.random() < probability:\n",
    "                G.add_edge(i, j)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f1c43f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:02.004747Z",
     "iopub.status.busy": "2023-08-01T20:55:02.004455Z",
     "iopub.status.idle": "2023-08-01T20:55:02.006562Z",
     "shell.execute_reply": "2023-08-01T20:55:02.006150Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate G\n",
    "# G1 = generate_random_graph(range(24), 0.7)\n",
    "# G2 = generate_random_graph(range(24), 0.875)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff4d87d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:02.008310Z",
     "iopub.status.busy": "2023-08-01T20:55:02.008062Z",
     "iopub.status.idle": "2023-08-01T20:55:02.011282Z",
     "shell.execute_reply": "2023-08-01T20:55:02.010847Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Write the graph as an adjacency list\n",
    "# nx.write_adjlist(G1, \"graph_sim1.adjlist\")\n",
    "# nx.write_adjlist(G2, \"graph_sim2.adjlist\")\n",
    "\n",
    "# Read the graph from the adjacency list\n",
    "G1 = nx.read_adjlist(\"graph_sim1.adjlist\")\n",
    "        \n",
    "G2 = nx.read_adjlist(\"graph_sim2.adjlist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c10bf5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:02.013106Z",
     "iopub.status.busy": "2023-08-01T20:55:02.012782Z",
     "iopub.status.idle": "2023-08-01T20:55:02.015627Z",
     "shell.execute_reply": "2023-08-01T20:55:02.015190Z"
    }
   },
   "outputs": [],
   "source": [
    "# Obtain the adjacency matrix of the graph G\n",
    "A1 = nx.to_numpy_array(G1)\n",
    "\n",
    "A2 = nx.to_numpy_array(G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e6d46a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:02.017269Z",
     "iopub.status.busy": "2023-08-01T20:55:02.017018Z",
     "iopub.status.idle": "2023-08-01T20:55:02.019967Z",
     "shell.execute_reply": "2023-08-01T20:55:02.019542Z"
    }
   },
   "outputs": [],
   "source": [
    "S1, U1 = sf.decompositions.takagi(A1)\n",
    "\n",
    "S2, U2 = sf.decompositions.takagi(A2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e02f12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:02.021700Z",
     "iopub.status.busy": "2023-08-01T20:55:02.021360Z",
     "iopub.status.idle": "2023-08-01T20:55:02.024080Z",
     "shell.execute_reply": "2023-08-01T20:55:02.023643Z"
    }
   },
   "outputs": [],
   "source": [
    "S1, U1 = sf.decompositions.takagi(A1)\n",
    "S1_max = np.max(S1)\n",
    "S1 = S1/(S1_max+0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab85a84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:02.025790Z",
     "iopub.status.busy": "2023-08-01T20:55:02.025460Z",
     "iopub.status.idle": "2023-08-01T20:55:02.028247Z",
     "shell.execute_reply": "2023-08-01T20:55:02.027817Z"
    }
   },
   "outputs": [],
   "source": [
    "S2, U2 = sf.decompositions.takagi(A2)\n",
    "S2_max = np.max(S2)\n",
    "S2 = S2/(S2_max+0.351)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44a8f7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:02.030039Z",
     "iopub.status.busy": "2023-08-01T20:55:02.029738Z",
     "iopub.status.idle": "2023-08-01T20:55:02.032543Z",
     "shell.execute_reply": "2023-08-01T20:55:02.032133Z"
    }
   },
   "outputs": [],
   "source": [
    "n1 = 0\n",
    "for s in S1:\n",
    "    n1 = n1+s**2/(1-s**2)\n",
    "print(n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0886731",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:02.034246Z",
     "iopub.status.busy": "2023-08-01T20:55:02.033973Z",
     "iopub.status.idle": "2023-08-01T20:55:02.036604Z",
     "shell.execute_reply": "2023-08-01T20:55:02.036199Z"
    }
   },
   "outputs": [],
   "source": [
    "n2 = 0\n",
    "for s in S2:\n",
    "    n2 = n2+s**2/(1-s**2)\n",
    "print(n2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d030856d",
   "metadata": {},
   "source": [
    "Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6715639c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:02.038357Z",
     "iopub.status.busy": "2023-08-01T20:55:02.038063Z",
     "iopub.status.idle": "2023-08-01T20:55:02.040479Z",
     "shell.execute_reply": "2023-08-01T20:55:02.040072Z"
    }
   },
   "outputs": [],
   "source": [
    "G1_acc1 = []\n",
    "G1_acc2 = []\n",
    "G1_acc3 = []\n",
    "G1_acc4 = []\n",
    "G2_acc1 = []\n",
    "G2_acc2 = []\n",
    "G2_acc3 = []\n",
    "G2_acc4 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cf9c61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:02.042203Z",
     "iopub.status.busy": "2023-08-01T20:55:02.041881Z",
     "iopub.status.idle": "2023-08-01T20:55:02.044187Z",
     "shell.execute_reply": "2023-08-01T20:55:02.043777Z"
    }
   },
   "outputs": [],
   "source": [
    "time_base = []\n",
    "sample_G1_base = []\n",
    "sample_G2_base = []\n",
    "vector_G1_base = []\n",
    "vector_G2_base = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79f1845",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T20:55:02.046071Z",
     "iopub.status.busy": "2023-08-01T20:55:02.045762Z",
     "iopub.status.idle": "2023-08-02T01:46:37.662041Z",
     "shell.execute_reply": "2023-08-02T01:46:37.661580Z"
    }
   },
   "outputs": [],
   "source": [
    "# base experiments\n",
    "M_base = 10000\n",
    "loss = 1\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "sample_list1 = vibration_sampling_plus(M_base, S1, 0.3324, U1, dec_list1, 0, len_list1, 12, 1, 1, 100, loss)\n",
    "sample_list2 = vibration_sampling_plus(M_base, S1, 0.3324, U1, dec_list1, 0, len_list1, 12, 1, 1, 100, loss)\n",
    "sample_list3 = vibration_sampling_plus(M_base, S1, 0.3324, U1, dec_list1, 0, len_list1, 12, 1, 1, 100, loss)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "time_base.append(execution_time)\n",
    "sample_G1_base.append(sample_list1)\n",
    "sample_G1_base.append(sample_list2)\n",
    "sample_G1_base.append(sample_list3)\n",
    "\n",
    "start_time = time.time()\n",
    "sample_list4 = vibration_sampling_plus(M_base, S2, 0.351, U2, dec_list1, 0, len_list1, 12, 1, 1, 100, loss)\n",
    "sample_list5 = vibration_sampling_plus(M_base, S2, 0.351, U2, dec_list1, 0, len_list1, 12, 1, 1, 100, loss)\n",
    "sample_list6 = vibration_sampling_plus(M_base, S2, 0.351, U2, dec_list1, 0, len_list1, 12, 1, 1, 100, loss)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "time_base.append(execution_time)\n",
    "sample_G2_base.append(sample_list4)\n",
    "sample_G2_base.append(sample_list5)\n",
    "sample_G2_base.append(sample_list6)\n",
    "\n",
    "orbits = [[1,1,1,1,1,1], [1,1,1,1], [1,1]]\n",
    "vector1 = feature_vector_orbits_sampling(sample_list1, orbits)\n",
    "vector2 = feature_vector_orbits_sampling(sample_list2, orbits)\n",
    "vector3 = feature_vector_orbits_sampling(sample_list3, orbits)\n",
    "vector4 = feature_vector_orbits_sampling(sample_list4, orbits)\n",
    "vector5 = feature_vector_orbits_sampling(sample_list5, orbits)\n",
    "vector6 = feature_vector_orbits_sampling(sample_list6, orbits)\n",
    "\n",
    "vector_G1_base.append(vector1)\n",
    "vector_G1_base.append(vector2)\n",
    "vector_G1_base.append(vector3)\n",
    "vector_G2_base.append(vector4)\n",
    "vector_G2_base.append(vector5)\n",
    "vector_G2_base.append(vector6)\n",
    "\n",
    "G1_base = (np.array(vector1)+np.array(vector2)+np.array(vector3))/3\n",
    "G2_base = (np.array(vector4)+np.array(vector5)+np.array(vector6))/3\n",
    "\n",
    "print(vector1)\n",
    "print(vector2)\n",
    "print(vector3)\n",
    "print(vector4)\n",
    "print(vector5)\n",
    "print(vector6)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# ax.scatter(vector1[0], vector1[1], vector1[2], color=\"blue\", s=150)\n",
    "# ax.scatter(vector2[0], vector2[1], vector2[2], color=\"blue\", s=150)\n",
    "# ax.scatter(vector3[0], vector3[1], vector3[2], color=\"blue\", s=150)\n",
    "# ax.scatter(vector4[0], vector4[1], vector4[2], color=\"red\", s=150)\n",
    "# ax.scatter(vector5[0], vector5[1], vector5[2], color=\"red\", s=150)\n",
    "# ax.scatter(vector6[0], vector6[1], vector6[2], color=\"red\", s=150)\n",
    "# ax.set_xlabel('[1,1,1,1,1,1]')\n",
    "# ax.set_ylabel('[1,1,1,1]')\n",
    "# ax.set_zlabel('[1,1]')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e9785a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T01:46:37.664423Z",
     "iopub.status.busy": "2023-08-02T01:46:37.663996Z",
     "iopub.status.idle": "2023-08-02T01:46:38.229873Z",
     "shell.execute_reply": "2023-08-02T01:46:38.229302Z"
    }
   },
   "outputs": [],
   "source": [
    "# # create path for M_base\n",
    "# path_M_base = 'M_base.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_M_base, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow([M_base])\n",
    "    \n",
    "# # create path for time_base\n",
    "# path_time_base = 'time_base.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_time_base, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(time_base)\n",
    "    \n",
    "    \n",
    "# create path for sample_G1_base\n",
    "path_sample_G1_base = 'sample_G1_base.csv'\n",
    "# Open the file in write mode and create a CSV writer\n",
    "with open(path_sample_G1_base, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the list as a single row in the CSV file\n",
    "    writer.writerow(sample_G1_base)\n",
    "    \n",
    "# create path for sample_G2_base\n",
    "path_sample_G2_base = 'sample_G2_base.csv'\n",
    "# Open the file in write mode and create a CSV writer\n",
    "with open(path_sample_G2_base, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the list as a single row in the CSV file\n",
    "    writer.writerow(sample_G2_base)\n",
    "    \n",
    "# # create path for vector_G1_base\n",
    "# path_vector_G1_base = 'vector_G1_base.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_vector_G1_base, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(vector_G1_base)\n",
    "    \n",
    "# # create path for vector_G2_base\n",
    "# path_vector_G2_base = 'vector_G2_base.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_vector_G2_base, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(vector_G2_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973a3c30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T01:46:38.232478Z",
     "iopub.status.busy": "2023-08-02T01:46:38.232150Z",
     "iopub.status.idle": "2023-08-02T01:46:38.234663Z",
     "shell.execute_reply": "2023-08-02T01:46:38.234254Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_range = [0.99, 0.98, 0.97, 0.96, 0.95, 0.94, 0.93, 0.92, 0.91, 0.9]\n",
    "M = 3400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2a720b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T01:46:38.236475Z",
     "iopub.status.busy": "2023-08-02T01:46:38.236124Z",
     "iopub.status.idle": "2023-08-02T01:46:38.239259Z",
     "shell.execute_reply": "2023-08-02T01:46:38.238858Z"
    }
   },
   "outputs": [],
   "source": [
    "# # create path for loss list\n",
    "# path_loss = 'loss.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_loss, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(loss_range)\n",
    "    \n",
    "# # create path for M\n",
    "# path_M = 'M.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_M, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow([M])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf3be1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T01:46:38.241161Z",
     "iopub.status.busy": "2023-08-02T01:46:38.240843Z",
     "iopub.status.idle": "2023-08-02T01:46:38.243106Z",
     "shell.execute_reply": "2023-08-02T01:46:38.242700Z"
    }
   },
   "outputs": [],
   "source": [
    "time1 = []\n",
    "time2 = []\n",
    "time3 = []\n",
    "time4 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e43b81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T01:46:38.245031Z",
     "iopub.status.busy": "2023-08-02T01:46:38.244719Z",
     "iopub.status.idle": "2023-08-02T01:46:38.247547Z",
     "shell.execute_reply": "2023-08-02T01:46:38.247123Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_G1_1 = []\n",
    "sample_G1_2 = []\n",
    "sample_G1_3 = []\n",
    "sample_G1_4 = []\n",
    "sample_G2_1 = []\n",
    "sample_G2_2 = []\n",
    "sample_G2_3 = []\n",
    "sample_G2_4 = []\n",
    "vector_G1_1 = []\n",
    "vector_G1_2 = []\n",
    "vector_G1_3 = []\n",
    "vector_G1_4 = []\n",
    "vector_G2_1 = []\n",
    "vector_G2_2 = []\n",
    "vector_G2_3 = []\n",
    "vector_G2_4 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697c353f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T01:46:38.249378Z",
     "iopub.status.busy": "2023-08-02T01:46:38.249019Z",
     "iopub.status.idle": "2023-08-02T01:46:38.251177Z",
     "shell.execute_reply": "2023-08-02T01:46:38.250781Z"
    }
   },
   "source": [
    "unitary approximation accuracy: 99.9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61eb079",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T01:46:38.253081Z",
     "iopub.status.busy": "2023-08-02T01:46:38.252933Z",
     "iopub.status.idle": "2023-08-03T22:14:55.878327Z",
     "shell.execute_reply": "2023-08-03T22:14:55.877751Z"
    }
   },
   "outputs": [],
   "source": [
    "for loss in loss_range:\n",
    "    \n",
    "    # 000\n",
    "    start_time = time.time()\n",
    "    sample_list1 = vibration_sampling_plus(M, S1, 0.3324, U1, dec_list1, 0, len_list1, 12, 1, 1, 100, loss)\n",
    "    sample_list2 = vibration_sampling_plus(M, S1, 0.3324, U1, dec_list1, 0, len_list1, 12, 1, 1, 100, loss)\n",
    "    sample_list3 = vibration_sampling_plus(M, S1, 0.3324, U1, dec_list1, 0, len_list1, 12, 1, 1, 100, loss)\n",
    "    end_time = time.time()\n",
    "    execution_time1 = end_time - start_time\n",
    "    time1.append(execution_time1)\n",
    "    sample_G1_1.append(sample_list1)\n",
    "    sample_G1_1.append(sample_list2)\n",
    "    sample_G1_1.append(sample_list3)\n",
    "    \n",
    "    \n",
    "    start_time = time.time()\n",
    "    sample_list4 = vibration_sampling_plus(M, S2, 0.351, U2, dec_list1, 0, len_list1, 12, 1, 1, 100, loss)\n",
    "    sample_list5 = vibration_sampling_plus(M, S2, 0.351, U2, dec_list1, 0, len_list1, 12, 1, 1, 100, loss)\n",
    "    sample_list6 = vibration_sampling_plus(M, S2, 0.351, U2, dec_list1, 0, len_list1, 12, 1, 1, 100, loss)\n",
    "    end_time = time.time()\n",
    "    execution_time1 = end_time - start_time\n",
    "    time1.append(execution_time1)\n",
    "    sample_G2_1.append(sample_list4)\n",
    "    sample_G2_1.append(sample_list5)\n",
    "    sample_G2_1.append(sample_list6)\n",
    "\n",
    "    \n",
    "    orbits = [[1,1,1,1,1,1], [1,1,1,1], [1,1]]\n",
    "    vector7 = feature_vector_orbits_sampling(sample_list1, orbits)\n",
    "    vector8 = feature_vector_orbits_sampling(sample_list2, orbits)\n",
    "    vector9 = feature_vector_orbits_sampling(sample_list3, orbits)\n",
    "    vector10 = feature_vector_orbits_sampling(sample_list4, orbits)\n",
    "    vector11 = feature_vector_orbits_sampling(sample_list5, orbits)\n",
    "    vector12 = feature_vector_orbits_sampling(sample_list6, orbits)\n",
    "    vector_G1_1.append(vector7)\n",
    "    vector_G1_1.append(vector8)\n",
    "    vector_G1_1.append(vector9)\n",
    "    vector_G2_1.append(vector10)\n",
    "    vector_G2_1.append(vector11)\n",
    "    vector_G2_1.append(vector12)\n",
    "\n",
    "    G1_e1 = (np.array(vector7)+np.array(vector8)+np.array(vector9))/3\n",
    "    G2_e1 = (np.array(vector10)+np.array(vector11)+np.array(vector12))/3\n",
    "\n",
    "    acc1 = distance_between_vectors(G1_e1, G1_base)\n",
    "    acc2 = distance_between_vectors(G2_e1, G2_base)\n",
    "\n",
    "\n",
    "    G1_acc1.append(acc1)\n",
    "    G2_acc1.append(acc2)\n",
    "    \n",
    "    \n",
    "    # 001\n",
    "    start_time = time.time()\n",
    "    sample_list1 = vibration_sampling_plus(M, S1, 0.3324, U1, dec_list1, 0, len_list1, 12, 0.985, 0.12, 100, loss)\n",
    "    sample_list2 = vibration_sampling_plus(M, S1, 0.3324, U1, dec_list1, 0, len_list1, 12, 0.985, 0.12, 100, loss)\n",
    "    sample_list3 = vibration_sampling_plus(M, S1, 0.3324, U1, dec_list1, 0, len_list1, 12, 0.985, 0.12, 100, loss)\n",
    "    end_time = time.time()\n",
    "    execution_time2 = end_time - start_time\n",
    "    time2.append(execution_time2)\n",
    "    sample_G1_2.append(sample_list1)\n",
    "    sample_G1_2.append(sample_list2)\n",
    "    sample_G1_2.append(sample_list3)\n",
    "    \n",
    "    \n",
    "    start_time = time.time()\n",
    "    sample_list4 = vibration_sampling_plus(M, S2, 0.351, U2, dec_list1, 0, len_list1, 12, 0.964, 0.16, 100, loss)\n",
    "    sample_list5 = vibration_sampling_plus(M, S2, 0.351, U2, dec_list1, 0, len_list1, 12, 0.964, 0.16, 100, loss)\n",
    "    sample_list6 = vibration_sampling_plus(M, S2, 0.351, U2, dec_list1, 0, len_list1, 12, 0.964, 0.16, 100, loss)\n",
    "    end_time = time.time()\n",
    "    execution_time2 = end_time - start_time\n",
    "    time2.append(execution_time2)\n",
    "    sample_G2_2.append(sample_list4)\n",
    "    sample_G2_2.append(sample_list5)\n",
    "    sample_G2_2.append(sample_list6)\n",
    "\n",
    "    orbits = [[1,1,1,1,1,1], [1,1,1,1], [1,1]]\n",
    "    vector7 = feature_vector_orbits_sampling(sample_list1, orbits)\n",
    "    vector8 = feature_vector_orbits_sampling(sample_list2, orbits)\n",
    "    vector9 = feature_vector_orbits_sampling(sample_list3, orbits)\n",
    "    vector10 = feature_vector_orbits_sampling(sample_list4, orbits)\n",
    "    vector11 = feature_vector_orbits_sampling(sample_list5, orbits)\n",
    "    vector12 = feature_vector_orbits_sampling(sample_list6, orbits)\n",
    "    vector_G1_2.append(vector7)\n",
    "    vector_G1_2.append(vector8)\n",
    "    vector_G1_2.append(vector9)\n",
    "    vector_G2_2.append(vector10)\n",
    "    vector_G2_2.append(vector11)\n",
    "    vector_G2_2.append(vector12)\n",
    "\n",
    "    G1_e2 = (np.array(vector7)+np.array(vector8)+np.array(vector9))/3\n",
    "    G2_e2 = (np.array(vector10)+np.array(vector11)+np.array(vector12))/3\n",
    "\n",
    "    acc1 = distance_between_vectors(G1_e2, G1_base)\n",
    "    acc2 = distance_between_vectors(G2_e2, G2_base)\n",
    "\n",
    "\n",
    "    G1_acc2.append(acc1)\n",
    "    G2_acc2.append(acc2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 101\n",
    "    start_time = time.time()\n",
    "    sample_list1 = vibration_sampling_plus(M, S1, 0.3324, U1, dec_list2, 0, len_list2, 12, 0.848, 0.05, 100, loss)\n",
    "    sample_list2 = vibration_sampling_plus(M, S1, 0.3324, U1, dec_list2, 0, len_list2, 12, 0.848, 0.05, 100, loss)\n",
    "    sample_list3 = vibration_sampling_plus(M, S1, 0.3324, U1, dec_list2, 0, len_list2, 12, 0.848, 0.05, 100, loss)\n",
    "    end_time = time.time()\n",
    "    execution_time3 = end_time - start_time\n",
    "    time3.append(execution_time3)\n",
    "    sample_G1_3.append(sample_list1)\n",
    "    sample_G1_3.append(sample_list2)\n",
    "    sample_G1_3.append(sample_list3)\n",
    "    \n",
    "    \n",
    "    start_time = time.time()\n",
    "    sample_list4 = vibration_sampling_plus(M, S2, 0.351, U2, dec_list2, 0, len_list2, 12, 0.754, 0.06, 100, loss)\n",
    "    sample_list5 = vibration_sampling_plus(M, S2, 0.351, U2, dec_list2, 0, len_list2, 12, 0.754, 0.06, 100, loss)\n",
    "    sample_list6 = vibration_sampling_plus(M, S2, 0.351, U2, dec_list2, 0, len_list2, 12, 0.754, 0.06, 100, loss)\n",
    "    end_time = time.time()\n",
    "    execution_time3 = end_time - start_time\n",
    "    time3.append(execution_time3)\n",
    "    sample_G2_3.append(sample_list4)\n",
    "    sample_G2_3.append(sample_list5)\n",
    "    sample_G2_3.append(sample_list6)\n",
    "\n",
    "    \n",
    "    orbits = [[1,1,1,1,1,1], [1,1,1,1], [1,1]]\n",
    "    vector7 = feature_vector_orbits_sampling(sample_list1, orbits)\n",
    "    vector8 = feature_vector_orbits_sampling(sample_list2, orbits)\n",
    "    vector9 = feature_vector_orbits_sampling(sample_list3, orbits)\n",
    "    vector10 = feature_vector_orbits_sampling(sample_list4, orbits)\n",
    "    vector11 = feature_vector_orbits_sampling(sample_list5, orbits)\n",
    "    vector12 = feature_vector_orbits_sampling(sample_list6, orbits)\n",
    "    vector_G1_3.append(vector7)\n",
    "    vector_G1_3.append(vector8)\n",
    "    vector_G1_3.append(vector9)\n",
    "    vector_G2_3.append(vector10)\n",
    "    vector_G2_3.append(vector11)\n",
    "    vector_G2_3.append(vector12)\n",
    "\n",
    "    G1_e3 = (np.array(vector7)+np.array(vector8)+np.array(vector9))/3\n",
    "    G2_e3 = (np.array(vector10)+np.array(vector11)+np.array(vector12))/3\n",
    "\n",
    "    acc1 = distance_between_vectors(G1_e3, G1_base)\n",
    "    acc2 = distance_between_vectors(G2_e3, G2_base)\n",
    "\n",
    "\n",
    "    G1_acc3.append(acc1)\n",
    "    G2_acc3.append(acc2)\n",
    "    \n",
    "    # 111\n",
    "    start_time = time.time()\n",
    "    sample_list1 = vibration_sampling_plus(M, S1, 0.3324, U1, dec_list2, 1, len_list2, 8, 0.729, 0.04, 100, loss)\n",
    "    sample_list2 = vibration_sampling_plus(M, S1, 0.3324, U1, dec_list2, 1, len_list2, 8, 0.728, 0.04, 100, loss)\n",
    "    sample_list3 = vibration_sampling_plus(M, S1, 0.3324, U1, dec_list2, 1, len_list2, 8, 0.728, 0.04, 100, loss)\n",
    "    end_time = time.time()\n",
    "    execution_time4 = end_time - start_time\n",
    "    time4.append(execution_time4)\n",
    "    sample_G1_4.append(sample_list1)\n",
    "    sample_G1_4.append(sample_list2)\n",
    "    sample_G1_4.append(sample_list3)\n",
    "    \n",
    "    \n",
    "    start_time = time.time()\n",
    "    sample_list4 = vibration_sampling_plus(M, S2, 0.351, U2, dec_list2, 1, len_list2, 8, 0.714, 0.045, 100, loss)\n",
    "    sample_list5 = vibration_sampling_plus(M, S2, 0.351, U2, dec_list2, 1, len_list2, 8, 0.714, 0.045, 100, loss)\n",
    "    sample_list6 = vibration_sampling_plus(M, S2, 0.351, U2, dec_list2, 1, len_list2, 8, 0.714, 0.045, 100, loss)\n",
    "    end_time = time.time()\n",
    "    execution_time4 = end_time - start_time\n",
    "    time4.append(execution_time4)\n",
    "    sample_G2_4.append(sample_list4)\n",
    "    sample_G2_4.append(sample_list5)\n",
    "    sample_G2_4.append(sample_list6)\n",
    "\n",
    "    \n",
    "    orbits = [[1,1,1,1,1,1], [1,1,1,1], [1,1]]\n",
    "    vector7 = feature_vector_orbits_sampling(sample_list1, orbits)\n",
    "    vector8 = feature_vector_orbits_sampling(sample_list2, orbits)\n",
    "    vector9 = feature_vector_orbits_sampling(sample_list3, orbits)\n",
    "    vector10 = feature_vector_orbits_sampling(sample_list4, orbits)\n",
    "    vector11 = feature_vector_orbits_sampling(sample_list5, orbits)\n",
    "    vector12 = feature_vector_orbits_sampling(sample_list6, orbits)\n",
    "    vector_G1_4.append(vector7)\n",
    "    vector_G1_4.append(vector8)\n",
    "    vector_G1_4.append(vector9)\n",
    "    vector_G2_4.append(vector10)\n",
    "    vector_G2_4.append(vector11)\n",
    "    vector_G2_4.append(vector12)\n",
    "\n",
    "    G1_e4 = (np.array(vector7)+np.array(vector8)+np.array(vector9))/3\n",
    "    G2_e4 = (np.array(vector10)+np.array(vector11)+np.array(vector12))/3\n",
    "\n",
    "    acc1 = distance_between_vectors(G1_e4, G1_base)\n",
    "    acc2 = distance_between_vectors(G2_e4, G2_base)\n",
    "\n",
    "\n",
    "    G1_acc4.append(acc1)\n",
    "    G2_acc4.append(acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a11bb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-03T22:14:55.881109Z",
     "iopub.status.busy": "2023-08-03T22:14:55.880687Z",
     "iopub.status.idle": "2023-08-03T22:15:00.633337Z",
     "shell.execute_reply": "2023-08-03T22:15:00.632768Z"
    }
   },
   "outputs": [],
   "source": [
    "# create path for sample_G1_1\n",
    "path_sample_G1_1 = 'sample_G1_1.csv'\n",
    "# Open the file in write mode and create a CSV writer\n",
    "with open(path_sample_G1_1, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the list as a single row in the CSV file\n",
    "    writer.writerow(sample_G1_1)\n",
    "    \n",
    "# create path for sample_G1_2\n",
    "path_sample_G1_2 = 'sample_G1_2.csv'\n",
    "# Open the file in write mode and create a CSV writer\n",
    "with open(path_sample_G1_2, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the list as a single row in the CSV file\n",
    "    writer.writerow(sample_G1_2)\n",
    "    \n",
    "# create path for sample_G1_3\n",
    "path_sample_G1_3 = 'sample_G1_3.csv'\n",
    "# Open the file in write mode and create a CSV writer\n",
    "with open(path_sample_G1_3, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the list as a single row in the CSV file\n",
    "    writer.writerow(sample_G1_3)\n",
    "    \n",
    "# create path for sample_G1_4\n",
    "path_sample_G1_4 = 'sample_G1_4.csv'\n",
    "# Open the file in write mode and create a CSV writer\n",
    "with open(path_sample_G1_4, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the list as a single row in the CSV file\n",
    "    writer.writerow(sample_G1_4)\n",
    "    \n",
    "    \n",
    "    \n",
    "# create path for sample_G2_1\n",
    "path_sample_G2_1 = 'sample_G2_1.csv'\n",
    "# Open the file in write mode and create a CSV writer\n",
    "with open(path_sample_G2_1, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the list as a single row in the CSV file\n",
    "    writer.writerow(sample_G2_1)\n",
    "    \n",
    "# create path for sample_G2_2\n",
    "path_sample_G2_2 = 'sample_G2_2.csv'\n",
    "# Open the file in write mode and create a CSV writer\n",
    "with open(path_sample_G2_2, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the list as a single row in the CSV file\n",
    "    writer.writerow(sample_G2_2)\n",
    "    \n",
    "# create path for sample_G2_3\n",
    "path_sample_G2_3 = 'sample_G2_3.csv'\n",
    "# Open the file in write mode and create a CSV writer\n",
    "with open(path_sample_G2_3, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the list as a single row in the CSV file\n",
    "    writer.writerow(sample_G2_3)\n",
    "    \n",
    "# create path for sample_G2_4\n",
    "path_sample_G2_4 = 'sample_G2_4.csv'\n",
    "# Open the file in write mode and create a CSV writer\n",
    "with open(path_sample_G2_4, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the list as a single row in the CSV file\n",
    "    writer.writerow(sample_G2_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83036dd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-03T22:15:00.635936Z",
     "iopub.status.busy": "2023-08-03T22:15:00.635625Z",
     "iopub.status.idle": "2023-08-03T22:15:00.644387Z",
     "shell.execute_reply": "2023-08-03T22:15:00.643937Z"
    }
   },
   "outputs": [],
   "source": [
    "# # create path for vector_G1_1\n",
    "# path_vector_G1_1 = 'vector_G1_1.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_vector_G1_1, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(vector_G1_1)\n",
    "    \n",
    "# # create path for vector_G1_2\n",
    "# path_vector_G1_2 = 'vector_G1_2.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_vector_G1_2, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(vector_G1_2)\n",
    "    \n",
    "# # create path for vector_G1_3\n",
    "# path_vector_G1_3 = 'vector_G1_3.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_vector_G1_3, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(vector_G1_3)\n",
    "    \n",
    "# # create path for vector_G1_4\n",
    "# path_vector_G1_4 = 'vector_G1_4.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_vector_G1_4, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(vector_G1_4)\n",
    "    \n",
    "    \n",
    "    \n",
    "# # create path for vector_G2_1\n",
    "# path_vector_G2_1 = 'vector_G2_1.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_vector_G2_1, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(vector_G2_1)\n",
    "    \n",
    "# # create path for vector_G2_2\n",
    "# path_vector_G2_2 = 'vector_G2_2.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_vector_G2_2, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(vector_G2_2)\n",
    "    \n",
    "# # create path for vector_G2_3\n",
    "# path_vector_G2_3 = 'vector_G2_3.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_vector_G2_3, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(vector_G2_3)\n",
    "    \n",
    "# # create path for vector_G2_4\n",
    "# path_vector_G2_4 = 'vector_G2_4.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_vector_G2_4, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(vector_G2_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3661092d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-03T22:15:00.646450Z",
     "iopub.status.busy": "2023-08-03T22:15:00.646068Z",
     "iopub.status.idle": "2023-08-03T22:15:00.652644Z",
     "shell.execute_reply": "2023-08-03T22:15:00.652190Z"
    }
   },
   "outputs": [],
   "source": [
    "# # create path for G1_acc1\n",
    "# path_G1_acc1 = 'G1_acc1.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_G1_acc1, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(G1_acc1)\n",
    "    \n",
    "# # create path for G1_acc2\n",
    "# path_G1_acc2 = 'G1_acc2.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_G1_acc2, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(G1_acc2)\n",
    "    \n",
    "# # create path for G1_acc3\n",
    "# path_G1_acc3 = 'G1_acc3.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_G1_acc3, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(G1_acc3)\n",
    "    \n",
    "# # create path for G1_acc4\n",
    "# path_G1_acc4 = 'G1_acc4.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_G1_acc4, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(G1_acc4)\n",
    "    \n",
    "    \n",
    "    \n",
    "# # create path for G2_acc1\n",
    "# path_G2_acc1 = 'G2_acc1.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_G2_acc1, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(G2_acc1)\n",
    "    \n",
    "# # create path for G2_acc2\n",
    "# path_G2_acc2 = 'G2_acc2.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_G2_acc2, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(G2_acc2)\n",
    "    \n",
    "# # create path for G2_acc3\n",
    "# path_G2_acc3 = 'G2_acc3.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_G2_acc3, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(G2_acc3)\n",
    "    \n",
    "# # create path for G2_acc4\n",
    "# path_G2_acc4 = 'G2_acc4.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_G2_acc4, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(G2_acc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8e04f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-03T22:15:00.654580Z",
     "iopub.status.busy": "2023-08-03T22:15:00.654267Z",
     "iopub.status.idle": "2023-08-03T22:15:00.658233Z",
     "shell.execute_reply": "2023-08-03T22:15:00.657818Z"
    }
   },
   "outputs": [],
   "source": [
    "# # create path for time1\n",
    "# path_time1 = 'time1.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_time1, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(time1)\n",
    "    \n",
    "# # create path for time2\n",
    "# path_time2 = 'time2.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_time2, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(time2)\n",
    "    \n",
    "# # create path for time3\n",
    "# path_time3 = 'time3.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_time3, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(time3)\n",
    "    \n",
    "# # create path for time4\n",
    "# path_time4 = 'time4.csv'\n",
    "# # Open the file in write mode and create a CSV writer\n",
    "# with open(path_time4, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "\n",
    "#     # Write the list as a single row in the CSV file\n",
    "#     writer.writerow(time4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63f9c22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f36e729",
   "metadata": {},
   "source": [
    "JSD caculation, for Fig. 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662e461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jensen_shannon_divergence(p, q):\n",
    "    \"\"\"\n",
    "    Calculate the Jensen-Shannon Divergence (JSD) between two probability distributions.\n",
    "\n",
    "    Parameters:\n",
    "        p (numpy array): Probability distribution P as a 1D numpy array.\n",
    "        q (numpy array): Probability distribution Q as a 1D numpy array.\n",
    "\n",
    "    Returns:\n",
    "        float: The Jensen-Shannon Divergence (JSD) between P and Q in nats.\n",
    "    \"\"\"\n",
    "    # Ensure that the input arrays have the same length\n",
    "    if len(p) != len(q):\n",
    "        raise ValueError(\"Input arrays must have the same length.\")\n",
    "\n",
    "    # Normalize the input arrays to ensure they are valid probability distributions\n",
    "    p = p / np.sum(p)\n",
    "    q = q / np.sum(q)\n",
    "\n",
    "    # Calculate the average distribution (M) as the element-wise average of P and Q\n",
    "    m = 0.5 * (p + q)\n",
    "    \n",
    "    # Count the number of zero entries\n",
    "    zero_count = np.count_nonzero(m == 0)\n",
    "\n",
    "    # Print the result\n",
    "    if zero_count>0:\n",
    "        print('error: m has zero entry')\n",
    "\n",
    "\n",
    "    kl_pm = 0\n",
    "    for i, p_i in enumerate(p):\n",
    "        if p[i] != 0:\n",
    "            kl_pm = kl_pm + p[i]*np.log(p[i] / m[i])\n",
    "            \n",
    "    kl_qm = 0\n",
    "    for i, q_i in enumerate(q):\n",
    "        if q[i] != 0:\n",
    "            kl_qm = kl_qm + q[i]*np.log(q[i] / m[i])\n",
    "    \n",
    "\n",
    "    # Calculate the Jensen-Shannon Divergence (JSD) in nats\n",
    "    jsd = 0.5 * (kl_pm + kl_qm)\n",
    "\n",
    "    return jsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82ac26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sample(sample):\n",
    "    # Remove 0 from the sample\n",
    "    sample_without_zeros = [element for element in sample if element != 0]\n",
    "    # Sort the sample in descending order\n",
    "    sorted_sample = sorted(sample_without_zeros, reverse=True)\n",
    "    return sorted_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bba0620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the element in base_sample and sample should be str\n",
    "def calculate_jsd(base_sample, sample):\n",
    "    \n",
    "    for i, s in enumerate(base_sample):\n",
    "        # Example string representing a list\n",
    "        string_representation = s\n",
    "\n",
    "        # Convert the string to a list using ast.literal_eval()\n",
    "        try:\n",
    "            result_list = ast.literal_eval(string_representation)\n",
    "        except ValueError as e:\n",
    "            # If the string is not a valid Python literal, handle the exception\n",
    "            print(f\"Error: {e}\")\n",
    "            result_list = None\n",
    "            \n",
    "        s = process_sample(result_list)\n",
    "        \n",
    "        string_list = str(s)\n",
    "        \n",
    "        base_sample[i] = string_list\n",
    "        \n",
    "    for i, s in enumerate(sample):\n",
    "        # Example string representing a list\n",
    "        string_representation = s\n",
    "\n",
    "        # Convert the string to a list using ast.literal_eval()\n",
    "        try:\n",
    "            result_list = ast.literal_eval(string_representation)\n",
    "        except ValueError as e:\n",
    "            # If the string is not a valid Python literal, handle the exception\n",
    "            print(f\"Error: {e}\")\n",
    "            result_list = None\n",
    "            \n",
    "        s = process_sample(result_list)\n",
    "        \n",
    "        string_list = str(s)\n",
    "        \n",
    "        sample[i] = string_list\n",
    "        \n",
    "        \n",
    "    \n",
    "    # Combine the two lists and convert to a set to remove duplicates\n",
    "    combined_set = set(base_sample + sample)\n",
    "\n",
    "    # Convert the set back to a list to get a distinct list\n",
    "    distinct_sample = list(combined_set)\n",
    "    \n",
    "    # Calculate the probability for base_sample\n",
    "    probability_list1 = []\n",
    "    total_elements1 = len(base_sample)\n",
    "    element_count1 = Counter(base_sample)\n",
    "    for element in distinct_sample:\n",
    "        occurrences = element_count1[element] if element in element_count1 else 0\n",
    "        probability = occurrences / total_elements1\n",
    "        probability_list1.append(probability)\n",
    "        \n",
    "    # Calculate the probability for sample\n",
    "    probability_list2 = []\n",
    "    total_elements2 = len(sample)\n",
    "    element_count2 = Counter(sample)\n",
    "    for element in distinct_sample:\n",
    "        occurrences = element_count2[element] if element in element_count2 else 0\n",
    "        probability = occurrences / total_elements2\n",
    "        probability_list2.append(probability) \n",
    "        \n",
    "    # Calculate the Jensen-Shannon Divergence (JSD) between P and Q\n",
    "    jsd_result = jensen_shannon_divergence(probability_list1, probability_list2)\n",
    "#     print(\"Jensen-Shannon Divergence:\", jsd_result)   \n",
    "    \n",
    "    return jsd_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1186d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the mean value for a group of 3 numbers\n",
    "def calculate_mean(group):\n",
    "    return sum(group) / len(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ad6344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97825dc3",
   "metadata": {},
   "source": [
    "picture 2 in graph similarity, Fig. 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0339cc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create path for base_sample\n",
    "path_sample_base = 'sample_G1_base.csv'\n",
    "# Open the file in read mode and create a CSV reader\n",
    "with open(path_sample_base, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    # Read the first row from the CSV file\n",
    "    row = next(reader)\n",
    "\n",
    "    # Convert the row elements to integers (if needed)\n",
    "    sample_base_read = [element for element in row] \n",
    "    \n",
    "x_axis = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]\n",
    "\n",
    "\n",
    "    \n",
    "# manipulate the base sample\n",
    "\n",
    "string_representation = sample_base_read[0]\n",
    "\n",
    "# Convert the string to an actual list of lists\n",
    "try:\n",
    "    list_of_lists = ast.literal_eval(string_representation)\n",
    "except ValueError as e:\n",
    "    # If the string_representation is not a valid Python literal, ValueError will be raised.\n",
    "    print(\"Error:\", e)\n",
    "    list_of_lists = None\n",
    "    \n",
    "string_list1 = [str(sub_list) for sub_list in list_of_lists]\n",
    "\n",
    "\n",
    "string_representation = sample_base_read[1]\n",
    "\n",
    "# Convert the string to an actual list of lists\n",
    "try:\n",
    "    list_of_lists = ast.literal_eval(string_representation)\n",
    "except ValueError as e:\n",
    "    # If the string_representation is not a valid Python literal, ValueError will be raised.\n",
    "    print(\"Error:\", e)\n",
    "    list_of_lists = None\n",
    "    \n",
    "string_list2 = [str(sub_list) for sub_list in list_of_lists]\n",
    "\n",
    "\n",
    "string_representation = sample_base_read[2]\n",
    "\n",
    "# Convert the string to an actual list of lists\n",
    "try:\n",
    "    list_of_lists = ast.literal_eval(string_representation)\n",
    "except ValueError as e:\n",
    "    # If the string_representation is not a valid Python literal, ValueError will be raised.\n",
    "    print(\"Error:\", e)\n",
    "    list_of_lists = None\n",
    "    \n",
    "string_list3 = [str(sub_list) for sub_list in list_of_lists]\n",
    "\n",
    "\n",
    "# Combining the three lists into a single list\n",
    "sample_base_read = string_list1 + string_list2 + string_list3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b72714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create path for sample\n",
    "path_sample = 'sample_G1_1.csv'\n",
    "# Open the file in read mode and create a CSV reader\n",
    "with open(path_sample, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    # Read the first row from the CSV file\n",
    "    row = next(reader)\n",
    "\n",
    "    # Convert the row elements to integers (if needed)\n",
    "    sample_read1 = [element for element in row]\n",
    "    \n",
    "\n",
    "# create path for sample\n",
    "path_sample = 'sample_G1_2.csv'\n",
    "# Open the file in read mode and create a CSV reader\n",
    "with open(path_sample, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    # Read the first row from the CSV file\n",
    "    row = next(reader)\n",
    "\n",
    "    # Convert the row elements to integers (if needed)\n",
    "    sample_read2 = [element for element in row]\n",
    "    \n",
    "# create path for sample\n",
    "path_sample = 'sample_G1_3.csv'\n",
    "# Open the file in read mode and create a CSV reader\n",
    "with open(path_sample, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    # Read the first row from the CSV file\n",
    "    row = next(reader)\n",
    "\n",
    "    # Convert the row elements to integers (if needed)\n",
    "    sample_read3 = [element for element in row]\n",
    "    \n",
    "# create path for sample\n",
    "path_sample = 'sample_G1_4.csv'\n",
    "# Open the file in read mode and create a CSV reader\n",
    "with open(path_sample, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    # Read the first row from the CSV file\n",
    "    row = next(reader)\n",
    "\n",
    "    # Convert the row elements to integers (if needed)\n",
    "    sample_read4 = [element for element in row]\n",
    "    \n",
    "    \n",
    "\n",
    "jsd1 = []\n",
    "\n",
    "for i, sample in enumerate(sample_read1):\n",
    "    \n",
    "    # Your string representation of the list of lists\n",
    "    string_representation = sample_read1[i]\n",
    "\n",
    "    # Convert the string to an actual list of lists\n",
    "    try:\n",
    "        list_of_lists = ast.literal_eval(string_representation)\n",
    "    except ValueError as e:\n",
    "        # If the string_representation is not a valid Python literal, ValueError will be raised.\n",
    "        print(\"Error:\", e)\n",
    "        list_of_lists = None\n",
    "    \n",
    "    string_list = [str(sub_list) for sub_list in list_of_lists]\n",
    "    \n",
    "    jsd = calculate_jsd(sample_base_read, string_list)\n",
    "    \n",
    "    jsd1.append(jsd)\n",
    "    \n",
    "#     print(jsd)\n",
    "    \n",
    "jsd2 = []\n",
    "\n",
    "for i, sample in enumerate(sample_read2):\n",
    "    \n",
    "    # Your string representation of the list of lists\n",
    "    string_representation = sample_read2[i]\n",
    "\n",
    "    # Convert the string to an actual list of lists\n",
    "    try:\n",
    "        list_of_lists = ast.literal_eval(string_representation)\n",
    "    except ValueError as e:\n",
    "        # If the string_representation is not a valid Python literal, ValueError will be raised.\n",
    "        print(\"Error:\", e)\n",
    "        list_of_lists = None\n",
    "    \n",
    "    string_list = [str(sub_list) for sub_list in list_of_lists]\n",
    "    \n",
    "    jsd = calculate_jsd(sample_base_read, string_list)\n",
    "    \n",
    "    jsd2.append(jsd)\n",
    "    \n",
    "#     print(jsd)\n",
    "    \n",
    "    \n",
    "jsd3 = []\n",
    "\n",
    "for i, sample in enumerate(sample_read3):\n",
    "    \n",
    "    # Your string representation of the list of lists\n",
    "    string_representation = sample_read3[i]\n",
    "\n",
    "    # Convert the string to an actual list of lists\n",
    "    try:\n",
    "        list_of_lists = ast.literal_eval(string_representation)\n",
    "    except ValueError as e:\n",
    "        # If the string_representation is not a valid Python literal, ValueError will be raised.\n",
    "        print(\"Error:\", e)\n",
    "        list_of_lists = None\n",
    "    \n",
    "    string_list = [str(sub_list) for sub_list in list_of_lists]\n",
    "    \n",
    "    jsd = calculate_jsd(sample_base_read, string_list)\n",
    "    \n",
    "    jsd3.append(jsd)\n",
    "    \n",
    "#     print(jsd)\n",
    "    \n",
    "    \n",
    "    \n",
    "jsd4 = []\n",
    "\n",
    "for i, sample in enumerate(sample_read4):\n",
    "    \n",
    "    # Your string representation of the list of lists\n",
    "    string_representation = sample_read4[i]\n",
    "\n",
    "    # Convert the string to an actual list of lists\n",
    "    try:\n",
    "        list_of_lists = ast.literal_eval(string_representation)\n",
    "    except ValueError as e:\n",
    "        # If the string_representation is not a valid Python literal, ValueError will be raised.\n",
    "        print(\"Error:\", e)\n",
    "        list_of_lists = None\n",
    "    \n",
    "    string_list = [str(sub_list) for sub_list in list_of_lists]\n",
    "    \n",
    "    jsd = calculate_jsd(sample_base_read, string_list)\n",
    "    \n",
    "    jsd4.append(jsd)\n",
    "    \n",
    "#     print(jsd)\n",
    "\n",
    "\n",
    "# List to store the reduced numbers\n",
    "reduced_jsd1= []\n",
    "\n",
    "# Grouping the elements and calculating the mean for each group\n",
    "for i in range(0, len(jsd1), 3):\n",
    "    group = jsd1[i:i+3]\n",
    "    mean_value = calculate_mean(group)\n",
    "    reduced_jsd1.append(mean_value)\n",
    "    \n",
    "# List to store the reduced numbers\n",
    "reduced_jsd2= []\n",
    "\n",
    "# Grouping the elements and calculating the mean for each group\n",
    "for i in range(0, len(jsd2), 3):\n",
    "    group = jsd2[i:i+3]\n",
    "    mean_value = calculate_mean(group)\n",
    "    reduced_jsd2.append(mean_value)\n",
    "    \n",
    "# List to store the reduced numbers\n",
    "reduced_jsd3= []\n",
    "\n",
    "# Grouping the elements and calculating the mean for each group\n",
    "for i in range(0, len(jsd3), 3):\n",
    "    group = jsd3[i:i+3]\n",
    "    mean_value = calculate_mean(group)\n",
    "    reduced_jsd3.append(mean_value)   \n",
    "    \n",
    "# List to store the reduced numbers\n",
    "reduced_jsd4= []\n",
    "\n",
    "# Grouping the elements and calculating the mean for each group\n",
    "for i in range(0, len(jsd4), 3):\n",
    "    group = jsd4[i:i+3]\n",
    "    mean_value = calculate_mean(group)\n",
    "    reduced_jsd4.append(mean_value)\n",
    "    \n",
    "    \n",
    "plt.figure(figsize=(8, 4))    \n",
    "    \n",
    "# Plot data on each subplot\n",
    "plt.plot(x_axis, reduced_jsd1, color='blue', label='baseline', marker='x', markersize=16, linewidth=1)\n",
    "plt.plot(x_axis, reduced_jsd2, color='green', label='rotation-cut', marker='^', markersize=16, linewidth=1)\n",
    "plt.plot(x_axis, reduced_jsd3, color='orange', label='decomposition-opt', marker='o', markersize=16, linewidth=1)\n",
    "plt.plot(x_axis, reduced_jsd4, color='red', label='full-opt', marker='s', markersize=16, linewidth=1)\n",
    "# plt.set_title('6by6 structure', fontsize=15)\n",
    "# plt.xlabel('loss', fontsize=15)\n",
    "# plt.ylabel('JSD-dense', fontsize=15)\n",
    "plt.tick_params(axis='x', labelsize=28)\n",
    "plt.tick_params(axis='y', labelsize=28)\n",
    "# Hide the tick labels on both x and y axes\n",
    "# plt.xticks([])\n",
    "# plt.yticks([])\n",
    "# axs[0, 0].legend(fontsize=12, loc='lower left')  # Set the fontsize for the legend labels to 12\n",
    "# plt.gca().invert_yaxis()  # Invert the y-axis\n",
    "# plt.legend(loc='lower left', fontsize=16)\n",
    "\n",
    "# Save the plot as a PDF\n",
    "output_filename = 'Fig 11-sim2.svg'\n",
    "plt.savefig(output_filename, format='svg', bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293e2479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86dd101f",
   "metadata": {},
   "source": [
    "picture 3 in graph similarity, Fig. 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bf5180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create path for base_sample\n",
    "path_sample_base = 'sample_G2_base.csv'\n",
    "# Open the file in read mode and create a CSV reader\n",
    "with open(path_sample_base, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    # Read the first row from the CSV file\n",
    "    row = next(reader)\n",
    "\n",
    "    # Convert the row elements to integers (if needed)\n",
    "    sample_base_read = [element for element in row] \n",
    "    \n",
    "x_axis = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]\n",
    "\n",
    "\n",
    "    \n",
    "# manipulate the base sample\n",
    "\n",
    "string_representation = sample_base_read[0]\n",
    "\n",
    "# Convert the string to an actual list of lists\n",
    "try:\n",
    "    list_of_lists = ast.literal_eval(string_representation)\n",
    "except ValueError as e:\n",
    "    # If the string_representation is not a valid Python literal, ValueError will be raised.\n",
    "    print(\"Error:\", e)\n",
    "    list_of_lists = None\n",
    "    \n",
    "string_list1 = [str(sub_list) for sub_list in list_of_lists]\n",
    "\n",
    "\n",
    "string_representation = sample_base_read[1]\n",
    "\n",
    "# Convert the string to an actual list of lists\n",
    "try:\n",
    "    list_of_lists = ast.literal_eval(string_representation)\n",
    "except ValueError as e:\n",
    "    # If the string_representation is not a valid Python literal, ValueError will be raised.\n",
    "    print(\"Error:\", e)\n",
    "    list_of_lists = None\n",
    "    \n",
    "string_list2 = [str(sub_list) for sub_list in list_of_lists]\n",
    "\n",
    "\n",
    "string_representation = sample_base_read[2]\n",
    "\n",
    "# Convert the string to an actual list of lists\n",
    "try:\n",
    "    list_of_lists = ast.literal_eval(string_representation)\n",
    "except ValueError as e:\n",
    "    # If the string_representation is not a valid Python literal, ValueError will be raised.\n",
    "    print(\"Error:\", e)\n",
    "    list_of_lists = None\n",
    "    \n",
    "string_list3 = [str(sub_list) for sub_list in list_of_lists]\n",
    "\n",
    "\n",
    "# Combining the three lists into a single list\n",
    "sample_base_read = string_list1 + string_list2 + string_list3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf96f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create path for sample\n",
    "path_sample = 'sample_G2_1.csv'\n",
    "# Open the file in read mode and create a CSV reader\n",
    "with open(path_sample, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    # Read the first row from the CSV file\n",
    "    row = next(reader)\n",
    "\n",
    "    # Convert the row elements to integers (if needed)\n",
    "    sample_read1 = [element for element in row]\n",
    "    \n",
    "\n",
    "# create path for sample\n",
    "path_sample = 'sample_G2_2.csv'\n",
    "# Open the file in read mode and create a CSV reader\n",
    "with open(path_sample, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    # Read the first row from the CSV file\n",
    "    row = next(reader)\n",
    "\n",
    "    # Convert the row elements to integers (if needed)\n",
    "    sample_read2 = [element for element in row]\n",
    "    \n",
    "# create path for sample\n",
    "path_sample = 'sample_G2_3.csv'\n",
    "# Open the file in read mode and create a CSV reader\n",
    "with open(path_sample, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    # Read the first row from the CSV file\n",
    "    row = next(reader)\n",
    "\n",
    "    # Convert the row elements to integers (if needed)\n",
    "    sample_read3 = [element for element in row]\n",
    "    \n",
    "# create path for sample\n",
    "path_sample = 'sample_G2_4.csv'\n",
    "# Open the file in read mode and create a CSV reader\n",
    "with open(path_sample, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    # Read the first row from the CSV file\n",
    "    row = next(reader)\n",
    "\n",
    "    # Convert the row elements to integers (if needed)\n",
    "    sample_read4 = [element for element in row]\n",
    "    \n",
    "    \n",
    "\n",
    "jsd1 = []\n",
    "\n",
    "for i, sample in enumerate(sample_read1):\n",
    "    \n",
    "    # Your string representation of the list of lists\n",
    "    string_representation = sample_read1[i]\n",
    "\n",
    "    # Convert the string to an actual list of lists\n",
    "    try:\n",
    "        list_of_lists = ast.literal_eval(string_representation)\n",
    "    except ValueError as e:\n",
    "        # If the string_representation is not a valid Python literal, ValueError will be raised.\n",
    "        print(\"Error:\", e)\n",
    "        list_of_lists = None\n",
    "    \n",
    "    string_list = [str(sub_list) for sub_list in list_of_lists]\n",
    "    \n",
    "    jsd = calculate_jsd(sample_base_read, string_list)\n",
    "    \n",
    "    jsd1.append(jsd)\n",
    "    \n",
    "#     print(jsd)\n",
    "    \n",
    "jsd2 = []\n",
    "\n",
    "for i, sample in enumerate(sample_read2):\n",
    "    \n",
    "    # Your string representation of the list of lists\n",
    "    string_representation = sample_read2[i]\n",
    "\n",
    "    # Convert the string to an actual list of lists\n",
    "    try:\n",
    "        list_of_lists = ast.literal_eval(string_representation)\n",
    "    except ValueError as e:\n",
    "        # If the string_representation is not a valid Python literal, ValueError will be raised.\n",
    "        print(\"Error:\", e)\n",
    "        list_of_lists = None\n",
    "    \n",
    "    string_list = [str(sub_list) for sub_list in list_of_lists]\n",
    "    \n",
    "    jsd = calculate_jsd(sample_base_read, string_list)\n",
    "    \n",
    "    jsd2.append(jsd)\n",
    "    \n",
    "#     print(jsd)\n",
    "    \n",
    "    \n",
    "jsd3 = []\n",
    "\n",
    "for i, sample in enumerate(sample_read3):\n",
    "    \n",
    "    # Your string representation of the list of lists\n",
    "    string_representation = sample_read3[i]\n",
    "\n",
    "    # Convert the string to an actual list of lists\n",
    "    try:\n",
    "        list_of_lists = ast.literal_eval(string_representation)\n",
    "    except ValueError as e:\n",
    "        # If the string_representation is not a valid Python literal, ValueError will be raised.\n",
    "        print(\"Error:\", e)\n",
    "        list_of_lists = None\n",
    "    \n",
    "    string_list = [str(sub_list) for sub_list in list_of_lists]\n",
    "    \n",
    "    jsd = calculate_jsd(sample_base_read, string_list)\n",
    "    \n",
    "    jsd3.append(jsd)\n",
    "    \n",
    "#     print(jsd)\n",
    "    \n",
    "    \n",
    "    \n",
    "jsd4 = []\n",
    "\n",
    "for i, sample in enumerate(sample_read4):\n",
    "    \n",
    "    # Your string representation of the list of lists\n",
    "    string_representation = sample_read4[i]\n",
    "\n",
    "    # Convert the string to an actual list of lists\n",
    "    try:\n",
    "        list_of_lists = ast.literal_eval(string_representation)\n",
    "    except ValueError as e:\n",
    "        # If the string_representation is not a valid Python literal, ValueError will be raised.\n",
    "        print(\"Error:\", e)\n",
    "        list_of_lists = None\n",
    "    \n",
    "    string_list = [str(sub_list) for sub_list in list_of_lists]\n",
    "    \n",
    "    jsd = calculate_jsd(sample_base_read, string_list)\n",
    "    \n",
    "    jsd4.append(jsd)\n",
    "    \n",
    "#     print(jsd)\n",
    "\n",
    "\n",
    "# List to store the reduced numbers\n",
    "reduced_jsd1= []\n",
    "\n",
    "# Grouping the elements and calculating the mean for each group\n",
    "for i in range(0, len(jsd1), 3):\n",
    "    group = jsd1[i:i+3]\n",
    "    mean_value = calculate_mean(group)\n",
    "    reduced_jsd1.append(mean_value)\n",
    "    \n",
    "# List to store the reduced numbers\n",
    "reduced_jsd2= []\n",
    "\n",
    "# Grouping the elements and calculating the mean for each group\n",
    "for i in range(0, len(jsd2), 3):\n",
    "    group = jsd2[i:i+3]\n",
    "    mean_value = calculate_mean(group)\n",
    "    reduced_jsd2.append(mean_value)\n",
    "    \n",
    "# List to store the reduced numbers\n",
    "reduced_jsd3= []\n",
    "\n",
    "# Grouping the elements and calculating the mean for each group\n",
    "for i in range(0, len(jsd3), 3):\n",
    "    group = jsd3[i:i+3]\n",
    "    mean_value = calculate_mean(group)\n",
    "    reduced_jsd3.append(mean_value)   \n",
    "    \n",
    "# List to store the reduced numbers\n",
    "reduced_jsd4= []\n",
    "\n",
    "# Grouping the elements and calculating the mean for each group\n",
    "for i in range(0, len(jsd4), 3):\n",
    "    group = jsd4[i:i+3]\n",
    "    mean_value = calculate_mean(group)\n",
    "    reduced_jsd4.append(mean_value)\n",
    "    \n",
    "    \n",
    "plt.figure(figsize=(8, 4))    \n",
    "    \n",
    "# Plot data on each subplot\n",
    "plt.plot(x_axis, reduced_jsd1, color='blue', label='baseline', marker='x', markersize=16, linewidth=1)\n",
    "plt.plot(x_axis, reduced_jsd2, color='green', label='rotation-cut', marker='^', markersize=16, linewidth=1)\n",
    "plt.plot(x_axis, reduced_jsd3, color='orange', label='decomposition-opt', marker='o', markersize=16, linewidth=1)\n",
    "plt.plot(x_axis, reduced_jsd4, color='red', label='full-opt', marker='s', markersize=16, linewidth=1)\n",
    "# plt.set_title('6by6 structure', fontsize=15)\n",
    "# plt.xlabel('loss', fontsize=15)\n",
    "# plt.ylabel('JSD-dense', fontsize=15)\n",
    "plt.tick_params(axis='x', labelsize=28)\n",
    "plt.tick_params(axis='y', labelsize=28)\n",
    "# Hide the tick labels on both x and y axes\n",
    "# plt.xticks([])\n",
    "# plt.yticks([])\n",
    "# axs[0, 0].legend(fontsize=12, loc='lower left')  # Set the fontsize for the legend labels to 12\n",
    "# plt.gca().invert_yaxis()  # Invert the y-axis\n",
    "# plt.legend(loc='lower left', fontsize=16)\n",
    "\n",
    "# Save the plot as a PDF\n",
    "output_filename = 'Fig 11-sim3.svg'\n",
    "plt.savefig(output_filename, format='svg', bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63aa7ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff1409f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec1af75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f06ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
